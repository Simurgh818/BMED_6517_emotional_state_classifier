{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simurgh818/BMED_6517_emotional_state_classifier/blob/main/EEG_SimpleResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vyf3uMJNv4Co"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "from scipy import signal\n",
        "from scipy.signal import welch\n",
        "from scipy.integrate import simps\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WaWMzJ4MSlWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing our git repo\n",
        "import os\n",
        "if not os.path.exists('/content/BMED_6517_emotional_state_classifier'):\n",
        "  !wget https://github.com/Simurgh818/BMED_6517_emotional_state_classifier/blob/main/requirements.txt -q --show-progress --progress=dot\n",
        "  !git clone https://github.com/Simurgh818/BMED_6517_emotional_state_classifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTiKd_g15Kl0",
        "outputId": "0a0be113-868d-4d8f-d6ce-b8ae28409751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     0K .......... .......... .......... .......... .......... 3.40M\n",
            "    50K .......... .......... .......... .......... .......... 6.91M\n",
            "   100K .......... .......... .......... .......... .......... 86.5M\n",
            "   150K .......... .......... ..                                102M=0.02sCloning into 'BMED_6517_emotional_state_classifier'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 139 (delta 6), reused 12 (delta 1), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (139/139), 78.37 MiB | 17.44 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5el_nmPRo6y"
      },
      "outputs": [],
      "source": [
        "#root_folder = 'C:/Users/thiag/OneDrive - Georgia Institute of Technology/DEAP'\n",
        "\n",
        "\n",
        "npy_folder = os.path.join(os.getcwd(), 'BMED_6517_emotional_state_classifier','results', 'npy')\n",
        "#feats_folder = os.path.join(os.getcwd(), 'results', 'EEG_features')\n",
        "\n",
        "\n",
        "#if not os.path.exists(feats_folder):\n",
        " #   os.makedirs(feats_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWW5y21XRo6z"
      },
      "source": [
        "# Load Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B-kzF1cRo61",
        "outputId": "a6db8ea8-1735-41fe-84ef-a4e9c576bfee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/BMED_6517_emotional_state_classifier/results/npy/EEG_features.npy\n",
            "(880, 5, 32, 32)\n",
            "(880, 5, 512)\n",
            "(880, 32, 6)\n",
            "(880,)\n",
            "(880,)\n",
            "(880,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "feats_path = os.path.join(npy_folder, 'EEG_features.npy')\n",
        "print(feats_path)\n",
        "loaded_features = np.load(feats_path, allow_pickle=True)\n",
        "\n",
        "connectivityMatrix = loaded_features.item().get('connectivity_matrix')\n",
        "connectivityLinear = loaded_features.item().get('connectivity_linear')\n",
        "wavelet = loaded_features.item().get('waveletEntropy')\n",
        "Valence = loaded_features.item().get('Valence')\n",
        "Arousal = loaded_features.item().get('Arousal')\n",
        "Classes = loaded_features.item().get('Classes')\n",
        "\n",
        "print(connectivityMatrix.shape)\n",
        "print(connectivityLinear.shape)\n",
        "print(wavelet.shape)\n",
        "print(Valence.shape)\n",
        "print(Arousal.shape)\n",
        "print(Classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykDsmxZ3Ro62",
        "outputId": "4dc6c4c3-43a0-4adf-d686-e377885f9fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7.71 8.1  8.58 4.94 6.96 8.27 7.44 7.32 4.04 1.99]\n",
            "[3. 3. 3. 2. 1. 1. 1. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(Valence[0:10])\n",
        "print(Classes[0:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZzOf2h-Ro63"
      },
      "source": [
        "### Binarization of connectivity matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q06di-GeRo63",
        "outputId": "b660154e-e6dd-4b00-ada1-d3892c4bb818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(880, 5, 32, 32)\n",
            "[[[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]]\n",
            "\n",
            " [[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]]\n",
            "\n",
            " [[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]]\n",
            "\n",
            " [[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]]\n",
            "\n",
            " [[1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  [1 1 1 ... 0 0 0]\n",
            "  ...\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]\n",
            "  [0 0 0 ... 1 1 1]]]\n"
          ]
        }
      ],
      "source": [
        "mean = np.mean(connectivityMatrix)\n",
        "binaryConnectivity = connectivityMatrix\n",
        "print(binaryConnectivity.shape)\n",
        "binaryConnectivity = np.where(connectivityMatrix < mean, 0, 1)\n",
        "print(binaryConnectivity[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BNj74mPkRo64",
        "outputId": "2186a2d5-01de-4416-9133-f0bb7ab3f321"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAEICAYAAADROQhJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de5xcVZXvvz8bQpSABFoQE0gCN4AZHSOEhwMiokBg9EZ83cRXuKPGUdDx+bmgDnCjjsx8VAZHfIRrBFQELvjIOJkbIw/xBaaD4REwEAIMiUAIEAUEYpJ1/zinTVV1rdVV3ZXqrsr6fj7n01V7nX327lPVq/fZ6yUzI0mSpBt4zkhPIEmSpFWkQkuSpGtIhZYkSdeQCi1Jkq4hFVqSJF1DKrQkSbqGVGhdgqRXSlrVgutcL+k9I32NJBkKqdC6BDP7uZkdPNLzaAZJkyWZpJ1Gei5Jd5AKLUmSriEVWoch6T5JZ0m6Q9Ljkr4laayk4yStLc85UNJjkg4t379I0iOSjivfHyXpV5I2Srqlv72JOZwm6ZeSviLpD5J+J+k1zrnPkfRpSfdLWi/pUknPL8U3lD83SnpS0iuGck+SpJ9UaJ3J24GTgAOBg4BPVwrN7B7gfwHfkfQ84FvAJWZ2vaQJwH8AnwX2BD4OXC3pBU3O4UjgHqAXOAf4vqQ965x3Wnm8GjgAGAd8pZQdW/7cw8zGmdmvm5xDklSRCq0z+YqZPWBmjwGfA+bUnmBmFwGrgZuAfYFPlaJ3AIvNbLGZbTWzpUAfcEqTc1gP/KuZ/dnMrgBWAX9b57y3A18yszVm9iRwFjA7982S7UEqtM7kgYrX9wMvcs67CHgJ8G9m9mzZNgl4S/m4uVHSRuAYCqXXDOusOrOBN48XlbLK83YC9mlyvCQZlFRoncl+Fa/3B35fe4KkccC/At8Ezq14HHwA+LaZ7VFx7Gpm5zU5hwmSNNg8yrZJNedtBh4GMtVL0lJSoXUmp0uaWCqpTwFX1DnnAqDPzN5DsWf29bL9O8DrJZ0kqafCoDCxyTnsDXxI0s6S3gK8GFhc57zvAR+RNKVUsv8EXGFmm4FHgK0Ue2tJMmxSoXUmlwE/AdZQbMx/tlIoaRYwE3h/2fRR4FBJbzezB4BZwCcpFMoDwCdo/rtwEzAV2ECxj/dmM3u0znkLgW9TWDTvBZ4BPghgZn8q+/6yfPw9qsk5JEkVygSPnYWk+4D3mNlPR3AOp5VzOGak5pAk9cgVWpIkXUMqtKQukr5eOrvWHl8fvHeSFEhaWDpU3+7IJenLklZLurXfGbyUzZV0d3nMbWi8fORMkmR7IelY4EngUjN7SR35KRR7qqdQOGtfYGZHlgavPmAGhTV8OXCYmT0ejZcrtCRJthtmdgPwWHDKLAplZ2Z2I7CHpH0pImGWmtljpRJbSmHoCmmrt3Zvb69NnjzZkS73O3o6eUsw2B8C2eZA9nQgc8bbGHTZFMieCGTPC2TRFL31dnSrojX6wbsFwugX6AlkDpuDSf4p6PfcQLbead8a9Imm/kwgi75W0XhjhzCWtxJ5BthkJkfcEDNnzrQNGzY0dO7y5ctXUj3VBWa2oInhJlDtKL62bPPaQ4al0CTNpPB36gH+z2DOmZMnT6avr8+RBl+jq52vQ6S06nlE9fNIILvFF5kz3o+Cy60NZNcGshmB7LeBzNMJkdKN/tiuPzIQRr/A8wOZw/rg/3jwsfDSQHaB0x4piz0C2R2BLPpaRQp52hDG8v7heX9dzbBhw4bg77QaSc+YWfR1bStDfuSU1ANcCJxM8ZnMkeR9NkmSdAxGsd5s5Bg266iOfJlYtnntIcPZQzsCWF0GHW8CLqd4Hk6SpKMxijVsI8ewWQS8q7R2HgX8wcweBJYAJ0oaL2k8cGLZFjKcR856z7gDHlAkzQPmAey///7DGC5JkvbQv0IbPpK+BxwH9Jb5+s4BdgYws69TbA6dQpEZ5k/A/yxlj0n6DLCsvNT8MrtMyHY3CpQbhAsAZsyYkT4iSTLqaZ1CM7MBqa1q5Aac7sgWUoTONcxwFNqQnnGTJBnttE6htZvhKLRlwFRJUygU2WzgbXGX5fjWzMBm/yYndda3PaM8sefL5EAWmPy0rH77Xs/Wb4fYuhVZxSLZzoHMcxMZqlWPp3zR+uBe7f0yRxB8Lr8PZA/4Ik7o9WUHON4HkQ2vXg6kfqKvVZTyNwq89frdF/TxEuC1aF3Vsiu1myErNDPbLOkMio26HmChma1s2cySJBlBdjCFBmBmi4k9vpIk6Ti2AsFjxygm87onSVLDDvjImSRJN5MKLUmSriBXaEmSdA2p0BrjcfxAc881AygKBNXhoSCpQJQywbN5D8av6jdHmTFeGMi8LAuDESXA+LPTHt2O0G3jfl8UuTDs7V008L94KLheFFwf3ZADHbeNm4Y4VpRg5OBA5n0u0TUjVxvveq3xXN86yOijl1yhJUlSh1yhJUnSFeQjZ5IkXUMqtCRJuoZUaEmSdA2p0BpjC37a7CjQ3LNmfiKw6TzrW0C3/KPfree/+zJeW7/5sMBktjRIE36oL+LNgezmQOZZv6I0KFEg/FNBpHaUgfupH9RvHxP0iYjm+MN7fZkXFB6lt44+l8DoS906bSWRYd2r1hzVgfBSQ0eW4sbpT/DYeeQKLUmSGnKFliRJ12DE68PRSyq0JElq6NwVWhYaTpKkDq2r+iRppqRVklZLOrOOfJKkayTdKul6SRMrZFskrSiPRYONlSu0JElqaF3oU0W5yxMoCiktk7TIzCrtMl+gqJ5+iaTjgc8D7yxlT5vZ9EbHyxVakiQ1tLQuZyPlLqexzWh+XR15w7R3hfYH/Py2UaSzF1kduGbwad+lo+fnQb8o+vhup31Xv8ukwG3jQ8FQUQD67wKZN1wUgB5VTo/SEUeB997HGbmcRETuHpG7xAFOe1TrIXLbiOoNRLUeotJHTuoFz0soJJpD4zS1h9YrqbJEw4Ky0ls/jZS7vAV4I0Wh+1OB3STtZWaPAmPL628GzjOzH0aTyUfOJEnq0LBC22BmM4Y52MeBr0g6DbiBwm2y38w6yczWSToAuFbSbWZ2j3ehVGhJktTQUivnoOUuzez3FCs0JI0D3mRmG0vZuvLnGknXAy8HXIWWe2hJktTQ0j20v5S7lDSGotxllbVSUq+kfl10FmVxYUnjJe3Sfw5wNHGQR67QkiSppXVWTq/cpaT5QJ+ZLQKOAz4vySgeOfsrqb8Y+IakrRSLr/NqrKMDSIWWJEkdWudYW6/cpZmdXfH6KuCqOv1+Bby0mbFSoSVJUkPnRgq0V6Ftxk+bMDno56QqCLNmRK4ZS4IsHYf7/f59bf32KF/86wLZJYFsdSB7NJB5bgXRA8RJgcxzewA4bJdA6PgpHH+x32VhcLmpgeyNXroKcGsYXBukzVgaXC6qAxG5ZkTuKp4suvdeaYbI66hxdlCFJuk+inu4BdjcAvNtkiQjzg6q0EpebWZObZ0kSTqTzLaRJElX0Lll7Ibrh2bATyQtlzSv3gmS5knqk9T3SLTZlCTJKKGlfmhtZbgrtGPKsIS9gaWSfmdmN1SeUMZ1LQCYsZtaUwc1SZLtSOfuoQ1rhVYRlrAe+AFFZH2SJB3NDrhCk7Qr8Bwze6J8fSIwP+z0NEVcfT2ilA8OYUGTyH4duGawzF9Evv5Ip19U0SRIBXHIpb4scqWIntxXOe2R20Dk9RAVBTn/WV/22Yvrt68JrvfrQLYikE37hS/ztrbPCa4XFRqJsqBEhVycmjFAdaBjo/PwXDruDPo0x+hTVo0wnEfOfYAfSOq/zmVm9v9aMqskSUaQzjUKDFmhmdka4GUtnEuSJKOCzt1DS7eNJElqSIWWJElXkQotSZKuIFdoSZJ0DanQGmMLmFPFQ8uCfr9y2qMqEl5BE/ysGRC4ZgDc5Lh0zPL73BdUEozcL/af6MvWBfN/idMeuRt4RToAnhfIosIlXnGVaB5RZoPIYTIq5OJlH4l+ryhDSuRd5LnMQFx45VVOe+Ti4n3ONzjtzbEDWjmTJOlmMjg9SZKuoHMfObNISpIkNbQ29EnSTEmrJK2WdGYd+SRJ10i6VdL1kiZWyOZKurs85g42Viq0JElqaJ1Ck9QDXAicTFEhfY6kaTWnfQG41Mz+miJ88vNl3z0potSOpIgTP0fS+Gi8VGhJktShZSu0I4DVZrbGzDYBlwOzas6ZBlxbvr6uQn4SsNTMHjOzxymyo8+MBmvrHtpG4EeObK8g0NmzSB12UzDYrr4oTMsWBZp71swf+QHtk9/vW0AnR9HMf+OLJkTmL8fUtv/Pgz6B6e4Dwc2Kbr/3mW0M+kT5BCILYkTtUqCfJUGf3QPZzoHs4EAWrRyectq9uYNfCum5QZ/GacrK2Supr+L9gjJlWD8TqC6BsJZixVXJLRSFhi8ATgV2k7SX03dCNJk0CiRJUkNTRoENLagl8nHgK5JOo/A8WccQzayp0JIkGYi1zG1jHdUZkiaWbduGMvs9xQoNSeOAN5nZRknrKIoQV/a9Phos99CSJBnI1gaPwVkGTJU0RdIYYDZQ5W4uqVdSvy46i20VDZcAJ0oaXxoDTiTeLUiFliRJDUbxwNfIMdilzDYDZ1AoojuBK81spaT5kvpTtB4HrJJ0F0Wexc+VfR8DPkOhFJcB88s2l3zkTJKkGmMQy1mTlzNbTE2EmpmdXfH6KuAqp+9C4hrUVaRCS5Kkmv4VWgfSVoW2icLuWo8/Bf1e6LQvdQLdASYFsij4OKoB4AWaR64ZfC0odPWOoF9UneH4QOYUD9gSuMX0nBdcboBf9zaiQPPJTvttQR8vkBzgRYHshEDmeeH0BH2iPAkHBrJzxvmyG5/0ZT912k8JxvL2ilq2hzSEGh+jgVyhJUlSTa7QkiTpKlKhJUnSFRj5yJkkSZdgFBveHUgqtCRJBpIrtCRJuoI0CjTGE2zLEVJLlHhirNMe5Wn/UCC7JJAdcqkv83wNw6wZkWvGdwKXjn8L+nl+LOCmaOiJkicE878j6Ba5v1zmtA817/7UQPb5QOa5MewR9HlPIIs+6p8HrhmvPDbo6BQCOOTtQR/Hz2nsdUGfZujQFdqgbiuSFkpaL+n2irY9JS0ts0guHSzpWpIkHUQLQ5/aTSN+eBczMKnamcA1ZjYVuKZ8nyRJN9DNCs3MbgBqA0Jnse3J7RLgDS2eV5IkI0V/LGcjxyhjqHto+5jZg+Xrhygi5OsiaR4wD1qVTTNJku3OKFx9NcKwjQJmZpLc3e0yHe8CgPHBeUmSjBI62LF2qLGsD0vaF6D8ub51U0qSZMTp0D20oa7QFgFzgfPKn17tkyqeB3jJxyNzuEdUzyTKBLE6kJ0UyPaf6AiCgiZh1ozINeODQ3Tp8G7wz4J5fMsXvTroFhU88VxtosIfUZGRaKzov7KXySLKEhi5o0Tz6AtkezquGRB8V68MLvgKp70V9YE7eIU2qEKT9D2KjJK9ktZS1Mk7D7hS0ruB+4G3bs9JJknSRro59MnM5jii17R4LkmSjBY6dIWWNQWSJKmmxX5okmZKWiVptaQBPquS9pd0naTfSrpV0ill+2RJT0taUR5fH2ysjOVMkmQgLdrwl9QDXEiRWHgtsEzSIjOrjKr7NEXxlK9JmkZRf2ByKbvHzKY3Ol6u0JIkqabfKNCaMnZHAKvNbI2ZbQIup3DMrx2xv2D984mzsYekQkuSZCCNP3L2SuqrOObVXGkC8EDF+7VlWyXnAu8ojY6LgQ9WyKaUj6I/k/TKwabd1kfOp4HfOrKdg36eWdupBwLA7wLZo4EsiuZY51R4mbAm6BQVNImyZgzVpeNJp9+uwVhBKosHTvdlDweX9EJHovsb3cao3+6BzPvVomItDwSyqFjLyYFsv0Dmjue5ZgAc7rRH6UwapbkydhvMzHMWapQ5wMVm9kVJrwC+LeklwIPA/mb2qKTDgB9K+isz+6N3oVyhJUlSTWuNAuuo1ucTy7ZK3k3pdWdmv6ZwY+w1s2fN7NGyfTlwD3BQNFgqtCRJBtK6PbRlwFRJUySNAWZTOOZX8l+UbmCSXkyh0B6R9ILSqICkAygW3NFCPq2cSZLU0MKMtWa2WdIZwBKKcqgLzWylpPlAn5ktAj4GXCTpI+Xop5Ux4scC8yX9mUJ9/r2ZRUEeqdCSJKmhxSm4zWwxxWZ/ZdvZFa/vAI6u0+9q4OpmxkqFliRJNc0ZBUYVqdCSJBlIh4Y+tVWhRSvZKBbW+2cR/RP5QyCLvPYiq/dLhtIp8i2JUk9EhnDPNQNgnOPS8eqgzxW+KHKJiO6x9/fgZeEAeEEgc2qCAHGmloec9uiJys1WSjzHaHMn+r1dr5losJc57U09oDlk1ackSbqKVGhJknQF3ZwPLUmSHZBcoSVJ0hWklTNJkq4hjQKNsQU/J/szQb8ep702IKySPQJZNFZklPSC5Pf/ud9ny7O+rCeaSFQDIAo096yZOwUB7fv5FtChWgM9C2j0jz/6taLPMwom9z6zyID40kB2QCCLYnLGRJHrTzjt7wv6nODYny94MujUBLmHliRJV5ArtCRJuoZUaEmSdBX5yJkkSVeQVs4kSbqGfORMkqSrSIU2OFFERWSW92RRUHK0BXBSIDsmkLk59IPBes4LLhj9At8KZEENADfQPHDN4BzfpeO+c/1+kZuF597gue1A7PYQ5fJ/dSB7h9N+d9Anct2J3DaOilwzgke4R39Rv32vHwfXu8JJq39/0KdROjj0adAU3JIWSlov6faKtnMlrasoAHrK9p1mkiRtpYWFhttJIzUFLgZm1mk/38yml8fiOvIkSTqRfqNAI8coY1CFZmY3EKd6SpKkm2ht1SckzZS0StJqSWfWke8v6bqy/uatlU98ks4q+62SFO0WAcOr+nRGOfhCSeO9kyTN6y9COgoVepIk9WhR1aeyatOFFGVLpwFzJNWmNv00cKWZvZyiKtRXy77Tyvd/RfGU+NX+KlAeQ1VoXwMOBKZTFAP9oneimS0wsxlmNiMqJpwkySihtSu0I4DVZrbGzDYBlwOz6ozYH5z6fLYllZ4FXF7W57wXWF1ez2VIVk4z+4vBT9JFQGSPSZKk02h8w79XUl/F+wVmtqDi/QSq8wesBY6suca5wE8kfZDCeP7air431vSdEE1mSApN0r5m9mD59lTg9uj8fg7eDa6v/VX6eSro6JiinwqKA0RWisj0Hlm9n+e0fyB4lr55wI7BNu4IxopcER443Zd5NQCi72fkmvGABVk6rg5cQW5x2l/rtEPx/9fjkkAW+Pwsry1pW+Jl4YA428Z/BrKHAmGUPMVzEbjsy34fr0bBXcE4DdOc28YGM4sqYDTCHOBiM/uipFcA35bklvCIGFShSfoecByFJl4LnAMcJ2k6xa9+H3GikyRJOgkjrlrUHOuA/SreT2Rg5q93U3pSmNmvJY0FehvsW8WgCs3M5tRp/uZg/ZIk6WBa51i7DJgqaQqFMpoNvK3mnP8CXgNcLOnFFAvQR4BFwGWSvkThWz0V+E00WIY+JUlSTQtjOc1ss6QzgCUUuVoXmtlKSfOBPjNbBHwMuEjSR8rRTzMzA1ZKupJid2YzcLqZhTNLhZYkSTUtDn0qHe8X17SdXfH6DuBop+/ngM81OlYqtCRJBjIKw5oaIRVakiTVZPqgBnkCuLa+aH2wxPXirpxLAfDCQHbYLr7s/KCoyRin/aZgrMg94HWBLMpK4Wb9wC9OEhU0ibJmhK4ZbwpcOm53+v02GCv6pd8YyAKfiMM81/FaX/VKorQff/JFkZf6vEDmeau8KuizymkP3egbJRM8JknSVeQKLUmSrqCD86GlQkuSZCC5QkuSpCvIFVqSJF1Da0Of2koqtCRJBpIrtAbooch2VIe9X+Z329vJpvDUD/w+YYrdetGpJZ+92Jd5GTy8LBwAkwPZZYHMy6YAsQuG9z303Dkgzj7iZs0A3zUD/MIr/xH0me2Ltjzpy3qiOTofzuPf9btE9Wmi79WpgSxydffyBEbZWDyviqeDPg2TfmhJknQNqdCSJOkq8pEzSZKuIFdoSZJ0DRn6lCRJV5ErtGESmY8eqN/sBYsD3BzIjr/Yl0VxyV6geRRTfVsg8wKMIY6djv55etbRqE80/7AGQBRo7lkz/zYIaH+fbwHtCepH8EQg+1795vFBgoL9ggQFUdKDIG49nKJn4I++w953P7AhN0461iZJ0lXkCi1Jkq6gg40Cw6mcniRJt9KiyukAkmZKWiVptaQBhR0lnS9pRXncJWljhWxLhcwpSriNXKElSVJNC62cknqAC4ETKAoFL5O0qKwjUAxn9pGK8z8IvLziEk+b2fRGx8sVWpIk1fQ/cjZyDM4RwGozW2Nmm4DLgVnB+XNwTTmDkwotSZKBNK7QeiX1VRy12cYnUO2nsLZsG4CkScAUqrPrjy2ve6OkNww27UYqp+8HXEoRE23AAjO7QNKewBUU8df3AW81s8eja23eAusd94zfB24bDw02ySZZGMh+Hci8eveRST7yNjg0kB0cyCLXkhc47VHdgOh6bsJ7iP09vEDzwDWDLwQuHb8J+h3ri/7d2ed5vZPwAOAtL/JlmwJXlSt8Ee8KZEc67dFn9ozTfknQp2Gac9vYYGben0azzAauqqm9OcnM1kk6ALhW0m1mdo93gUZWaJuBj5nZNOAo4HRJ04AzgWvMbCpwTfk+SZJuoHWPnOuA/SreTyzb6jGbmsdNM1tX/lwDXE/1/toABlVoZvagmd1cvn4CuJNiyTiLbf8QLgEGXQ4mSdIB9BsFGjkGZxkwVdIUSWMolNYAa6WkQ4DxVDwkSRovaZfydS9FMeIoq1JzVk5Jkyk05E3APmb2YCl6iDhNV5IkHUSr3NDMbLOkM4AlFBkRF5rZSknzgT4z61dus4HLzaxy3+HFwDckbaVYfJ1XaR2tR8MKTdI44Grgw2b2R2nbnoaZmaS6GyDlJuE8KNaaSZKMblrtV2tmi6nJj2pmZ9e8P7dOv18BL21mrIasnJJ2plBm3zWz75fND0vat5TvC6yv19fMFpjZDDObsVczM0uSZMRooV9tWxlUoalYin0TuNPMvlQhWgTMLV/PBX7U+uklSdJuWuuG1l4aeeQ8GngncJukFWXbJ4HzgCslvRu4H3jrYBf6E36KeiehBuB7BzwS9IkycUwNZCsCmaf9o6wZgQdAOI/IIyLai/UyPgReCuEcQz+AN/oirwZAmDUjcs04InDp2M3v52bO+FQwj/t90ZjAl+LwX/iyScFw3kon8oXwNpJaFfozGldfjTDo729mv8DPSvKa1k4nSZKRZisdW8UuYzmTJBlI167QkiTZsejg7EGp0JIkGUgqtCRJuoIOzsCdCi1Jkmo6uOhTexXac/Hdfk/oDTo61Ul+eK/f5fbgcm88xpdNC0zvi32RywmB7POBLHIQ3D2Qea4skVvMqwNZ6O/xM1/U4/nnRKlJgqwZkWsGj/guHdP/wel3oX+5LwR+OM/3Rbx3nC/7O8eNJSKK8fHcejY0P0xd8pEzSZKuII0CSZJ0FbmHliRJV5ArtCRJuoZUaEmSdA1p5UySpKvIPbQGWA9c4MgOCOzNBzqynwZjHRBNJPBhiJbaXqKIaUGfNweyyDUj+t2iLB1eQRnH8wWAdwSy5UFp18OiX+B5TntQoMwraAJB1gwC1wyACxyXjul+n+i74xWhAcIP+/0X+7IlTvurgqG8wjYXBX0aJR85kyTpKjpVoWVdziRJqugPfWpVxlpJMyWtkrRa0oDqcJLOl7SiPO6StLFCNlfS3eUxt7ZvLblCS5JkAK1aoUnqoYjLOIGiyPAySYsqi52Y2Ucqzv8gZam6svbvORS5Lg1YXvZ16//mCi1JkipaW8WOI4DVZrbGzDYBl1OUwPSYw7ad1pOApWb2WKnElgIzo8FyhZYkSRVNGgV6JfVVvF9gZgsq3k+g2gy3FqdYvKRJwBTg2qDvhGgybVVoW/FL2Pc57VAUAa1HFLzr5dYHuDbIGX9O0M8z3HlWKigKEXpEcd+PBbLbApn3RYysc3cHssg6Gpl3H/9u/fbxu/h9Xh/dkKgGQBBo7lozV/gB7W/8H4HV9GXBWIH1/PBTfdmhP6jf/sdgqJ847c8N+jRDE24bG8wsKn/QDLOBq8xsyE+8+ciZJEkVLa76tA7Yr+L9xLKtHrOpduxppi+QCi1Jkjq0UKEtA6ZKmiJpDIXSGuDdKOkQYDzw64rmJcCJksZLGg+cSPxAlHtoSZJU08rQJzPbLOkMCkXUAyw0s5WS5gN9Ztav3GYDl5uZVfR9TNJnKJQiwHwzi3ZjUqElSVJNqyMFzGwxNflRzezsmvfnOn0XAgsbHSsVWpIkA8hYziRJuoKujuWUtB9wKbAPxe+6wMwukHQu8F62pbH/ZLm0dOnBd1XwAr/Bz59+aNAnki0NZF5wN8DrnPYox/+yQPaeIYwFcX2AfZx2r5YDwM2BLOrnRkgD33LaoyDzt7woGCtwtYlqAHiB5qFrxhW+Swdf9fvdFbiWHPT3vqznTfXbxwcfzMlOPY3z/C4N0+1VnzYDHzOzmyXtRhF+0K8TzjezL2y/6SVJMhJ07QrNzB4EHixfPyHpTgbx1k2SpHPp5ASPTfmhSZpMETja77x/hqRbJS0s/USSJOlwWuxY21YaVmiSxgFXAx82sz8CXwMOBKZTrOC+6PSbJ6lPUl8UjpQkyeihqxWapJ0plNl3zez7AGb2sJltMbOtFIkyj6jX18wWmNkMM5vhxUImSTJ6aHU+tHYyqEKTJOCbwJ1m9qWK9n0rTjuVuFh5kiQdRKeu0Bqxch4NvBO4TdKKsu2TwBxJ0ykU+n3A+wa70DP4GTKieIYnnPbAkh+6gYwNZFF2Ce8/0s5BnwMD2SOBzHNVAYi8G7ysGlGe/Ej2n4EsSmnifZ4vDC636be+bMyuvuz5wTXdLCNR1ozANYMP+C4dB/0o6Bf5v3i+NsESaHdn177n4WCcBulqtw0z+wVQ75MKfc6SJOlMDNg00pMYIhkpkCTJALp2hZYkyY5FV4c+JUmyY5EKLUmSriIfOZMk6Qo6OfSprQptM76rQlTE42CnPXJ8i1wp5gSyyJXCS+rgzQ/gnOAR0HoAAAmjSURBVHG+7OdP+rKoaMzJgcxzlwgSY3BUcMGHAr+NyInRqwkSRYtcEcgO/4Uve29wj3mz0x6kLAmzZkSuGUuCLB3H+/3+eF399t0DT/S7nBvpFSFqhnzkTJKkq+hUhZZFUpIkqaLVoU+SZkpaJWm1pDOdc94q6Q5JKyVdVtG+RdKK8hhQXKWWXKElSTKAVq3QJPVQVE49gaJQ8DJJi8zsjopzpgJnAUeb2eOS9q64xNNmNr3R8XKFliRJFS1OH3QEsNrM1pjZJuByYFbNOe8FLjSzxwHMbP1Q554KLUmSKvqtnI0cQG9/erDymFdzuQlUm2DWMjBB7EHAQZJ+KelGSTMrZGPL694o6Q2DzT0fOZMkGUATfmgbzGzGMIfbCZgKHEdRHf0GSS81s43AJDNbJ+kA4FpJt5nZPdGF2sZWfLP9T4N+nk9MlHUics2IioL8IJB5hVeiZe6NgWvGK4/1ZXve4Mv2C8bzMomMiXw9AqejnwXdav8VV/I5p93LnALwrkA2KZD9XXCP339x/fbDPb8S4oImYdaMwDWDa32Xjt0/7vT7J/9yB/1L/faxX/P7NEqL3TbWUf2VnVi2VbIWuMnM/gzcK+kuCgW3zMzWAZjZGknXU2TMdhVaPnImSTKAFu6hLQOmSpoiaQxFhfRaa+UPKVZnSOqleARdI2m8pF0q2o/Gz0AG5CNnkiQ1tDIfmpltlnQGsISikuVCM1spaT7QZ2aLStmJku6g0JOfMLNHJf0N8A1JWykWX+dVWkfrkQotSZIBtNKxtqzXu7im7eyK1wZ8tDwqz/kVg5SGrSUVWpIkVWwlYzmTJOkiOjX0KRVakiRVdHVNgVYyFpjmyKJsG56p/5igT1QrInLbiFwiXuW0PxX0idxRCFwzomItQaIIpnqCwF/i0SCTxSnBWKsDmZftJKpNcmQgG+of2BKn/dDAP6fnTcEFvYIm+FkzIHDNAPiC49Lx2aCPV0WnRUurXKElSdIVZPqgJEm6hkzwmCRJV5ErtCRJuoI0CiRJ0lV07QpN0lgKe9wu5flXmdk5kqZQ5DbaC1gOvLPMd+TyDH4g1n2D9KtHdNNfG8gOCGQPBTIvL79nuYXYSnjI2wPhlYHsFYHMMxe/z++y14992WVf9mWe1Rf8zzmyMO8ayKJ0DlEsjDfHPwZ9xkeTDJYuUQ2AKNDctWZ+OqhRQE/95uuHv7bq5BVaI8HpzwLHm9nLgOnATElHAf8MnG9m/w14HHj39ptmkiTtpIXB6W1lUIVmBf0JWnYuDwOOB64q2y8BBk2+liTJ6KfJBI+jiobSB0nqkbQCWA8spchHtNHMNpen1MtCmSRJB9LiFNxtpSGjgJltAaZL2oMiB+IhjQ5QpuSdBzBmKDNMkqSt7DCOtWa2UdJ1FNvSe0jaqVyl1ctC2d9nAbAAYJwU7XImSTJK6FqjgKQXlCszJD2XohzVncB1bKtLPRf40faaZJIk7aPbHzn3BS4p6+s9B7jSzH5cZpe8XNJngd8C3xzsQs8BPMt2VB/A23yM3CUiouDuyKXjJU57lIEu/I/hFViA2DXj8EDmRX+fsLvf5wrficGrUQCwKpB5n1m07eC550DsmuHFaYPvavOToM/J9/qy3YOd8LuCz9OrAQAEv4DjmgH46mS49UoKOnWFNqhCM7NbKQoT1Lavoai5lyRJF2FA6FA6iskiKUmSVNHvWNvI0QiSZkpaJWm1pDOdc94q6Q5JKyVdVtE+V9Ld5TF3sLEy9ClJkgG0an+s3Kq6kGLvfS2wTNKiymInkqYCZwFHm9njkvYu2/cEzqF4jjZgedn3cW+8XKElSVJFi40CRwCrzWxNGRp5OTCr5pz3Ahf2KyozW1+2nwQsNbPHStlSYCYBqdCSJBlAE4+cvZL6Ko7a+tMTqLbD1XPCPwg4SNIvJd0oaWYTfavIR84kSapoMsHjBjMbrml1J4rs8cdR+LTeIKmp8nWVF2obT8CG6+D+8m0vsGE417t9+FMaMI8gvT6Xtma8bVTntW/8fgS1CFzeFeWXGOI8WkyNa0ZL5jF/uBeoncfaIV7lH4fQ54tV2+4198OtNzBpCCNVsRWWPFWM1wiDfUbrqC7VUc8Jfy1wk5n9GbhX0l0UCm4dZUX1ir7XR4OpqPHZfiT1tUCz5zxyHjmPUYyknYC7gNdQKKhlwNvMbGXFOTOBOWY2V1IvhV/rdEpDAHBoeerNwGFm9pg3Xj5yJkmy3TCzzZLOoCjA1QMsNLOVkuYDfWa2qJSdWDrrbwE+YWaPAkj6DIUSBJgfKTNIhZYkyXbGzBYDi2vazq54bcBHy6O270JgYaNjjaSVc8EIjl1JzqOanEc1OY8OYsT20JIkSVpN+qElSdI1pEJLkqRrGBGF1kiwapvmcZ+k2yStkNTXxnEXSlov6faKtj0lLS2DcJdKGj9C8zhX0rrynqyQFBWuatU89pN0XUVw8j+U7W29J8E82npPJI2V9BtJt5Tz+N9l+xRJN5V/N1dIyiTQtZhZWw8K0+09FKnHxgC3ANPaPY9yLvcBvSMw7rEUvjW3V7T9C3Bm+fpM4J9HaB7nAh9v8/3YFzi0fL0bhd/StHbfk2Aebb0nFF6z48rXOwM3AUdRFDecXbZ/HXh/Oz+nTjhGYoXWSLBqV2NmNwC1/jSzKKpnQZuqaDnzaDtm9qCZ3Vy+foIiI/IE2nxPgnm0FSvISmtDYCQUWtMBp9sRA34iaXmdoNp2s4+ZPVi+fgjYZwTncoakW8tH0u3+6FuJpMkUCUVvYgTvSc08oM33JCutDY0d3ShwjJkdCpwMnC7p2JGeEPzF0XCk/Gm+BhxIEXryIPDFdg0saRxwNfBhM6sKPm3nPakzj7bfEzPbYmbTKeIXj6CJSms7MiOh0BoJVm0LZrau/LmeIlR8JFOKPyxpX4Dy5/pBzt8umNnD5R/TVuAi2nRPJO1MoUS+a2bfL5vbfk/qzWOk7kk59kaKgkR/qbRWikbs72Y0MxIKbRkwtbTYjAFmA4vaPQlJu0rarf81cCItS+AxJBZRVM+CEayi1a9ASk6lDfdEkiiK7NxpZl+qELX1nnjzaPc9UVZaGzojYYkATqGwIN0DfGqE5nAAhYX1FmBlO+cBfI/i0eXPFHsh7wb2Aq4B7gZ+Cuw5QvP4NnAbcCuFQtm3DfM4huJx8lZgRXmc0u57EsyjrfcE+GuKjBO3UijPsyu+s78BVgP/F9ilXd/ZTjky9ClJkq5hRzcKJEnSRaRCS5Kka0iFliRJ15AKLUmSriEVWpIkXUMqtCRJuoZUaEmSdA3/H2ecrGgRuj/gAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0\n"
          ]
        }
      ],
      "source": [
        "epoch = 3\n",
        "for connectivity_matrix in connectivityMatrix[epoch]:\n",
        "    pixel_plot = plt.figure()\n",
        "    pixel_plot.add_axes()\n",
        "    plt.title(\"pixel_plot\")\n",
        "    pixel_plot = plt.imshow(connectivity_matrix, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar(pixel_plot)\n",
        "    plt.show(pixel_plot)\n",
        "\n",
        "print(Classes[epoch])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UNpFGLIRo65"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKTvDQFmRo65"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "torch.manual_seed(104)\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIk_6O4URo66",
        "outputId": "a81e893f-a45e-465a-ddb6-336c9c4038da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(880, 5, 32, 32)\n",
            "(880, 3, 32, 32)\n",
            "748\n",
            "132\n",
            "[2 2 3 0 3 1 0 2 1]\n",
            "[3 3 2 1 3 3 0 0 3]\n"
          ]
        }
      ],
      "source": [
        "x = connectivityMatrix\n",
        "y = Classes.astype(int)\n",
        "# y = np.where(Valence < 5, 0, 1)\n",
        "\n",
        "print(x[:,:,:,:].shape)\n",
        "xx = x[:,2:5,:,:]\n",
        "print(xx.shape)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(xx, y, test_size=0.15, random_state=42)\n",
        "print(len(x_train))\n",
        "print(len(x_test))\n",
        "print(y_train[0:9])\n",
        "print(y_test[0:9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKwYIk2yRo66",
        "outputId": "b6bc717a-9ab5-45d9-cae4-a37c3f038f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 2., 3., 0., 3., 1., 0., 2., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "tensor_x_train = torch.Tensor(x_train) # transform to torch tensor\n",
        "tensor_y_train = torch.Tensor(y_train)\n",
        "my_train_dataset = data.TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
        "\n",
        "tensor_x_test = torch.Tensor(x_test)\n",
        "tensor_y_test = torch.Tensor(y_test)\n",
        "my_test_dataset = data.TensorDataset(tensor_x_test,tensor_y_test) # create your datset\n",
        "\n",
        "num_epochs = 500\n",
        "lr = 1e-2\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = data.DataLoader(my_train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = data.DataLoader(my_test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(tensor_y_train[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18LdBmz2Ro67"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, inchannel, outchannel, stride=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.left = nn.Sequential(\n",
        "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(outchannel)\n",
        "        )\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inchannel != outchannel:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(outchannel)\n",
        "            )\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.left(x)\n",
        "        out = out + self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, ResidualBlock, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inchannel = 64\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n",
        "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
        "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)        \n",
        "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)        \n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        \n",
        "    def make_layer(self, block, channels, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.inchannel, channels, stride))\n",
        "            self.inchannel = channels\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-swQChRWRo68"
      },
      "outputs": [],
      "source": [
        "def ResNet18():\n",
        "    return ResNet(ResidualBlock)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UpdMe1BRo68"
      },
      "outputs": [],
      "source": [
        "# Utilities\n",
        "def plot_curves(history):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "    axes[0].plot(range(1, num_epochs+1), history['train_loss'])\n",
        "#    axes[0].plot(range(1, num_epochs+1), history['test_loss'])\n",
        "    axes[0].legend(['Train loss curve', 'Validation loss curve'])\n",
        "    axes[0].set_xlabel('epoch')\n",
        "    axes[0].set_ylabel('loss')\n",
        "\n",
        "\n",
        "    axes[1].plot(range(1, num_epochs+1), history['train_acc'])\n",
        "    #axes[1].plot(range(1, num_epochs+1), history['test_acc'])\n",
        "    axes[1].legend(['Train accuracy curve', 'Validation accuracy curve'])\n",
        "    axes[1].set_xlabel('epoch')\n",
        "    axes[1].set_ylabel('accuracy')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qs6mZIsRo68",
        "outputId": "3c474bf4-1564-4071-99a6-d3692df48fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "tensor([2., 2., 3., 0., 3., 1., 0., 2., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "#Use the ResNet18 on Cifar-10\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "#check gpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "#set hyperparameter\n",
        "EPOCH = 100\n",
        "pre_epoch = 0\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.01\n",
        "n_classes = 4\n",
        "\n",
        "tensor_x_train = torch.Tensor(x_train) # transform to torch tensor\n",
        "tensor_y_train = torch.Tensor(y_train)\n",
        "my_train_dataset = data.TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
        "\n",
        "tensor_x_test = torch.Tensor(x_test)\n",
        "tensor_y_test = torch.Tensor(y_test)\n",
        "my_test_dataset = data.TensorDataset(tensor_x_test,tensor_y_test) # create your datset\n",
        "\n",
        "num_epochs = 500\n",
        "lr = 1e-2\n",
        "batch_size = 32\n",
        "\n",
        "trainloader = data.DataLoader(my_train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "testloader = data.DataLoader(my_test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(tensor_y_train[0:10])\n",
        "\n",
        "#labels in CIFAR10\n",
        "classes = ('0', '1', '2', '3')\n",
        "\n",
        "#define ResNet18\n",
        "net = ResNet18().to(device)\n",
        "\n",
        "#define loss funtion & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.mean()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRKzNbBczdyI",
        "outputId": "e1f5ef18-0761-4639-f16a-9872944e8939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7252620063491604"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ExEszj3Ro69",
        "outputId": "8b255ffe-9310-41e3-e015-5427c93aff15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1\n",
            "[epoch:1, iter:1] Loss: 2.458 | Acc: 0.000% \n",
            "[epoch:1, iter:2] Loss: 2.169 | Acc: 15.625% \n",
            "[epoch:1, iter:3] Loss: 2.055 | Acc: 15.625% \n",
            "[epoch:1, iter:4] Loss: 1.926 | Acc: 16.406% \n",
            "[epoch:1, iter:5] Loss: 1.854 | Acc: 17.500% \n",
            "[epoch:1, iter:6] Loss: 1.752 | Acc: 22.396% \n",
            "[epoch:1, iter:7] Loss: 1.697 | Acc: 24.554% \n",
            "[epoch:1, iter:8] Loss: 1.674 | Acc: 25.000% \n",
            "[epoch:1, iter:9] Loss: 1.649 | Acc: 25.694% \n",
            "[epoch:1, iter:10] Loss: 1.624 | Acc: 26.250% \n",
            "[epoch:1, iter:11] Loss: 1.618 | Acc: 27.841% \n",
            "[epoch:1, iter:12] Loss: 1.609 | Acc: 28.385% \n",
            "[epoch:1, iter:13] Loss: 1.601 | Acc: 27.644% \n",
            "[epoch:1, iter:14] Loss: 1.590 | Acc: 27.679% \n",
            "[epoch:1, iter:15] Loss: 1.574 | Acc: 27.292% \n",
            "[epoch:1, iter:16] Loss: 1.565 | Acc: 27.930% \n",
            "[epoch:1, iter:17] Loss: 1.558 | Acc: 29.228% \n",
            "[epoch:1, iter:18] Loss: 1.548 | Acc: 29.514% \n",
            "[epoch:1, iter:19] Loss: 1.561 | Acc: 29.112% \n",
            "[epoch:1, iter:20] Loss: 1.570 | Acc: 28.594% \n",
            "[epoch:1, iter:21] Loss: 1.572 | Acc: 28.125% \n",
            "[epoch:1, iter:22] Loss: 1.571 | Acc: 28.551% \n",
            "[epoch:1, iter:23] Loss: 1.569 | Acc: 28.940% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.121%\n",
            "\n",
            "Epoch: 2\n",
            "[epoch:2, iter:24] Loss: 1.409 | Acc: 25.000% \n",
            "[epoch:2, iter:25] Loss: 1.466 | Acc: 34.375% \n",
            "[epoch:2, iter:26] Loss: 1.510 | Acc: 32.292% \n",
            "[epoch:2, iter:27] Loss: 1.484 | Acc: 30.469% \n",
            "[epoch:2, iter:28] Loss: 1.478 | Acc: 34.375% \n",
            "[epoch:2, iter:29] Loss: 1.563 | Acc: 31.771% \n",
            "[epoch:2, iter:30] Loss: 1.564 | Acc: 30.804% \n",
            "[epoch:2, iter:31] Loss: 1.538 | Acc: 31.641% \n",
            "[epoch:2, iter:32] Loss: 1.615 | Acc: 30.556% \n",
            "[epoch:2, iter:33] Loss: 1.612 | Acc: 29.688% \n",
            "[epoch:2, iter:34] Loss: 1.591 | Acc: 30.682% \n",
            "[epoch:2, iter:35] Loss: 1.640 | Acc: 30.208% \n",
            "[epoch:2, iter:36] Loss: 1.635 | Acc: 30.769% \n",
            "[epoch:2, iter:37] Loss: 1.670 | Acc: 29.911% \n",
            "[epoch:2, iter:38] Loss: 1.650 | Acc: 30.000% \n",
            "[epoch:2, iter:39] Loss: 1.645 | Acc: 30.273% \n",
            "[epoch:2, iter:40] Loss: 1.646 | Acc: 30.331% \n",
            "[epoch:2, iter:41] Loss: 1.656 | Acc: 29.861% \n",
            "[epoch:2, iter:42] Loss: 1.651 | Acc: 30.428% \n",
            "[epoch:2, iter:43] Loss: 1.650 | Acc: 30.469% \n",
            "[epoch:2, iter:44] Loss: 1.640 | Acc: 30.506% \n",
            "[epoch:2, iter:45] Loss: 1.633 | Acc: 29.972% \n",
            "[epoch:2, iter:46] Loss: 1.626 | Acc: 29.891% \n",
            "Waiting Test...\n",
            "Test's ac is: 23.485%\n",
            "\n",
            "Epoch: 3\n",
            "[epoch:3, iter:47] Loss: 1.439 | Acc: 25.000% \n",
            "[epoch:3, iter:48] Loss: 1.438 | Acc: 25.000% \n",
            "[epoch:3, iter:49] Loss: 1.432 | Acc: 29.167% \n",
            "[epoch:3, iter:50] Loss: 1.469 | Acc: 28.125% \n",
            "[epoch:3, iter:51] Loss: 1.437 | Acc: 30.000% \n",
            "[epoch:3, iter:52] Loss: 1.426 | Acc: 30.208% \n",
            "[epoch:3, iter:53] Loss: 1.423 | Acc: 29.911% \n",
            "[epoch:3, iter:54] Loss: 1.411 | Acc: 32.031% \n",
            "[epoch:3, iter:55] Loss: 1.404 | Acc: 31.944% \n",
            "[epoch:3, iter:56] Loss: 1.392 | Acc: 32.812% \n",
            "[epoch:3, iter:57] Loss: 1.405 | Acc: 32.102% \n",
            "[epoch:3, iter:58] Loss: 1.409 | Acc: 32.031% \n",
            "[epoch:3, iter:59] Loss: 1.398 | Acc: 32.452% \n",
            "[epoch:3, iter:60] Loss: 1.400 | Acc: 32.589% \n",
            "[epoch:3, iter:61] Loss: 1.410 | Acc: 31.667% \n",
            "[epoch:3, iter:62] Loss: 1.406 | Acc: 31.836% \n",
            "[epoch:3, iter:63] Loss: 1.411 | Acc: 31.801% \n",
            "[epoch:3, iter:64] Loss: 1.412 | Acc: 31.424% \n",
            "[epoch:3, iter:65] Loss: 1.416 | Acc: 30.921% \n",
            "[epoch:3, iter:66] Loss: 1.411 | Acc: 32.031% \n",
            "[epoch:3, iter:67] Loss: 1.417 | Acc: 31.994% \n",
            "[epoch:3, iter:68] Loss: 1.421 | Acc: 32.244% \n",
            "[epoch:3, iter:69] Loss: 1.420 | Acc: 32.609% \n",
            "Waiting Test...\n",
            "Test's ac is: 27.273%\n",
            "\n",
            "Epoch: 4\n",
            "[epoch:4, iter:70] Loss: 1.485 | Acc: 18.750% \n",
            "[epoch:4, iter:71] Loss: 1.380 | Acc: 28.125% \n",
            "[epoch:4, iter:72] Loss: 1.379 | Acc: 30.208% \n",
            "[epoch:4, iter:73] Loss: 1.386 | Acc: 28.125% \n",
            "[epoch:4, iter:74] Loss: 1.429 | Acc: 25.625% \n",
            "[epoch:4, iter:75] Loss: 1.408 | Acc: 28.646% \n",
            "[epoch:4, iter:76] Loss: 1.399 | Acc: 27.232% \n",
            "[epoch:4, iter:77] Loss: 1.382 | Acc: 28.516% \n",
            "[epoch:4, iter:78] Loss: 1.359 | Acc: 32.292% \n",
            "[epoch:4, iter:79] Loss: 1.355 | Acc: 33.438% \n",
            "[epoch:4, iter:80] Loss: 1.350 | Acc: 34.375% \n",
            "[epoch:4, iter:81] Loss: 1.339 | Acc: 34.375% \n",
            "[epoch:4, iter:82] Loss: 1.342 | Acc: 33.894% \n",
            "[epoch:4, iter:83] Loss: 1.346 | Acc: 34.598% \n",
            "[epoch:4, iter:84] Loss: 1.346 | Acc: 34.792% \n",
            "[epoch:4, iter:85] Loss: 1.342 | Acc: 35.547% \n",
            "[epoch:4, iter:86] Loss: 1.352 | Acc: 35.294% \n",
            "[epoch:4, iter:87] Loss: 1.340 | Acc: 36.458% \n",
            "[epoch:4, iter:88] Loss: 1.337 | Acc: 36.842% \n",
            "[epoch:4, iter:89] Loss: 1.344 | Acc: 36.562% \n",
            "[epoch:4, iter:90] Loss: 1.341 | Acc: 37.351% \n",
            "[epoch:4, iter:91] Loss: 1.341 | Acc: 37.216% \n",
            "[epoch:4, iter:92] Loss: 1.346 | Acc: 36.957% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 5\n",
            "[epoch:5, iter:93] Loss: 1.287 | Acc: 28.125% \n",
            "[epoch:5, iter:94] Loss: 1.260 | Acc: 39.062% \n",
            "[epoch:5, iter:95] Loss: 1.263 | Acc: 37.500% \n",
            "[epoch:5, iter:96] Loss: 1.226 | Acc: 39.062% \n",
            "[epoch:5, iter:97] Loss: 1.260 | Acc: 38.125% \n",
            "[epoch:5, iter:98] Loss: 1.306 | Acc: 36.458% \n",
            "[epoch:5, iter:99] Loss: 1.310 | Acc: 35.714% \n",
            "[epoch:5, iter:100] Loss: 1.292 | Acc: 37.891% \n",
            "[epoch:5, iter:101] Loss: 1.290 | Acc: 38.194% \n",
            "[epoch:5, iter:102] Loss: 1.300 | Acc: 37.500% \n",
            "[epoch:5, iter:103] Loss: 1.295 | Acc: 38.920% \n",
            "[epoch:5, iter:104] Loss: 1.311 | Acc: 39.323% \n",
            "[epoch:5, iter:105] Loss: 1.345 | Acc: 38.221% \n",
            "[epoch:5, iter:106] Loss: 1.345 | Acc: 37.723% \n",
            "[epoch:5, iter:107] Loss: 1.338 | Acc: 38.125% \n",
            "[epoch:5, iter:108] Loss: 1.344 | Acc: 37.695% \n",
            "[epoch:5, iter:109] Loss: 1.341 | Acc: 38.603% \n",
            "[epoch:5, iter:110] Loss: 1.344 | Acc: 38.021% \n",
            "[epoch:5, iter:111] Loss: 1.337 | Acc: 37.993% \n",
            "[epoch:5, iter:112] Loss: 1.335 | Acc: 37.969% \n",
            "[epoch:5, iter:113] Loss: 1.338 | Acc: 37.500% \n",
            "[epoch:5, iter:114] Loss: 1.348 | Acc: 37.358% \n",
            "[epoch:5, iter:115] Loss: 1.356 | Acc: 36.821% \n",
            "Waiting Test...\n",
            "Test's ac is: 25.000%\n",
            "\n",
            "Epoch: 6\n",
            "[epoch:6, iter:116] Loss: 1.338 | Acc: 37.500% \n",
            "[epoch:6, iter:117] Loss: 1.414 | Acc: 37.500% \n",
            "[epoch:6, iter:118] Loss: 1.411 | Acc: 33.333% \n",
            "[epoch:6, iter:119] Loss: 1.356 | Acc: 36.719% \n",
            "[epoch:6, iter:120] Loss: 1.357 | Acc: 34.375% \n",
            "[epoch:6, iter:121] Loss: 1.327 | Acc: 36.458% \n",
            "[epoch:6, iter:122] Loss: 1.327 | Acc: 37.054% \n",
            "[epoch:6, iter:123] Loss: 1.320 | Acc: 37.891% \n",
            "[epoch:6, iter:124] Loss: 1.320 | Acc: 37.847% \n",
            "[epoch:6, iter:125] Loss: 1.327 | Acc: 36.562% \n",
            "[epoch:6, iter:126] Loss: 1.326 | Acc: 37.216% \n",
            "[epoch:6, iter:127] Loss: 1.326 | Acc: 36.719% \n",
            "[epoch:6, iter:128] Loss: 1.325 | Acc: 36.058% \n",
            "[epoch:6, iter:129] Loss: 1.325 | Acc: 35.491% \n",
            "[epoch:6, iter:130] Loss: 1.326 | Acc: 35.625% \n",
            "[epoch:6, iter:131] Loss: 1.318 | Acc: 36.523% \n",
            "[epoch:6, iter:132] Loss: 1.313 | Acc: 36.581% \n",
            "[epoch:6, iter:133] Loss: 1.327 | Acc: 36.111% \n",
            "[epoch:6, iter:134] Loss: 1.320 | Acc: 37.007% \n",
            "[epoch:6, iter:135] Loss: 1.315 | Acc: 37.031% \n",
            "[epoch:6, iter:136] Loss: 1.321 | Acc: 36.607% \n",
            "[epoch:6, iter:137] Loss: 1.309 | Acc: 37.642% \n",
            "[epoch:6, iter:138] Loss: 1.311 | Acc: 37.636% \n",
            "Waiting Test...\n",
            "Test's ac is: 30.303%\n",
            "\n",
            "Epoch: 7\n",
            "[epoch:7, iter:139] Loss: 1.224 | Acc: 50.000% \n",
            "[epoch:7, iter:140] Loss: 1.288 | Acc: 40.625% \n",
            "[epoch:7, iter:141] Loss: 1.355 | Acc: 37.500% \n",
            "[epoch:7, iter:142] Loss: 1.308 | Acc: 38.281% \n",
            "[epoch:7, iter:143] Loss: 1.269 | Acc: 42.500% \n",
            "[epoch:7, iter:144] Loss: 1.258 | Acc: 41.667% \n",
            "[epoch:7, iter:145] Loss: 1.268 | Acc: 40.625% \n",
            "[epoch:7, iter:146] Loss: 1.274 | Acc: 40.625% \n",
            "[epoch:7, iter:147] Loss: 1.284 | Acc: 40.278% \n",
            "[epoch:7, iter:148] Loss: 1.279 | Acc: 40.625% \n",
            "[epoch:7, iter:149] Loss: 1.275 | Acc: 40.909% \n",
            "[epoch:7, iter:150] Loss: 1.280 | Acc: 40.625% \n",
            "[epoch:7, iter:151] Loss: 1.282 | Acc: 40.865% \n",
            "[epoch:7, iter:152] Loss: 1.290 | Acc: 40.179% \n",
            "[epoch:7, iter:153] Loss: 1.295 | Acc: 39.792% \n",
            "[epoch:7, iter:154] Loss: 1.301 | Acc: 40.234% \n",
            "[epoch:7, iter:155] Loss: 1.293 | Acc: 40.625% \n",
            "[epoch:7, iter:156] Loss: 1.289 | Acc: 41.319% \n",
            "[epoch:7, iter:157] Loss: 1.285 | Acc: 41.612% \n",
            "[epoch:7, iter:158] Loss: 1.290 | Acc: 41.406% \n",
            "[epoch:7, iter:159] Loss: 1.284 | Acc: 42.113% \n",
            "[epoch:7, iter:160] Loss: 1.281 | Acc: 41.761% \n",
            "[epoch:7, iter:161] Loss: 1.281 | Acc: 41.712% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.030%\n",
            "\n",
            "Epoch: 8\n",
            "[epoch:8, iter:162] Loss: 1.217 | Acc: 53.125% \n",
            "[epoch:8, iter:163] Loss: 1.194 | Acc: 51.562% \n",
            "[epoch:8, iter:164] Loss: 1.255 | Acc: 45.833% \n",
            "[epoch:8, iter:165] Loss: 1.266 | Acc: 41.406% \n",
            "[epoch:8, iter:166] Loss: 1.288 | Acc: 41.250% \n",
            "[epoch:8, iter:167] Loss: 1.275 | Acc: 42.188% \n",
            "[epoch:8, iter:168] Loss: 1.265 | Acc: 41.964% \n",
            "[epoch:8, iter:169] Loss: 1.278 | Acc: 41.016% \n",
            "[epoch:8, iter:170] Loss: 1.274 | Acc: 42.014% \n",
            "[epoch:8, iter:171] Loss: 1.290 | Acc: 41.562% \n",
            "[epoch:8, iter:172] Loss: 1.288 | Acc: 41.477% \n",
            "[epoch:8, iter:173] Loss: 1.283 | Acc: 41.927% \n",
            "[epoch:8, iter:174] Loss: 1.290 | Acc: 41.346% \n",
            "[epoch:8, iter:175] Loss: 1.293 | Acc: 40.848% \n",
            "[epoch:8, iter:176] Loss: 1.298 | Acc: 40.833% \n",
            "[epoch:8, iter:177] Loss: 1.302 | Acc: 40.039% \n",
            "[epoch:8, iter:178] Loss: 1.306 | Acc: 40.257% \n",
            "[epoch:8, iter:179] Loss: 1.300 | Acc: 40.451% \n",
            "[epoch:8, iter:180] Loss: 1.296 | Acc: 40.132% \n",
            "[epoch:8, iter:181] Loss: 1.285 | Acc: 41.094% \n",
            "[epoch:8, iter:182] Loss: 1.288 | Acc: 40.923% \n",
            "[epoch:8, iter:183] Loss: 1.286 | Acc: 40.909% \n",
            "[epoch:8, iter:184] Loss: 1.286 | Acc: 41.033% \n",
            "Waiting Test...\n",
            "Test's ac is: 29.545%\n",
            "\n",
            "Epoch: 9\n",
            "[epoch:9, iter:185] Loss: 1.325 | Acc: 37.500% \n",
            "[epoch:9, iter:186] Loss: 1.226 | Acc: 46.875% \n",
            "[epoch:9, iter:187] Loss: 1.210 | Acc: 45.833% \n",
            "[epoch:9, iter:188] Loss: 1.189 | Acc: 44.531% \n",
            "[epoch:9, iter:189] Loss: 1.181 | Acc: 45.625% \n",
            "[epoch:9, iter:190] Loss: 1.171 | Acc: 47.917% \n",
            "[epoch:9, iter:191] Loss: 1.220 | Acc: 47.321% \n",
            "[epoch:9, iter:192] Loss: 1.194 | Acc: 48.047% \n",
            "[epoch:9, iter:193] Loss: 1.194 | Acc: 47.222% \n",
            "[epoch:9, iter:194] Loss: 1.198 | Acc: 46.875% \n",
            "[epoch:9, iter:195] Loss: 1.220 | Acc: 45.739% \n",
            "[epoch:9, iter:196] Loss: 1.240 | Acc: 44.531% \n",
            "[epoch:9, iter:197] Loss: 1.245 | Acc: 44.712% \n",
            "[epoch:9, iter:198] Loss: 1.265 | Acc: 43.973% \n",
            "[epoch:9, iter:199] Loss: 1.259 | Acc: 44.167% \n",
            "[epoch:9, iter:200] Loss: 1.273 | Acc: 44.141% \n",
            "[epoch:9, iter:201] Loss: 1.262 | Acc: 44.669% \n",
            "[epoch:9, iter:202] Loss: 1.280 | Acc: 43.750% \n",
            "[epoch:9, iter:203] Loss: 1.284 | Acc: 43.421% \n",
            "[epoch:9, iter:204] Loss: 1.294 | Acc: 42.969% \n",
            "[epoch:9, iter:205] Loss: 1.298 | Acc: 42.708% \n",
            "[epoch:9, iter:206] Loss: 1.303 | Acc: 42.188% \n",
            "[epoch:9, iter:207] Loss: 1.299 | Acc: 42.527% \n",
            "Waiting Test...\n",
            "Test's ac is: 33.333%\n",
            "\n",
            "Epoch: 10\n",
            "[epoch:10, iter:208] Loss: 1.282 | Acc: 37.500% \n",
            "[epoch:10, iter:209] Loss: 1.354 | Acc: 32.812% \n",
            "[epoch:10, iter:210] Loss: 1.307 | Acc: 30.208% \n",
            "[epoch:10, iter:211] Loss: 1.307 | Acc: 29.688% \n",
            "[epoch:10, iter:212] Loss: 1.295 | Acc: 32.500% \n",
            "[epoch:10, iter:213] Loss: 1.265 | Acc: 35.938% \n",
            "[epoch:10, iter:214] Loss: 1.253 | Acc: 37.054% \n",
            "[epoch:10, iter:215] Loss: 1.241 | Acc: 38.672% \n",
            "[epoch:10, iter:216] Loss: 1.233 | Acc: 40.625% \n",
            "[epoch:10, iter:217] Loss: 1.233 | Acc: 41.250% \n",
            "[epoch:10, iter:218] Loss: 1.232 | Acc: 42.045% \n",
            "[epoch:10, iter:219] Loss: 1.243 | Acc: 41.667% \n",
            "[epoch:10, iter:220] Loss: 1.243 | Acc: 42.788% \n",
            "[epoch:10, iter:221] Loss: 1.270 | Acc: 42.188% \n",
            "[epoch:10, iter:222] Loss: 1.263 | Acc: 42.500% \n",
            "[epoch:10, iter:223] Loss: 1.274 | Acc: 41.992% \n",
            "[epoch:10, iter:224] Loss: 1.284 | Acc: 41.728% \n",
            "[epoch:10, iter:225] Loss: 1.287 | Acc: 41.493% \n",
            "[epoch:10, iter:226] Loss: 1.287 | Acc: 40.625% \n",
            "[epoch:10, iter:227] Loss: 1.289 | Acc: 40.781% \n",
            "[epoch:10, iter:228] Loss: 1.281 | Acc: 41.220% \n",
            "[epoch:10, iter:229] Loss: 1.276 | Acc: 41.335% \n",
            "[epoch:10, iter:230] Loss: 1.283 | Acc: 41.033% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 11\n",
            "[epoch:11, iter:231] Loss: 1.290 | Acc: 34.375% \n",
            "[epoch:11, iter:232] Loss: 1.281 | Acc: 37.500% \n",
            "[epoch:11, iter:233] Loss: 1.275 | Acc: 38.542% \n",
            "[epoch:11, iter:234] Loss: 1.232 | Acc: 43.750% \n",
            "[epoch:11, iter:235] Loss: 1.214 | Acc: 45.000% \n",
            "[epoch:11, iter:236] Loss: 1.228 | Acc: 44.271% \n",
            "[epoch:11, iter:237] Loss: 1.237 | Acc: 43.304% \n",
            "[epoch:11, iter:238] Loss: 1.224 | Acc: 45.312% \n",
            "[epoch:11, iter:239] Loss: 1.203 | Acc: 47.569% \n",
            "[epoch:11, iter:240] Loss: 1.182 | Acc: 49.375% \n",
            "[epoch:11, iter:241] Loss: 1.165 | Acc: 50.284% \n",
            "[epoch:11, iter:242] Loss: 1.167 | Acc: 50.260% \n",
            "[epoch:11, iter:243] Loss: 1.193 | Acc: 48.798% \n",
            "[epoch:11, iter:244] Loss: 1.196 | Acc: 49.107% \n",
            "[epoch:11, iter:245] Loss: 1.183 | Acc: 48.958% \n",
            "[epoch:11, iter:246] Loss: 1.190 | Acc: 48.633% \n",
            "[epoch:11, iter:247] Loss: 1.182 | Acc: 49.081% \n",
            "[epoch:11, iter:248] Loss: 1.183 | Acc: 48.785% \n",
            "[epoch:11, iter:249] Loss: 1.183 | Acc: 48.849% \n",
            "[epoch:11, iter:250] Loss: 1.191 | Acc: 48.125% \n",
            "[epoch:11, iter:251] Loss: 1.206 | Acc: 47.173% \n",
            "[epoch:11, iter:252] Loss: 1.212 | Acc: 46.449% \n",
            "[epoch:11, iter:253] Loss: 1.207 | Acc: 46.739% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.030%\n",
            "\n",
            "Epoch: 12\n",
            "[epoch:12, iter:254] Loss: 1.121 | Acc: 37.500% \n",
            "[epoch:12, iter:255] Loss: 1.228 | Acc: 37.500% \n",
            "[epoch:12, iter:256] Loss: 1.206 | Acc: 39.583% \n",
            "[epoch:12, iter:257] Loss: 1.200 | Acc: 39.062% \n",
            "[epoch:12, iter:258] Loss: 1.221 | Acc: 38.125% \n",
            "[epoch:12, iter:259] Loss: 1.228 | Acc: 39.062% \n",
            "[epoch:12, iter:260] Loss: 1.206 | Acc: 41.071% \n",
            "[epoch:12, iter:261] Loss: 1.226 | Acc: 40.625% \n",
            "[epoch:12, iter:262] Loss: 1.218 | Acc: 42.014% \n",
            "[epoch:12, iter:263] Loss: 1.215 | Acc: 41.875% \n",
            "[epoch:12, iter:264] Loss: 1.207 | Acc: 42.330% \n",
            "[epoch:12, iter:265] Loss: 1.212 | Acc: 42.969% \n",
            "[epoch:12, iter:266] Loss: 1.205 | Acc: 43.029% \n",
            "[epoch:12, iter:267] Loss: 1.195 | Acc: 43.304% \n",
            "[epoch:12, iter:268] Loss: 1.210 | Acc: 43.542% \n",
            "[epoch:12, iter:269] Loss: 1.215 | Acc: 43.750% \n",
            "[epoch:12, iter:270] Loss: 1.204 | Acc: 44.853% \n",
            "[epoch:12, iter:271] Loss: 1.205 | Acc: 44.965% \n",
            "[epoch:12, iter:272] Loss: 1.209 | Acc: 44.901% \n",
            "[epoch:12, iter:273] Loss: 1.209 | Acc: 45.000% \n",
            "[epoch:12, iter:274] Loss: 1.213 | Acc: 45.089% \n",
            "[epoch:12, iter:275] Loss: 1.218 | Acc: 45.028% \n",
            "[epoch:12, iter:276] Loss: 1.220 | Acc: 44.701% \n",
            "Waiting Test...\n",
            "Test's ac is: 29.545%\n",
            "\n",
            "Epoch: 13\n",
            "[epoch:13, iter:277] Loss: 1.238 | Acc: 37.500% \n",
            "[epoch:13, iter:278] Loss: 1.187 | Acc: 45.312% \n",
            "[epoch:13, iter:279] Loss: 1.260 | Acc: 44.792% \n",
            "[epoch:13, iter:280] Loss: 1.267 | Acc: 42.188% \n",
            "[epoch:13, iter:281] Loss: 1.279 | Acc: 41.875% \n",
            "[epoch:13, iter:282] Loss: 1.260 | Acc: 43.750% \n",
            "[epoch:13, iter:283] Loss: 1.235 | Acc: 46.429% \n",
            "[epoch:13, iter:284] Loss: 1.253 | Acc: 44.141% \n",
            "[epoch:13, iter:285] Loss: 1.268 | Acc: 43.403% \n",
            "[epoch:13, iter:286] Loss: 1.252 | Acc: 45.312% \n",
            "[epoch:13, iter:287] Loss: 1.245 | Acc: 46.023% \n",
            "[epoch:13, iter:288] Loss: 1.249 | Acc: 44.792% \n",
            "[epoch:13, iter:289] Loss: 1.248 | Acc: 44.471% \n",
            "[epoch:13, iter:290] Loss: 1.250 | Acc: 43.973% \n",
            "[epoch:13, iter:291] Loss: 1.251 | Acc: 43.750% \n",
            "[epoch:13, iter:292] Loss: 1.257 | Acc: 43.555% \n",
            "[epoch:13, iter:293] Loss: 1.266 | Acc: 43.015% \n",
            "[epoch:13, iter:294] Loss: 1.283 | Acc: 42.361% \n",
            "[epoch:13, iter:295] Loss: 1.287 | Acc: 42.270% \n",
            "[epoch:13, iter:296] Loss: 1.283 | Acc: 42.344% \n",
            "[epoch:13, iter:297] Loss: 1.274 | Acc: 42.560% \n",
            "[epoch:13, iter:298] Loss: 1.277 | Acc: 42.330% \n",
            "[epoch:13, iter:299] Loss: 1.276 | Acc: 42.527% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 14\n",
            "[epoch:14, iter:300] Loss: 1.426 | Acc: 43.750% \n",
            "[epoch:14, iter:301] Loss: 1.447 | Acc: 39.062% \n",
            "[epoch:14, iter:302] Loss: 1.299 | Acc: 45.833% \n",
            "[epoch:14, iter:303] Loss: 1.249 | Acc: 48.438% \n",
            "[epoch:14, iter:304] Loss: 1.245 | Acc: 48.750% \n",
            "[epoch:14, iter:305] Loss: 1.249 | Acc: 47.917% \n",
            "[epoch:14, iter:306] Loss: 1.240 | Acc: 47.768% \n",
            "[epoch:14, iter:307] Loss: 1.225 | Acc: 47.656% \n",
            "[epoch:14, iter:308] Loss: 1.218 | Acc: 46.875% \n",
            "[epoch:14, iter:309] Loss: 1.205 | Acc: 48.125% \n",
            "[epoch:14, iter:310] Loss: 1.214 | Acc: 47.443% \n",
            "[epoch:14, iter:311] Loss: 1.201 | Acc: 47.135% \n",
            "[epoch:14, iter:312] Loss: 1.205 | Acc: 46.635% \n",
            "[epoch:14, iter:313] Loss: 1.209 | Acc: 46.205% \n",
            "[epoch:14, iter:314] Loss: 1.206 | Acc: 46.042% \n",
            "[epoch:14, iter:315] Loss: 1.206 | Acc: 45.898% \n",
            "[epoch:14, iter:316] Loss: 1.221 | Acc: 45.037% \n",
            "[epoch:14, iter:317] Loss: 1.225 | Acc: 45.486% \n",
            "[epoch:14, iter:318] Loss: 1.234 | Acc: 45.559% \n",
            "[epoch:14, iter:319] Loss: 1.240 | Acc: 44.844% \n",
            "[epoch:14, iter:320] Loss: 1.234 | Acc: 45.238% \n",
            "[epoch:14, iter:321] Loss: 1.242 | Acc: 44.034% \n",
            "[epoch:14, iter:322] Loss: 1.240 | Acc: 43.750% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.030%\n",
            "\n",
            "Epoch: 15\n",
            "[epoch:15, iter:323] Loss: 1.175 | Acc: 50.000% \n",
            "[epoch:15, iter:324] Loss: 1.233 | Acc: 43.750% \n",
            "[epoch:15, iter:325] Loss: 1.228 | Acc: 42.708% \n",
            "[epoch:15, iter:326] Loss: 1.188 | Acc: 45.312% \n",
            "[epoch:15, iter:327] Loss: 1.211 | Acc: 45.000% \n",
            "[epoch:15, iter:328] Loss: 1.222 | Acc: 43.229% \n",
            "[epoch:15, iter:329] Loss: 1.240 | Acc: 43.304% \n",
            "[epoch:15, iter:330] Loss: 1.227 | Acc: 44.531% \n",
            "[epoch:15, iter:331] Loss: 1.207 | Acc: 46.181% \n",
            "[epoch:15, iter:332] Loss: 1.194 | Acc: 47.500% \n",
            "[epoch:15, iter:333] Loss: 1.181 | Acc: 49.148% \n",
            "[epoch:15, iter:334] Loss: 1.192 | Acc: 48.958% \n",
            "[epoch:15, iter:335] Loss: 1.200 | Acc: 48.798% \n",
            "[epoch:15, iter:336] Loss: 1.204 | Acc: 48.438% \n",
            "[epoch:15, iter:337] Loss: 1.217 | Acc: 47.708% \n",
            "[epoch:15, iter:338] Loss: 1.227 | Acc: 46.875% \n",
            "[epoch:15, iter:339] Loss: 1.229 | Acc: 46.324% \n",
            "[epoch:15, iter:340] Loss: 1.232 | Acc: 46.528% \n",
            "[epoch:15, iter:341] Loss: 1.246 | Acc: 45.724% \n",
            "[epoch:15, iter:342] Loss: 1.239 | Acc: 45.938% \n",
            "[epoch:15, iter:343] Loss: 1.232 | Acc: 45.833% \n",
            "[epoch:15, iter:344] Loss: 1.216 | Acc: 46.875% \n",
            "[epoch:15, iter:345] Loss: 1.220 | Acc: 46.332% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 16\n",
            "[epoch:16, iter:346] Loss: 1.227 | Acc: 53.125% \n",
            "[epoch:16, iter:347] Loss: 1.186 | Acc: 50.000% \n",
            "[epoch:16, iter:348] Loss: 1.188 | Acc: 46.875% \n",
            "[epoch:16, iter:349] Loss: 1.270 | Acc: 43.750% \n",
            "[epoch:16, iter:350] Loss: 1.209 | Acc: 46.250% \n",
            "[epoch:16, iter:351] Loss: 1.227 | Acc: 45.312% \n",
            "[epoch:16, iter:352] Loss: 1.224 | Acc: 44.196% \n",
            "[epoch:16, iter:353] Loss: 1.195 | Acc: 46.484% \n",
            "[epoch:16, iter:354] Loss: 1.185 | Acc: 47.569% \n",
            "[epoch:16, iter:355] Loss: 1.210 | Acc: 47.500% \n",
            "[epoch:16, iter:356] Loss: 1.211 | Acc: 46.875% \n",
            "[epoch:16, iter:357] Loss: 1.209 | Acc: 47.135% \n",
            "[epoch:16, iter:358] Loss: 1.202 | Acc: 46.875% \n",
            "[epoch:16, iter:359] Loss: 1.204 | Acc: 46.652% \n",
            "[epoch:16, iter:360] Loss: 1.205 | Acc: 46.458% \n",
            "[epoch:16, iter:361] Loss: 1.206 | Acc: 46.094% \n",
            "[epoch:16, iter:362] Loss: 1.211 | Acc: 46.140% \n",
            "[epoch:16, iter:363] Loss: 1.210 | Acc: 46.181% \n",
            "[epoch:16, iter:364] Loss: 1.207 | Acc: 46.053% \n",
            "[epoch:16, iter:365] Loss: 1.204 | Acc: 45.938% \n",
            "[epoch:16, iter:366] Loss: 1.199 | Acc: 46.131% \n",
            "[epoch:16, iter:367] Loss: 1.201 | Acc: 45.881% \n",
            "[epoch:16, iter:368] Loss: 1.200 | Acc: 45.652% \n",
            "Waiting Test...\n",
            "Test's ac is: 41.667%\n",
            "\n",
            "Epoch: 17\n",
            "[epoch:17, iter:369] Loss: 0.957 | Acc: 56.250% \n",
            "[epoch:17, iter:370] Loss: 1.137 | Acc: 43.750% \n",
            "[epoch:17, iter:371] Loss: 1.255 | Acc: 35.417% \n",
            "[epoch:17, iter:372] Loss: 1.198 | Acc: 42.969% \n",
            "[epoch:17, iter:373] Loss: 1.217 | Acc: 42.500% \n",
            "[epoch:17, iter:374] Loss: 1.222 | Acc: 43.750% \n",
            "[epoch:17, iter:375] Loss: 1.207 | Acc: 44.643% \n",
            "[epoch:17, iter:376] Loss: 1.224 | Acc: 42.578% \n",
            "[epoch:17, iter:377] Loss: 1.228 | Acc: 43.056% \n",
            "[epoch:17, iter:378] Loss: 1.239 | Acc: 42.188% \n",
            "[epoch:17, iter:379] Loss: 1.244 | Acc: 42.045% \n",
            "[epoch:17, iter:380] Loss: 1.236 | Acc: 42.708% \n",
            "[epoch:17, iter:381] Loss: 1.236 | Acc: 42.548% \n",
            "[epoch:17, iter:382] Loss: 1.218 | Acc: 43.304% \n",
            "[epoch:17, iter:383] Loss: 1.234 | Acc: 43.750% \n",
            "[epoch:17, iter:384] Loss: 1.234 | Acc: 43.750% \n",
            "[epoch:17, iter:385] Loss: 1.249 | Acc: 43.382% \n",
            "[epoch:17, iter:386] Loss: 1.238 | Acc: 43.924% \n",
            "[epoch:17, iter:387] Loss: 1.232 | Acc: 43.914% \n",
            "[epoch:17, iter:388] Loss: 1.222 | Acc: 44.531% \n",
            "[epoch:17, iter:389] Loss: 1.219 | Acc: 44.792% \n",
            "[epoch:17, iter:390] Loss: 1.217 | Acc: 44.744% \n",
            "[epoch:17, iter:391] Loss: 1.228 | Acc: 43.886% \n",
            "Waiting Test...\n",
            "Test's ac is: 32.576%\n",
            "\n",
            "Epoch: 18\n",
            "[epoch:18, iter:392] Loss: 1.437 | Acc: 28.125% \n",
            "[epoch:18, iter:393] Loss: 1.369 | Acc: 34.375% \n",
            "[epoch:18, iter:394] Loss: 1.389 | Acc: 34.375% \n",
            "[epoch:18, iter:395] Loss: 1.296 | Acc: 39.844% \n",
            "[epoch:18, iter:396] Loss: 1.313 | Acc: 39.375% \n",
            "[epoch:18, iter:397] Loss: 1.270 | Acc: 42.188% \n",
            "[epoch:18, iter:398] Loss: 1.262 | Acc: 44.196% \n",
            "[epoch:18, iter:399] Loss: 1.250 | Acc: 45.312% \n",
            "[epoch:18, iter:400] Loss: 1.281 | Acc: 44.792% \n",
            "[epoch:18, iter:401] Loss: 1.297 | Acc: 44.375% \n",
            "[epoch:18, iter:402] Loss: 1.288 | Acc: 44.034% \n",
            "[epoch:18, iter:403] Loss: 1.285 | Acc: 44.010% \n",
            "[epoch:18, iter:404] Loss: 1.292 | Acc: 43.990% \n",
            "[epoch:18, iter:405] Loss: 1.287 | Acc: 44.196% \n",
            "[epoch:18, iter:406] Loss: 1.279 | Acc: 44.792% \n",
            "[epoch:18, iter:407] Loss: 1.276 | Acc: 45.117% \n",
            "[epoch:18, iter:408] Loss: 1.266 | Acc: 46.140% \n",
            "[epoch:18, iter:409] Loss: 1.270 | Acc: 45.312% \n",
            "[epoch:18, iter:410] Loss: 1.267 | Acc: 45.559% \n",
            "[epoch:18, iter:411] Loss: 1.263 | Acc: 45.469% \n",
            "[epoch:18, iter:412] Loss: 1.264 | Acc: 45.238% \n",
            "[epoch:18, iter:413] Loss: 1.261 | Acc: 45.028% \n",
            "[epoch:18, iter:414] Loss: 1.253 | Acc: 45.245% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 19\n",
            "[epoch:19, iter:415] Loss: 0.972 | Acc: 53.125% \n",
            "[epoch:19, iter:416] Loss: 1.050 | Acc: 51.562% \n",
            "[epoch:19, iter:417] Loss: 1.074 | Acc: 52.083% \n",
            "[epoch:19, iter:418] Loss: 1.122 | Acc: 50.781% \n",
            "[epoch:19, iter:419] Loss: 1.135 | Acc: 49.375% \n",
            "[epoch:19, iter:420] Loss: 1.142 | Acc: 50.000% \n",
            "[epoch:19, iter:421] Loss: 1.132 | Acc: 50.446% \n",
            "[epoch:19, iter:422] Loss: 1.147 | Acc: 49.609% \n",
            "[epoch:19, iter:423] Loss: 1.154 | Acc: 48.264% \n",
            "[epoch:19, iter:424] Loss: 1.146 | Acc: 48.750% \n",
            "[epoch:19, iter:425] Loss: 1.140 | Acc: 50.000% \n",
            "[epoch:19, iter:426] Loss: 1.129 | Acc: 50.781% \n",
            "[epoch:19, iter:427] Loss: 1.152 | Acc: 50.240% \n",
            "[epoch:19, iter:428] Loss: 1.157 | Acc: 49.777% \n",
            "[epoch:19, iter:429] Loss: 1.155 | Acc: 50.417% \n",
            "[epoch:19, iter:430] Loss: 1.159 | Acc: 50.586% \n",
            "[epoch:19, iter:431] Loss: 1.160 | Acc: 50.184% \n",
            "[epoch:19, iter:432] Loss: 1.166 | Acc: 49.653% \n",
            "[epoch:19, iter:433] Loss: 1.164 | Acc: 49.671% \n",
            "[epoch:19, iter:434] Loss: 1.162 | Acc: 49.844% \n",
            "[epoch:19, iter:435] Loss: 1.168 | Acc: 49.405% \n",
            "[epoch:19, iter:436] Loss: 1.165 | Acc: 49.716% \n",
            "[epoch:19, iter:437] Loss: 1.171 | Acc: 50.000% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.818%\n",
            "\n",
            "Epoch: 20\n",
            "[epoch:20, iter:438] Loss: 1.127 | Acc: 43.750% \n",
            "[epoch:20, iter:439] Loss: 1.090 | Acc: 48.438% \n",
            "[epoch:20, iter:440] Loss: 1.084 | Acc: 53.125% \n",
            "[epoch:20, iter:441] Loss: 1.067 | Acc: 52.344% \n",
            "[epoch:20, iter:442] Loss: 1.093 | Acc: 50.625% \n",
            "[epoch:20, iter:443] Loss: 1.093 | Acc: 50.000% \n",
            "[epoch:20, iter:444] Loss: 1.129 | Acc: 47.768% \n",
            "[epoch:20, iter:445] Loss: 1.143 | Acc: 47.656% \n",
            "[epoch:20, iter:446] Loss: 1.133 | Acc: 48.264% \n",
            "[epoch:20, iter:447] Loss: 1.118 | Acc: 49.688% \n",
            "[epoch:20, iter:448] Loss: 1.119 | Acc: 49.148% \n",
            "[epoch:20, iter:449] Loss: 1.133 | Acc: 48.698% \n",
            "[epoch:20, iter:450] Loss: 1.131 | Acc: 49.519% \n",
            "[epoch:20, iter:451] Loss: 1.127 | Acc: 49.777% \n",
            "[epoch:20, iter:452] Loss: 1.133 | Acc: 50.000% \n",
            "[epoch:20, iter:453] Loss: 1.139 | Acc: 50.000% \n",
            "[epoch:20, iter:454] Loss: 1.134 | Acc: 50.368% \n",
            "[epoch:20, iter:455] Loss: 1.150 | Acc: 49.826% \n",
            "[epoch:20, iter:456] Loss: 1.149 | Acc: 49.342% \n",
            "[epoch:20, iter:457] Loss: 1.157 | Acc: 49.062% \n",
            "[epoch:20, iter:458] Loss: 1.144 | Acc: 49.554% \n",
            "[epoch:20, iter:459] Loss: 1.151 | Acc: 49.574% \n",
            "[epoch:20, iter:460] Loss: 1.158 | Acc: 49.592% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 21\n",
            "[epoch:21, iter:461] Loss: 0.935 | Acc: 59.375% \n",
            "[epoch:21, iter:462] Loss: 1.031 | Acc: 56.250% \n",
            "[epoch:21, iter:463] Loss: 1.085 | Acc: 54.167% \n",
            "[epoch:21, iter:464] Loss: 1.167 | Acc: 50.781% \n",
            "[epoch:21, iter:465] Loss: 1.234 | Acc: 45.000% \n",
            "[epoch:21, iter:466] Loss: 1.182 | Acc: 47.396% \n",
            "[epoch:21, iter:467] Loss: 1.172 | Acc: 46.429% \n",
            "[epoch:21, iter:468] Loss: 1.186 | Acc: 46.484% \n",
            "[epoch:21, iter:469] Loss: 1.161 | Acc: 47.569% \n",
            "[epoch:21, iter:470] Loss: 1.149 | Acc: 48.125% \n",
            "[epoch:21, iter:471] Loss: 1.160 | Acc: 47.443% \n",
            "[epoch:21, iter:472] Loss: 1.157 | Acc: 47.135% \n",
            "[epoch:21, iter:473] Loss: 1.164 | Acc: 46.875% \n",
            "[epoch:21, iter:474] Loss: 1.167 | Acc: 46.652% \n",
            "[epoch:21, iter:475] Loss: 1.171 | Acc: 46.667% \n",
            "[epoch:21, iter:476] Loss: 1.176 | Acc: 46.875% \n",
            "[epoch:21, iter:477] Loss: 1.175 | Acc: 47.243% \n",
            "[epoch:21, iter:478] Loss: 1.170 | Acc: 48.090% \n",
            "[epoch:21, iter:479] Loss: 1.163 | Acc: 48.355% \n",
            "[epoch:21, iter:480] Loss: 1.166 | Acc: 47.969% \n",
            "[epoch:21, iter:481] Loss: 1.170 | Acc: 47.768% \n",
            "[epoch:21, iter:482] Loss: 1.168 | Acc: 47.869% \n",
            "[epoch:21, iter:483] Loss: 1.172 | Acc: 47.826% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.818%\n",
            "\n",
            "Epoch: 22\n",
            "[epoch:22, iter:484] Loss: 1.183 | Acc: 50.000% \n",
            "[epoch:22, iter:485] Loss: 1.165 | Acc: 50.000% \n",
            "[epoch:22, iter:486] Loss: 1.122 | Acc: 51.042% \n",
            "[epoch:22, iter:487] Loss: 1.098 | Acc: 50.781% \n",
            "[epoch:22, iter:488] Loss: 1.107 | Acc: 51.875% \n",
            "[epoch:22, iter:489] Loss: 1.123 | Acc: 50.521% \n",
            "[epoch:22, iter:490] Loss: 1.117 | Acc: 51.339% \n",
            "[epoch:22, iter:491] Loss: 1.119 | Acc: 50.000% \n",
            "[epoch:22, iter:492] Loss: 1.089 | Acc: 50.000% \n",
            "[epoch:22, iter:493] Loss: 1.076 | Acc: 50.938% \n",
            "[epoch:22, iter:494] Loss: 1.081 | Acc: 50.852% \n",
            "[epoch:22, iter:495] Loss: 1.094 | Acc: 49.740% \n",
            "[epoch:22, iter:496] Loss: 1.087 | Acc: 50.481% \n",
            "[epoch:22, iter:497] Loss: 1.101 | Acc: 50.223% \n",
            "[epoch:22, iter:498] Loss: 1.099 | Acc: 50.000% \n",
            "[epoch:22, iter:499] Loss: 1.101 | Acc: 50.195% \n",
            "[epoch:22, iter:500] Loss: 1.101 | Acc: 50.184% \n",
            "[epoch:22, iter:501] Loss: 1.106 | Acc: 49.826% \n",
            "[epoch:22, iter:502] Loss: 1.108 | Acc: 49.671% \n",
            "[epoch:22, iter:503] Loss: 1.106 | Acc: 49.688% \n",
            "[epoch:22, iter:504] Loss: 1.108 | Acc: 49.554% \n",
            "[epoch:22, iter:505] Loss: 1.114 | Acc: 49.574% \n",
            "[epoch:22, iter:506] Loss: 1.110 | Acc: 49.457% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 23\n",
            "[epoch:23, iter:507] Loss: 0.945 | Acc: 68.750% \n",
            "[epoch:23, iter:508] Loss: 1.067 | Acc: 50.000% \n",
            "[epoch:23, iter:509] Loss: 1.056 | Acc: 52.083% \n",
            "[epoch:23, iter:510] Loss: 1.097 | Acc: 51.562% \n",
            "[epoch:23, iter:511] Loss: 1.085 | Acc: 51.250% \n",
            "[epoch:23, iter:512] Loss: 1.099 | Acc: 51.042% \n",
            "[epoch:23, iter:513] Loss: 1.138 | Acc: 49.554% \n",
            "[epoch:23, iter:514] Loss: 1.133 | Acc: 48.828% \n",
            "[epoch:23, iter:515] Loss: 1.116 | Acc: 50.694% \n",
            "[epoch:23, iter:516] Loss: 1.112 | Acc: 50.000% \n",
            "[epoch:23, iter:517] Loss: 1.107 | Acc: 50.284% \n",
            "[epoch:23, iter:518] Loss: 1.092 | Acc: 51.042% \n",
            "[epoch:23, iter:519] Loss: 1.077 | Acc: 50.721% \n",
            "[epoch:23, iter:520] Loss: 1.076 | Acc: 51.339% \n",
            "[epoch:23, iter:521] Loss: 1.086 | Acc: 50.833% \n",
            "[epoch:23, iter:522] Loss: 1.096 | Acc: 50.195% \n",
            "[epoch:23, iter:523] Loss: 1.103 | Acc: 50.368% \n",
            "[epoch:23, iter:524] Loss: 1.117 | Acc: 50.694% \n",
            "[epoch:23, iter:525] Loss: 1.113 | Acc: 50.658% \n",
            "[epoch:23, iter:526] Loss: 1.112 | Acc: 50.781% \n",
            "[epoch:23, iter:527] Loss: 1.112 | Acc: 50.595% \n",
            "[epoch:23, iter:528] Loss: 1.121 | Acc: 50.284% \n",
            "[epoch:23, iter:529] Loss: 1.126 | Acc: 49.864% \n",
            "Waiting Test...\n",
            "Test's ac is: 20.455%\n",
            "\n",
            "Epoch: 24\n",
            "[epoch:24, iter:530] Loss: 1.131 | Acc: 56.250% \n",
            "[epoch:24, iter:531] Loss: 1.094 | Acc: 54.688% \n",
            "[epoch:24, iter:532] Loss: 1.081 | Acc: 52.083% \n",
            "[epoch:24, iter:533] Loss: 1.105 | Acc: 51.562% \n",
            "[epoch:24, iter:534] Loss: 1.106 | Acc: 49.375% \n",
            "[epoch:24, iter:535] Loss: 1.081 | Acc: 49.479% \n",
            "[epoch:24, iter:536] Loss: 1.099 | Acc: 49.107% \n",
            "[epoch:24, iter:537] Loss: 1.095 | Acc: 49.219% \n",
            "[epoch:24, iter:538] Loss: 1.100 | Acc: 49.653% \n",
            "[epoch:24, iter:539] Loss: 1.108 | Acc: 49.062% \n",
            "[epoch:24, iter:540] Loss: 1.098 | Acc: 49.716% \n",
            "[epoch:24, iter:541] Loss: 1.100 | Acc: 49.740% \n",
            "[epoch:24, iter:542] Loss: 1.116 | Acc: 48.798% \n",
            "[epoch:24, iter:543] Loss: 1.121 | Acc: 49.107% \n",
            "[epoch:24, iter:544] Loss: 1.105 | Acc: 50.625% \n",
            "[epoch:24, iter:545] Loss: 1.111 | Acc: 50.000% \n",
            "[epoch:24, iter:546] Loss: 1.113 | Acc: 50.000% \n",
            "[epoch:24, iter:547] Loss: 1.117 | Acc: 49.826% \n",
            "[epoch:24, iter:548] Loss: 1.133 | Acc: 49.671% \n",
            "[epoch:24, iter:549] Loss: 1.130 | Acc: 50.000% \n",
            "[epoch:24, iter:550] Loss: 1.130 | Acc: 50.298% \n",
            "[epoch:24, iter:551] Loss: 1.134 | Acc: 49.858% \n",
            "[epoch:24, iter:552] Loss: 1.136 | Acc: 49.728% \n",
            "Waiting Test...\n",
            "Test's ac is: 32.576%\n",
            "\n",
            "Epoch: 25\n",
            "[epoch:25, iter:553] Loss: 1.168 | Acc: 46.875% \n",
            "[epoch:25, iter:554] Loss: 1.238 | Acc: 43.750% \n",
            "[epoch:25, iter:555] Loss: 1.218 | Acc: 42.708% \n",
            "[epoch:25, iter:556] Loss: 1.194 | Acc: 44.531% \n",
            "[epoch:25, iter:557] Loss: 1.167 | Acc: 48.125% \n",
            "[epoch:25, iter:558] Loss: 1.164 | Acc: 46.354% \n",
            "[epoch:25, iter:559] Loss: 1.153 | Acc: 46.875% \n",
            "[epoch:25, iter:560] Loss: 1.162 | Acc: 46.484% \n",
            "[epoch:25, iter:561] Loss: 1.165 | Acc: 46.875% \n",
            "[epoch:25, iter:562] Loss: 1.134 | Acc: 50.000% \n",
            "[epoch:25, iter:563] Loss: 1.124 | Acc: 51.136% \n",
            "[epoch:25, iter:564] Loss: 1.112 | Acc: 51.823% \n",
            "[epoch:25, iter:565] Loss: 1.114 | Acc: 52.404% \n",
            "[epoch:25, iter:566] Loss: 1.117 | Acc: 51.339% \n",
            "[epoch:25, iter:567] Loss: 1.124 | Acc: 51.042% \n",
            "[epoch:25, iter:568] Loss: 1.125 | Acc: 51.562% \n",
            "[epoch:25, iter:569] Loss: 1.131 | Acc: 50.368% \n",
            "[epoch:25, iter:570] Loss: 1.129 | Acc: 50.000% \n",
            "[epoch:25, iter:571] Loss: 1.133 | Acc: 49.836% \n",
            "[epoch:25, iter:572] Loss: 1.127 | Acc: 49.688% \n",
            "[epoch:25, iter:573] Loss: 1.121 | Acc: 50.000% \n",
            "[epoch:25, iter:574] Loss: 1.113 | Acc: 50.142% \n",
            "[epoch:25, iter:575] Loss: 1.122 | Acc: 49.728% \n",
            "Waiting Test...\n",
            "Test's ac is: 17.424%\n",
            "\n",
            "Epoch: 26\n",
            "[epoch:26, iter:576] Loss: 1.072 | Acc: 46.875% \n",
            "[epoch:26, iter:577] Loss: 0.999 | Acc: 50.000% \n",
            "[epoch:26, iter:578] Loss: 1.088 | Acc: 45.833% \n",
            "[epoch:26, iter:579] Loss: 1.063 | Acc: 50.781% \n",
            "[epoch:26, iter:580] Loss: 1.057 | Acc: 51.875% \n",
            "[epoch:26, iter:581] Loss: 1.058 | Acc: 49.479% \n",
            "[epoch:26, iter:582] Loss: 1.048 | Acc: 50.000% \n",
            "[epoch:26, iter:583] Loss: 1.070 | Acc: 50.000% \n",
            "[epoch:26, iter:584] Loss: 1.082 | Acc: 48.958% \n",
            "[epoch:26, iter:585] Loss: 1.098 | Acc: 49.062% \n",
            "[epoch:26, iter:586] Loss: 1.091 | Acc: 50.000% \n",
            "[epoch:26, iter:587] Loss: 1.083 | Acc: 50.521% \n",
            "[epoch:26, iter:588] Loss: 1.090 | Acc: 50.481% \n",
            "[epoch:26, iter:589] Loss: 1.091 | Acc: 50.446% \n",
            "[epoch:26, iter:590] Loss: 1.081 | Acc: 51.042% \n",
            "[epoch:26, iter:591] Loss: 1.085 | Acc: 51.367% \n",
            "[epoch:26, iter:592] Loss: 1.091 | Acc: 51.103% \n",
            "[epoch:26, iter:593] Loss: 1.088 | Acc: 51.389% \n",
            "[epoch:26, iter:594] Loss: 1.091 | Acc: 50.658% \n",
            "[epoch:26, iter:595] Loss: 1.108 | Acc: 49.688% \n",
            "[epoch:26, iter:596] Loss: 1.103 | Acc: 49.851% \n",
            "[epoch:26, iter:597] Loss: 1.113 | Acc: 49.716% \n",
            "[epoch:26, iter:598] Loss: 1.107 | Acc: 50.000% \n",
            "Waiting Test...\n",
            "Test's ac is: 30.303%\n",
            "\n",
            "Epoch: 27\n",
            "[epoch:27, iter:599] Loss: 1.043 | Acc: 56.250% \n",
            "[epoch:27, iter:600] Loss: 1.185 | Acc: 40.625% \n",
            "[epoch:27, iter:601] Loss: 1.126 | Acc: 42.708% \n",
            "[epoch:27, iter:602] Loss: 1.156 | Acc: 41.406% \n",
            "[epoch:27, iter:603] Loss: 1.109 | Acc: 46.250% \n",
            "[epoch:27, iter:604] Loss: 1.072 | Acc: 48.958% \n",
            "[epoch:27, iter:605] Loss: 1.082 | Acc: 48.214% \n",
            "[epoch:27, iter:606] Loss: 1.059 | Acc: 50.391% \n",
            "[epoch:27, iter:607] Loss: 1.064 | Acc: 50.694% \n",
            "[epoch:27, iter:608] Loss: 1.088 | Acc: 49.688% \n",
            "[epoch:27, iter:609] Loss: 1.076 | Acc: 51.136% \n",
            "[epoch:27, iter:610] Loss: 1.071 | Acc: 51.302% \n",
            "[epoch:27, iter:611] Loss: 1.079 | Acc: 50.721% \n",
            "[epoch:27, iter:612] Loss: 1.064 | Acc: 52.009% \n",
            "[epoch:27, iter:613] Loss: 1.077 | Acc: 51.042% \n",
            "[epoch:27, iter:614] Loss: 1.078 | Acc: 50.977% \n",
            "[epoch:27, iter:615] Loss: 1.081 | Acc: 50.368% \n",
            "[epoch:27, iter:616] Loss: 1.099 | Acc: 50.000% \n",
            "[epoch:27, iter:617] Loss: 1.094 | Acc: 50.658% \n",
            "[epoch:27, iter:618] Loss: 1.092 | Acc: 50.312% \n",
            "[epoch:27, iter:619] Loss: 1.093 | Acc: 50.298% \n",
            "[epoch:27, iter:620] Loss: 1.086 | Acc: 50.568% \n",
            "[epoch:27, iter:621] Loss: 1.088 | Acc: 50.543% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.121%\n",
            "\n",
            "Epoch: 28\n",
            "[epoch:28, iter:622] Loss: 1.045 | Acc: 50.000% \n",
            "[epoch:28, iter:623] Loss: 1.099 | Acc: 45.312% \n",
            "[epoch:28, iter:624] Loss: 1.106 | Acc: 50.000% \n",
            "[epoch:28, iter:625] Loss: 1.120 | Acc: 47.656% \n",
            "[epoch:28, iter:626] Loss: 1.100 | Acc: 49.375% \n",
            "[epoch:28, iter:627] Loss: 1.146 | Acc: 48.958% \n",
            "[epoch:28, iter:628] Loss: 1.143 | Acc: 49.554% \n",
            "[epoch:28, iter:629] Loss: 1.136 | Acc: 49.219% \n",
            "[epoch:28, iter:630] Loss: 1.136 | Acc: 48.958% \n",
            "[epoch:28, iter:631] Loss: 1.131 | Acc: 48.750% \n",
            "[epoch:28, iter:632] Loss: 1.126 | Acc: 49.432% \n",
            "[epoch:28, iter:633] Loss: 1.128 | Acc: 49.219% \n",
            "[epoch:28, iter:634] Loss: 1.126 | Acc: 49.519% \n",
            "[epoch:28, iter:635] Loss: 1.116 | Acc: 49.777% \n",
            "[epoch:28, iter:636] Loss: 1.116 | Acc: 49.792% \n",
            "[epoch:28, iter:637] Loss: 1.118 | Acc: 48.633% \n",
            "[epoch:28, iter:638] Loss: 1.120 | Acc: 48.529% \n",
            "[epoch:28, iter:639] Loss: 1.121 | Acc: 48.090% \n",
            "[epoch:28, iter:640] Loss: 1.122 | Acc: 48.026% \n",
            "[epoch:28, iter:641] Loss: 1.131 | Acc: 47.188% \n",
            "[epoch:28, iter:642] Loss: 1.137 | Acc: 46.875% \n",
            "[epoch:28, iter:643] Loss: 1.143 | Acc: 46.733% \n",
            "[epoch:28, iter:644] Loss: 1.150 | Acc: 46.875% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.091%\n",
            "\n",
            "Epoch: 29\n",
            "[epoch:29, iter:645] Loss: 1.123 | Acc: 37.500% \n",
            "[epoch:29, iter:646] Loss: 1.106 | Acc: 45.312% \n",
            "[epoch:29, iter:647] Loss: 1.101 | Acc: 45.833% \n",
            "[epoch:29, iter:648] Loss: 1.078 | Acc: 50.000% \n",
            "[epoch:29, iter:649] Loss: 1.097 | Acc: 53.125% \n",
            "[epoch:29, iter:650] Loss: 1.095 | Acc: 51.042% \n",
            "[epoch:29, iter:651] Loss: 1.063 | Acc: 54.464% \n",
            "[epoch:29, iter:652] Loss: 1.070 | Acc: 54.688% \n",
            "[epoch:29, iter:653] Loss: 1.051 | Acc: 56.597% \n",
            "[epoch:29, iter:654] Loss: 1.054 | Acc: 55.625% \n",
            "[epoch:29, iter:655] Loss: 1.044 | Acc: 55.114% \n",
            "[epoch:29, iter:656] Loss: 1.084 | Acc: 53.385% \n",
            "[epoch:29, iter:657] Loss: 1.068 | Acc: 54.327% \n",
            "[epoch:29, iter:658] Loss: 1.058 | Acc: 54.241% \n",
            "[epoch:29, iter:659] Loss: 1.079 | Acc: 53.542% \n",
            "[epoch:29, iter:660] Loss: 1.075 | Acc: 53.711% \n",
            "[epoch:29, iter:661] Loss: 1.081 | Acc: 53.493% \n",
            "[epoch:29, iter:662] Loss: 1.077 | Acc: 53.299% \n",
            "[epoch:29, iter:663] Loss: 1.072 | Acc: 53.454% \n",
            "[epoch:29, iter:664] Loss: 1.078 | Acc: 53.281% \n",
            "[epoch:29, iter:665] Loss: 1.084 | Acc: 52.530% \n",
            "[epoch:29, iter:666] Loss: 1.080 | Acc: 52.415% \n",
            "[epoch:29, iter:667] Loss: 1.089 | Acc: 51.902% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 30\n",
            "[epoch:30, iter:668] Loss: 1.090 | Acc: 43.750% \n",
            "[epoch:30, iter:669] Loss: 0.955 | Acc: 57.812% \n",
            "[epoch:30, iter:670] Loss: 0.996 | Acc: 55.208% \n",
            "[epoch:30, iter:671] Loss: 0.979 | Acc: 57.031% \n",
            "[epoch:30, iter:672] Loss: 0.968 | Acc: 56.875% \n",
            "[epoch:30, iter:673] Loss: 0.989 | Acc: 54.688% \n",
            "[epoch:30, iter:674] Loss: 1.036 | Acc: 54.018% \n",
            "[epoch:30, iter:675] Loss: 1.022 | Acc: 53.125% \n",
            "[epoch:30, iter:676] Loss: 0.999 | Acc: 54.167% \n",
            "[epoch:30, iter:677] Loss: 1.005 | Acc: 54.688% \n",
            "[epoch:30, iter:678] Loss: 1.020 | Acc: 53.125% \n",
            "[epoch:30, iter:679] Loss: 1.041 | Acc: 52.604% \n",
            "[epoch:30, iter:680] Loss: 1.060 | Acc: 51.202% \n",
            "[epoch:30, iter:681] Loss: 1.079 | Acc: 50.893% \n",
            "[epoch:30, iter:682] Loss: 1.074 | Acc: 51.250% \n",
            "[epoch:30, iter:683] Loss: 1.068 | Acc: 51.758% \n",
            "[epoch:30, iter:684] Loss: 1.063 | Acc: 52.574% \n",
            "[epoch:30, iter:685] Loss: 1.069 | Acc: 51.736% \n",
            "[epoch:30, iter:686] Loss: 1.083 | Acc: 51.151% \n",
            "[epoch:30, iter:687] Loss: 1.101 | Acc: 50.156% \n",
            "[epoch:30, iter:688] Loss: 1.100 | Acc: 50.149% \n",
            "[epoch:30, iter:689] Loss: 1.114 | Acc: 50.000% \n",
            "[epoch:30, iter:690] Loss: 1.110 | Acc: 49.864% \n",
            "Waiting Test...\n",
            "Test's ac is: 33.333%\n",
            "\n",
            "Epoch: 31\n",
            "[epoch:31, iter:691] Loss: 1.114 | Acc: 56.250% \n",
            "[epoch:31, iter:692] Loss: 1.042 | Acc: 57.812% \n",
            "[epoch:31, iter:693] Loss: 1.134 | Acc: 53.125% \n",
            "[epoch:31, iter:694] Loss: 1.148 | Acc: 50.781% \n",
            "[epoch:31, iter:695] Loss: 1.126 | Acc: 50.625% \n",
            "[epoch:31, iter:696] Loss: 1.136 | Acc: 47.917% \n",
            "[epoch:31, iter:697] Loss: 1.129 | Acc: 47.768% \n",
            "[epoch:31, iter:698] Loss: 1.109 | Acc: 49.219% \n",
            "[epoch:31, iter:699] Loss: 1.096 | Acc: 49.653% \n",
            "[epoch:31, iter:700] Loss: 1.089 | Acc: 50.312% \n",
            "[epoch:31, iter:701] Loss: 1.086 | Acc: 50.568% \n",
            "[epoch:31, iter:702] Loss: 1.067 | Acc: 52.083% \n",
            "[epoch:31, iter:703] Loss: 1.056 | Acc: 53.846% \n",
            "[epoch:31, iter:704] Loss: 1.049 | Acc: 54.688% \n",
            "[epoch:31, iter:705] Loss: 1.041 | Acc: 55.208% \n",
            "[epoch:31, iter:706] Loss: 1.039 | Acc: 55.469% \n",
            "[epoch:31, iter:707] Loss: 1.051 | Acc: 54.596% \n",
            "[epoch:31, iter:708] Loss: 1.051 | Acc: 55.035% \n",
            "[epoch:31, iter:709] Loss: 1.064 | Acc: 54.770% \n",
            "[epoch:31, iter:710] Loss: 1.069 | Acc: 54.062% \n",
            "[epoch:31, iter:711] Loss: 1.070 | Acc: 53.869% \n",
            "[epoch:31, iter:712] Loss: 1.076 | Acc: 53.693% \n",
            "[epoch:31, iter:713] Loss: 1.087 | Acc: 53.533% \n",
            "Waiting Test...\n",
            "Test's ac is: 32.576%\n",
            "\n",
            "Epoch: 32\n",
            "[epoch:32, iter:714] Loss: 1.074 | Acc: 62.500% \n",
            "[epoch:32, iter:715] Loss: 1.045 | Acc: 59.375% \n",
            "[epoch:32, iter:716] Loss: 1.044 | Acc: 56.250% \n",
            "[epoch:32, iter:717] Loss: 1.060 | Acc: 56.250% \n",
            "[epoch:32, iter:718] Loss: 1.007 | Acc: 56.875% \n",
            "[epoch:32, iter:719] Loss: 1.033 | Acc: 55.208% \n",
            "[epoch:32, iter:720] Loss: 1.033 | Acc: 54.911% \n",
            "[epoch:32, iter:721] Loss: 1.048 | Acc: 53.125% \n",
            "[epoch:32, iter:722] Loss: 1.059 | Acc: 52.083% \n",
            "[epoch:32, iter:723] Loss: 1.070 | Acc: 51.875% \n",
            "[epoch:32, iter:724] Loss: 1.086 | Acc: 50.568% \n",
            "[epoch:32, iter:725] Loss: 1.084 | Acc: 51.042% \n",
            "[epoch:32, iter:726] Loss: 1.083 | Acc: 51.923% \n",
            "[epoch:32, iter:727] Loss: 1.075 | Acc: 52.009% \n",
            "[epoch:32, iter:728] Loss: 1.071 | Acc: 52.500% \n",
            "[epoch:32, iter:729] Loss: 1.067 | Acc: 52.344% \n",
            "[epoch:32, iter:730] Loss: 1.059 | Acc: 52.757% \n",
            "[epoch:32, iter:731] Loss: 1.058 | Acc: 52.604% \n",
            "[epoch:32, iter:732] Loss: 1.064 | Acc: 52.796% \n",
            "[epoch:32, iter:733] Loss: 1.075 | Acc: 52.656% \n",
            "[epoch:32, iter:734] Loss: 1.085 | Acc: 52.232% \n",
            "[epoch:32, iter:735] Loss: 1.088 | Acc: 52.415% \n",
            "[epoch:32, iter:736] Loss: 1.080 | Acc: 52.446% \n",
            "Waiting Test...\n",
            "Test's ac is: 30.303%\n",
            "\n",
            "Epoch: 33\n",
            "[epoch:33, iter:737] Loss: 0.974 | Acc: 59.375% \n",
            "[epoch:33, iter:738] Loss: 0.916 | Acc: 60.938% \n",
            "[epoch:33, iter:739] Loss: 0.972 | Acc: 58.333% \n",
            "[epoch:33, iter:740] Loss: 1.028 | Acc: 55.469% \n",
            "[epoch:33, iter:741] Loss: 1.032 | Acc: 56.875% \n",
            "[epoch:33, iter:742] Loss: 1.027 | Acc: 57.292% \n",
            "[epoch:33, iter:743] Loss: 1.016 | Acc: 56.250% \n",
            "[epoch:33, iter:744] Loss: 1.010 | Acc: 56.641% \n",
            "[epoch:33, iter:745] Loss: 1.027 | Acc: 55.903% \n",
            "[epoch:33, iter:746] Loss: 1.024 | Acc: 56.250% \n",
            "[epoch:33, iter:747] Loss: 1.030 | Acc: 56.250% \n",
            "[epoch:33, iter:748] Loss: 1.029 | Acc: 55.990% \n",
            "[epoch:33, iter:749] Loss: 1.040 | Acc: 55.769% \n",
            "[epoch:33, iter:750] Loss: 1.033 | Acc: 55.804% \n",
            "[epoch:33, iter:751] Loss: 1.037 | Acc: 55.833% \n",
            "[epoch:33, iter:752] Loss: 1.038 | Acc: 55.859% \n",
            "[epoch:33, iter:753] Loss: 1.023 | Acc: 57.169% \n",
            "[epoch:33, iter:754] Loss: 1.037 | Acc: 56.771% \n",
            "[epoch:33, iter:755] Loss: 1.044 | Acc: 56.250% \n",
            "[epoch:33, iter:756] Loss: 1.046 | Acc: 55.938% \n",
            "[epoch:33, iter:757] Loss: 1.047 | Acc: 55.804% \n",
            "[epoch:33, iter:758] Loss: 1.049 | Acc: 55.256% \n",
            "[epoch:33, iter:759] Loss: 1.047 | Acc: 54.891% \n",
            "Waiting Test...\n",
            "Test's ac is: 21.970%\n",
            "\n",
            "Epoch: 34\n",
            "[epoch:34, iter:760] Loss: 0.968 | Acc: 62.500% \n",
            "[epoch:34, iter:761] Loss: 1.129 | Acc: 51.562% \n",
            "[epoch:34, iter:762] Loss: 1.012 | Acc: 57.292% \n",
            "[epoch:34, iter:763] Loss: 0.935 | Acc: 60.938% \n",
            "[epoch:34, iter:764] Loss: 0.935 | Acc: 63.125% \n",
            "[epoch:34, iter:765] Loss: 0.976 | Acc: 58.854% \n",
            "[epoch:34, iter:766] Loss: 0.959 | Acc: 59.821% \n",
            "[epoch:34, iter:767] Loss: 0.975 | Acc: 59.766% \n",
            "[epoch:34, iter:768] Loss: 0.965 | Acc: 60.069% \n",
            "[epoch:34, iter:769] Loss: 0.960 | Acc: 59.062% \n",
            "[epoch:34, iter:770] Loss: 0.957 | Acc: 59.659% \n",
            "[epoch:34, iter:771] Loss: 0.952 | Acc: 59.375% \n",
            "[epoch:34, iter:772] Loss: 0.941 | Acc: 59.856% \n",
            "[epoch:34, iter:773] Loss: 0.970 | Acc: 59.375% \n",
            "[epoch:34, iter:774] Loss: 0.978 | Acc: 59.167% \n",
            "[epoch:34, iter:775] Loss: 0.980 | Acc: 58.984% \n",
            "[epoch:34, iter:776] Loss: 0.984 | Acc: 58.640% \n",
            "[epoch:34, iter:777] Loss: 0.997 | Acc: 57.465% \n",
            "[epoch:34, iter:778] Loss: 1.013 | Acc: 57.072% \n",
            "[epoch:34, iter:779] Loss: 1.016 | Acc: 56.875% \n",
            "[epoch:34, iter:780] Loss: 1.021 | Acc: 56.696% \n",
            "[epoch:34, iter:781] Loss: 1.031 | Acc: 56.392% \n",
            "[epoch:34, iter:782] Loss: 1.040 | Acc: 56.114% \n",
            "Waiting Test...\n",
            "Test's ac is: 18.939%\n",
            "\n",
            "Epoch: 35\n",
            "[epoch:35, iter:783] Loss: 1.052 | Acc: 46.875% \n",
            "[epoch:35, iter:784] Loss: 1.028 | Acc: 53.125% \n",
            "[epoch:35, iter:785] Loss: 1.017 | Acc: 54.167% \n",
            "[epoch:35, iter:786] Loss: 1.039 | Acc: 54.688% \n",
            "[epoch:35, iter:787] Loss: 1.055 | Acc: 55.625% \n",
            "[epoch:35, iter:788] Loss: 1.055 | Acc: 53.646% \n",
            "[epoch:35, iter:789] Loss: 1.051 | Acc: 54.911% \n",
            "[epoch:35, iter:790] Loss: 1.050 | Acc: 54.688% \n",
            "[epoch:35, iter:791] Loss: 1.037 | Acc: 55.903% \n",
            "[epoch:35, iter:792] Loss: 1.034 | Acc: 56.250% \n",
            "[epoch:35, iter:793] Loss: 1.047 | Acc: 55.966% \n",
            "[epoch:35, iter:794] Loss: 1.033 | Acc: 57.031% \n",
            "[epoch:35, iter:795] Loss: 1.023 | Acc: 57.212% \n",
            "[epoch:35, iter:796] Loss: 1.026 | Acc: 56.696% \n",
            "[epoch:35, iter:797] Loss: 1.014 | Acc: 56.875% \n",
            "[epoch:35, iter:798] Loss: 1.029 | Acc: 55.664% \n",
            "[epoch:35, iter:799] Loss: 1.034 | Acc: 55.699% \n",
            "[epoch:35, iter:800] Loss: 1.033 | Acc: 55.556% \n",
            "[epoch:35, iter:801] Loss: 1.035 | Acc: 55.592% \n",
            "[epoch:35, iter:802] Loss: 1.042 | Acc: 55.312% \n",
            "[epoch:35, iter:803] Loss: 1.035 | Acc: 55.506% \n",
            "[epoch:35, iter:804] Loss: 1.025 | Acc: 56.108% \n",
            "[epoch:35, iter:805] Loss: 1.028 | Acc: 56.250% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 36\n",
            "[epoch:36, iter:806] Loss: 1.061 | Acc: 59.375% \n",
            "[epoch:36, iter:807] Loss: 1.086 | Acc: 54.688% \n",
            "[epoch:36, iter:808] Loss: 1.099 | Acc: 52.083% \n",
            "[epoch:36, iter:809] Loss: 1.085 | Acc: 53.125% \n",
            "[epoch:36, iter:810] Loss: 1.060 | Acc: 53.125% \n",
            "[epoch:36, iter:811] Loss: 1.051 | Acc: 53.125% \n",
            "[epoch:36, iter:812] Loss: 1.022 | Acc: 55.804% \n",
            "[epoch:36, iter:813] Loss: 1.069 | Acc: 54.297% \n",
            "[epoch:36, iter:814] Loss: 1.067 | Acc: 53.819% \n",
            "[epoch:36, iter:815] Loss: 1.081 | Acc: 52.812% \n",
            "[epoch:36, iter:816] Loss: 1.067 | Acc: 53.409% \n",
            "[epoch:36, iter:817] Loss: 1.067 | Acc: 53.646% \n",
            "[epoch:36, iter:818] Loss: 1.044 | Acc: 55.288% \n",
            "[epoch:36, iter:819] Loss: 1.042 | Acc: 55.357% \n",
            "[epoch:36, iter:820] Loss: 1.040 | Acc: 55.625% \n",
            "[epoch:36, iter:821] Loss: 1.032 | Acc: 55.664% \n",
            "[epoch:36, iter:822] Loss: 1.047 | Acc: 55.882% \n",
            "[epoch:36, iter:823] Loss: 1.038 | Acc: 56.250% \n",
            "[epoch:36, iter:824] Loss: 1.048 | Acc: 55.757% \n",
            "[epoch:36, iter:825] Loss: 1.042 | Acc: 55.938% \n",
            "[epoch:36, iter:826] Loss: 1.046 | Acc: 55.804% \n",
            "[epoch:36, iter:827] Loss: 1.038 | Acc: 56.250% \n",
            "[epoch:36, iter:828] Loss: 1.031 | Acc: 56.386% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.061%\n",
            "\n",
            "Epoch: 37\n",
            "[epoch:37, iter:829] Loss: 1.017 | Acc: 43.750% \n",
            "[epoch:37, iter:830] Loss: 1.045 | Acc: 50.000% \n",
            "[epoch:37, iter:831] Loss: 1.019 | Acc: 46.875% \n",
            "[epoch:37, iter:832] Loss: 1.037 | Acc: 46.094% \n",
            "[epoch:37, iter:833] Loss: 1.062 | Acc: 44.375% \n",
            "[epoch:37, iter:834] Loss: 1.072 | Acc: 46.875% \n",
            "[epoch:37, iter:835] Loss: 1.115 | Acc: 47.321% \n",
            "[epoch:37, iter:836] Loss: 1.125 | Acc: 47.656% \n",
            "[epoch:37, iter:837] Loss: 1.069 | Acc: 51.389% \n",
            "[epoch:37, iter:838] Loss: 1.051 | Acc: 52.500% \n",
            "[epoch:37, iter:839] Loss: 1.042 | Acc: 52.841% \n",
            "[epoch:37, iter:840] Loss: 1.027 | Acc: 53.906% \n",
            "[epoch:37, iter:841] Loss: 1.038 | Acc: 53.125% \n",
            "[epoch:37, iter:842] Loss: 1.065 | Acc: 53.125% \n",
            "[epoch:37, iter:843] Loss: 1.085 | Acc: 52.500% \n",
            "[epoch:37, iter:844] Loss: 1.095 | Acc: 52.344% \n",
            "[epoch:37, iter:845] Loss: 1.079 | Acc: 53.860% \n",
            "[epoch:37, iter:846] Loss: 1.075 | Acc: 53.299% \n",
            "[epoch:37, iter:847] Loss: 1.076 | Acc: 53.289% \n",
            "[epoch:37, iter:848] Loss: 1.087 | Acc: 52.812% \n",
            "[epoch:37, iter:849] Loss: 1.094 | Acc: 52.530% \n",
            "[epoch:37, iter:850] Loss: 1.092 | Acc: 52.557% \n",
            "[epoch:37, iter:851] Loss: 1.097 | Acc: 51.902% \n",
            "Waiting Test...\n",
            "Test's ac is: 21.212%\n",
            "\n",
            "Epoch: 38\n",
            "[epoch:38, iter:852] Loss: 1.111 | Acc: 37.500% \n",
            "[epoch:38, iter:853] Loss: 1.034 | Acc: 51.562% \n",
            "[epoch:38, iter:854] Loss: 1.022 | Acc: 54.167% \n",
            "[epoch:38, iter:855] Loss: 1.047 | Acc: 50.000% \n",
            "[epoch:38, iter:856] Loss: 1.021 | Acc: 53.750% \n",
            "[epoch:38, iter:857] Loss: 1.032 | Acc: 53.646% \n",
            "[epoch:38, iter:858] Loss: 1.033 | Acc: 52.232% \n",
            "[epoch:38, iter:859] Loss: 1.019 | Acc: 52.734% \n",
            "[epoch:38, iter:860] Loss: 1.022 | Acc: 53.472% \n",
            "[epoch:38, iter:861] Loss: 1.005 | Acc: 55.312% \n",
            "[epoch:38, iter:862] Loss: 1.008 | Acc: 55.398% \n",
            "[epoch:38, iter:863] Loss: 1.004 | Acc: 55.208% \n",
            "[epoch:38, iter:864] Loss: 0.986 | Acc: 56.490% \n",
            "[epoch:38, iter:865] Loss: 0.986 | Acc: 56.696% \n",
            "[epoch:38, iter:866] Loss: 0.989 | Acc: 56.250% \n",
            "[epoch:38, iter:867] Loss: 0.987 | Acc: 56.250% \n",
            "[epoch:38, iter:868] Loss: 0.988 | Acc: 56.801% \n",
            "[epoch:38, iter:869] Loss: 0.985 | Acc: 56.597% \n",
            "[epoch:38, iter:870] Loss: 0.976 | Acc: 56.908% \n",
            "[epoch:38, iter:871] Loss: 0.973 | Acc: 57.812% \n",
            "[epoch:38, iter:872] Loss: 0.984 | Acc: 57.738% \n",
            "[epoch:38, iter:873] Loss: 0.997 | Acc: 57.244% \n",
            "[epoch:38, iter:874] Loss: 0.996 | Acc: 57.065% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 39\n",
            "[epoch:39, iter:875] Loss: 0.811 | Acc: 62.500% \n",
            "[epoch:39, iter:876] Loss: 0.830 | Acc: 64.062% \n",
            "[epoch:39, iter:877] Loss: 0.860 | Acc: 62.500% \n",
            "[epoch:39, iter:878] Loss: 0.864 | Acc: 62.500% \n",
            "[epoch:39, iter:879] Loss: 0.866 | Acc: 62.500% \n",
            "[epoch:39, iter:880] Loss: 0.923 | Acc: 59.375% \n",
            "[epoch:39, iter:881] Loss: 0.916 | Acc: 61.161% \n",
            "[epoch:39, iter:882] Loss: 0.899 | Acc: 61.719% \n",
            "[epoch:39, iter:883] Loss: 0.926 | Acc: 61.458% \n",
            "[epoch:39, iter:884] Loss: 0.926 | Acc: 60.938% \n",
            "[epoch:39, iter:885] Loss: 0.918 | Acc: 60.511% \n",
            "[epoch:39, iter:886] Loss: 0.910 | Acc: 60.417% \n",
            "[epoch:39, iter:887] Loss: 0.922 | Acc: 59.856% \n",
            "[epoch:39, iter:888] Loss: 0.922 | Acc: 59.821% \n",
            "[epoch:39, iter:889] Loss: 0.935 | Acc: 59.583% \n",
            "[epoch:39, iter:890] Loss: 0.942 | Acc: 59.375% \n",
            "[epoch:39, iter:891] Loss: 0.950 | Acc: 59.007% \n",
            "[epoch:39, iter:892] Loss: 0.953 | Acc: 58.854% \n",
            "[epoch:39, iter:893] Loss: 0.956 | Acc: 58.388% \n",
            "[epoch:39, iter:894] Loss: 0.974 | Acc: 57.656% \n",
            "[epoch:39, iter:895] Loss: 0.989 | Acc: 57.292% \n",
            "[epoch:39, iter:896] Loss: 0.986 | Acc: 57.244% \n",
            "[epoch:39, iter:897] Loss: 0.993 | Acc: 57.065% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.788%\n",
            "\n",
            "Epoch: 40\n",
            "[epoch:40, iter:898] Loss: 1.083 | Acc: 43.750% \n",
            "[epoch:40, iter:899] Loss: 0.990 | Acc: 51.562% \n",
            "[epoch:40, iter:900] Loss: 0.950 | Acc: 57.292% \n",
            "[epoch:40, iter:901] Loss: 0.942 | Acc: 59.375% \n",
            "[epoch:40, iter:902] Loss: 0.921 | Acc: 61.250% \n",
            "[epoch:40, iter:903] Loss: 0.953 | Acc: 60.417% \n",
            "[epoch:40, iter:904] Loss: 0.962 | Acc: 58.929% \n",
            "[epoch:40, iter:905] Loss: 1.003 | Acc: 56.250% \n",
            "[epoch:40, iter:906] Loss: 1.027 | Acc: 55.208% \n",
            "[epoch:40, iter:907] Loss: 1.024 | Acc: 55.625% \n",
            "[epoch:40, iter:908] Loss: 1.024 | Acc: 55.682% \n",
            "[epoch:40, iter:909] Loss: 1.013 | Acc: 55.990% \n",
            "[epoch:40, iter:910] Loss: 1.000 | Acc: 56.731% \n",
            "[epoch:40, iter:911] Loss: 0.980 | Acc: 57.589% \n",
            "[epoch:40, iter:912] Loss: 0.976 | Acc: 57.500% \n",
            "[epoch:40, iter:913] Loss: 0.983 | Acc: 57.812% \n",
            "[epoch:40, iter:914] Loss: 0.984 | Acc: 57.904% \n",
            "[epoch:40, iter:915] Loss: 0.978 | Acc: 57.986% \n",
            "[epoch:40, iter:916] Loss: 0.979 | Acc: 57.566% \n",
            "[epoch:40, iter:917] Loss: 0.980 | Acc: 57.500% \n",
            "[epoch:40, iter:918] Loss: 0.981 | Acc: 57.292% \n",
            "[epoch:40, iter:919] Loss: 0.975 | Acc: 57.955% \n",
            "[epoch:40, iter:920] Loss: 0.981 | Acc: 57.609% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 41\n",
            "[epoch:41, iter:921] Loss: 0.833 | Acc: 68.750% \n",
            "[epoch:41, iter:922] Loss: 0.932 | Acc: 64.062% \n",
            "[epoch:41, iter:923] Loss: 0.883 | Acc: 65.625% \n",
            "[epoch:41, iter:924] Loss: 0.921 | Acc: 62.500% \n",
            "[epoch:41, iter:925] Loss: 0.920 | Acc: 61.250% \n",
            "[epoch:41, iter:926] Loss: 0.874 | Acc: 64.062% \n",
            "[epoch:41, iter:927] Loss: 0.904 | Acc: 62.946% \n",
            "[epoch:41, iter:928] Loss: 0.922 | Acc: 62.891% \n",
            "[epoch:41, iter:929] Loss: 0.911 | Acc: 62.153% \n",
            "[epoch:41, iter:930] Loss: 0.906 | Acc: 62.500% \n",
            "[epoch:41, iter:931] Loss: 0.897 | Acc: 63.636% \n",
            "[epoch:41, iter:932] Loss: 0.903 | Acc: 63.542% \n",
            "[epoch:41, iter:933] Loss: 0.890 | Acc: 63.462% \n",
            "[epoch:41, iter:934] Loss: 0.884 | Acc: 63.393% \n",
            "[epoch:41, iter:935] Loss: 0.909 | Acc: 62.292% \n",
            "[epoch:41, iter:936] Loss: 0.939 | Acc: 60.938% \n",
            "[epoch:41, iter:937] Loss: 0.928 | Acc: 61.397% \n",
            "[epoch:41, iter:938] Loss: 0.950 | Acc: 61.285% \n",
            "[epoch:41, iter:939] Loss: 0.955 | Acc: 61.020% \n",
            "[epoch:41, iter:940] Loss: 0.949 | Acc: 61.094% \n",
            "[epoch:41, iter:941] Loss: 0.959 | Acc: 60.417% \n",
            "[epoch:41, iter:942] Loss: 0.964 | Acc: 60.085% \n",
            "[epoch:41, iter:943] Loss: 0.971 | Acc: 59.647% \n",
            "Waiting Test...\n",
            "Test's ac is: 30.303%\n",
            "\n",
            "Epoch: 42\n",
            "[epoch:42, iter:944] Loss: 0.874 | Acc: 59.375% \n",
            "[epoch:42, iter:945] Loss: 0.852 | Acc: 57.812% \n",
            "[epoch:42, iter:946] Loss: 0.888 | Acc: 56.250% \n",
            "[epoch:42, iter:947] Loss: 0.934 | Acc: 53.906% \n",
            "[epoch:42, iter:948] Loss: 0.941 | Acc: 54.375% \n",
            "[epoch:42, iter:949] Loss: 0.995 | Acc: 53.125% \n",
            "[epoch:42, iter:950] Loss: 0.981 | Acc: 55.357% \n",
            "[epoch:42, iter:951] Loss: 0.966 | Acc: 55.859% \n",
            "[epoch:42, iter:952] Loss: 0.955 | Acc: 57.292% \n",
            "[epoch:42, iter:953] Loss: 0.951 | Acc: 56.875% \n",
            "[epoch:42, iter:954] Loss: 0.945 | Acc: 57.955% \n",
            "[epoch:42, iter:955] Loss: 0.955 | Acc: 57.031% \n",
            "[epoch:42, iter:956] Loss: 0.968 | Acc: 56.490% \n",
            "[epoch:42, iter:957] Loss: 0.968 | Acc: 56.920% \n",
            "[epoch:42, iter:958] Loss: 0.958 | Acc: 57.500% \n",
            "[epoch:42, iter:959] Loss: 0.961 | Acc: 57.812% \n",
            "[epoch:42, iter:960] Loss: 0.965 | Acc: 57.353% \n",
            "[epoch:42, iter:961] Loss: 0.961 | Acc: 58.333% \n",
            "[epoch:42, iter:962] Loss: 0.968 | Acc: 58.224% \n",
            "[epoch:42, iter:963] Loss: 0.964 | Acc: 57.969% \n",
            "[epoch:42, iter:964] Loss: 0.964 | Acc: 58.036% \n",
            "[epoch:42, iter:965] Loss: 0.966 | Acc: 57.528% \n",
            "[epoch:42, iter:966] Loss: 0.969 | Acc: 57.473% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.848%\n",
            "\n",
            "Epoch: 43\n",
            "[epoch:43, iter:967] Loss: 0.866 | Acc: 68.750% \n",
            "[epoch:43, iter:968] Loss: 0.877 | Acc: 68.750% \n",
            "[epoch:43, iter:969] Loss: 0.851 | Acc: 70.833% \n",
            "[epoch:43, iter:970] Loss: 0.873 | Acc: 67.969% \n",
            "[epoch:43, iter:971] Loss: 0.843 | Acc: 68.750% \n",
            "[epoch:43, iter:972] Loss: 0.834 | Acc: 68.229% \n",
            "[epoch:43, iter:973] Loss: 0.842 | Acc: 66.964% \n",
            "[epoch:43, iter:974] Loss: 0.834 | Acc: 67.578% \n",
            "[epoch:43, iter:975] Loss: 0.844 | Acc: 65.972% \n",
            "[epoch:43, iter:976] Loss: 0.859 | Acc: 64.688% \n",
            "[epoch:43, iter:977] Loss: 0.886 | Acc: 63.352% \n",
            "[epoch:43, iter:978] Loss: 0.879 | Acc: 64.062% \n",
            "[epoch:43, iter:979] Loss: 0.862 | Acc: 64.423% \n",
            "[epoch:43, iter:980] Loss: 0.877 | Acc: 64.062% \n",
            "[epoch:43, iter:981] Loss: 0.888 | Acc: 63.542% \n",
            "[epoch:43, iter:982] Loss: 0.890 | Acc: 62.500% \n",
            "[epoch:43, iter:983] Loss: 0.908 | Acc: 61.581% \n",
            "[epoch:43, iter:984] Loss: 0.900 | Acc: 62.153% \n",
            "[epoch:43, iter:985] Loss: 0.906 | Acc: 62.171% \n",
            "[epoch:43, iter:986] Loss: 0.890 | Acc: 62.656% \n",
            "[epoch:43, iter:987] Loss: 0.887 | Acc: 62.798% \n",
            "[epoch:43, iter:988] Loss: 0.894 | Acc: 62.074% \n",
            "[epoch:43, iter:989] Loss: 0.906 | Acc: 61.413% \n",
            "Waiting Test...\n",
            "Test's ac is: 21.212%\n",
            "\n",
            "Epoch: 44\n",
            "[epoch:44, iter:990] Loss: 0.918 | Acc: 50.000% \n",
            "[epoch:44, iter:991] Loss: 0.991 | Acc: 51.562% \n",
            "[epoch:44, iter:992] Loss: 0.962 | Acc: 57.292% \n",
            "[epoch:44, iter:993] Loss: 0.971 | Acc: 57.812% \n",
            "[epoch:44, iter:994] Loss: 0.979 | Acc: 57.500% \n",
            "[epoch:44, iter:995] Loss: 1.038 | Acc: 55.729% \n",
            "[epoch:44, iter:996] Loss: 1.001 | Acc: 58.036% \n",
            "[epoch:44, iter:997] Loss: 0.974 | Acc: 58.594% \n",
            "[epoch:44, iter:998] Loss: 0.963 | Acc: 59.028% \n",
            "[epoch:44, iter:999] Loss: 0.975 | Acc: 59.062% \n",
            "[epoch:44, iter:1000] Loss: 0.988 | Acc: 59.659% \n",
            "[epoch:44, iter:1001] Loss: 0.998 | Acc: 59.115% \n",
            "[epoch:44, iter:1002] Loss: 0.995 | Acc: 59.135% \n",
            "[epoch:44, iter:1003] Loss: 0.988 | Acc: 60.045% \n",
            "[epoch:44, iter:1004] Loss: 0.989 | Acc: 59.583% \n",
            "[epoch:44, iter:1005] Loss: 0.993 | Acc: 58.789% \n",
            "[epoch:44, iter:1006] Loss: 0.980 | Acc: 59.375% \n",
            "[epoch:44, iter:1007] Loss: 0.983 | Acc: 59.549% \n",
            "[epoch:44, iter:1008] Loss: 0.982 | Acc: 59.539% \n",
            "[epoch:44, iter:1009] Loss: 0.982 | Acc: 59.375% \n",
            "[epoch:44, iter:1010] Loss: 0.976 | Acc: 59.524% \n",
            "[epoch:44, iter:1011] Loss: 0.983 | Acc: 59.091% \n",
            "[epoch:44, iter:1012] Loss: 0.982 | Acc: 59.375% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 45\n",
            "[epoch:45, iter:1013] Loss: 0.935 | Acc: 50.000% \n",
            "[epoch:45, iter:1014] Loss: 0.883 | Acc: 62.500% \n",
            "[epoch:45, iter:1015] Loss: 0.876 | Acc: 64.583% \n",
            "[epoch:45, iter:1016] Loss: 0.893 | Acc: 61.719% \n",
            "[epoch:45, iter:1017] Loss: 0.874 | Acc: 62.500% \n",
            "[epoch:45, iter:1018] Loss: 0.830 | Acc: 64.583% \n",
            "[epoch:45, iter:1019] Loss: 0.832 | Acc: 65.179% \n",
            "[epoch:45, iter:1020] Loss: 0.820 | Acc: 66.406% \n",
            "[epoch:45, iter:1021] Loss: 0.846 | Acc: 64.931% \n",
            "[epoch:45, iter:1022] Loss: 0.853 | Acc: 63.750% \n",
            "[epoch:45, iter:1023] Loss: 0.835 | Acc: 64.205% \n",
            "[epoch:45, iter:1024] Loss: 0.845 | Acc: 64.062% \n",
            "[epoch:45, iter:1025] Loss: 0.860 | Acc: 62.740% \n",
            "[epoch:45, iter:1026] Loss: 0.871 | Acc: 62.054% \n",
            "[epoch:45, iter:1027] Loss: 0.880 | Acc: 61.250% \n",
            "[epoch:45, iter:1028] Loss: 0.870 | Acc: 61.914% \n",
            "[epoch:45, iter:1029] Loss: 0.874 | Acc: 61.397% \n",
            "[epoch:45, iter:1030] Loss: 0.878 | Acc: 61.806% \n",
            "[epoch:45, iter:1031] Loss: 0.870 | Acc: 62.171% \n",
            "[epoch:45, iter:1032] Loss: 0.864 | Acc: 62.812% \n",
            "[epoch:45, iter:1033] Loss: 0.871 | Acc: 62.798% \n",
            "[epoch:45, iter:1034] Loss: 0.888 | Acc: 62.216% \n",
            "[epoch:45, iter:1035] Loss: 0.889 | Acc: 61.821% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.818%\n",
            "\n",
            "Epoch: 46\n",
            "[epoch:46, iter:1036] Loss: 0.669 | Acc: 81.250% \n",
            "[epoch:46, iter:1037] Loss: 0.793 | Acc: 70.312% \n",
            "[epoch:46, iter:1038] Loss: 0.828 | Acc: 65.625% \n",
            "[epoch:46, iter:1039] Loss: 0.797 | Acc: 65.625% \n",
            "[epoch:46, iter:1040] Loss: 0.805 | Acc: 66.250% \n",
            "[epoch:46, iter:1041] Loss: 0.808 | Acc: 65.104% \n",
            "[epoch:46, iter:1042] Loss: 0.784 | Acc: 66.964% \n",
            "[epoch:46, iter:1043] Loss: 0.804 | Acc: 66.406% \n",
            "[epoch:46, iter:1044] Loss: 0.813 | Acc: 65.972% \n",
            "[epoch:46, iter:1045] Loss: 0.810 | Acc: 65.625% \n",
            "[epoch:46, iter:1046] Loss: 0.826 | Acc: 65.909% \n",
            "[epoch:46, iter:1047] Loss: 0.867 | Acc: 63.021% \n",
            "[epoch:46, iter:1048] Loss: 0.864 | Acc: 63.462% \n",
            "[epoch:46, iter:1049] Loss: 0.867 | Acc: 63.393% \n",
            "[epoch:46, iter:1050] Loss: 0.875 | Acc: 63.125% \n",
            "[epoch:46, iter:1051] Loss: 0.885 | Acc: 63.086% \n",
            "[epoch:46, iter:1052] Loss: 0.881 | Acc: 63.419% \n",
            "[epoch:46, iter:1053] Loss: 0.883 | Acc: 63.194% \n",
            "[epoch:46, iter:1054] Loss: 0.878 | Acc: 63.322% \n",
            "[epoch:46, iter:1055] Loss: 0.879 | Acc: 63.125% \n",
            "[epoch:46, iter:1056] Loss: 0.877 | Acc: 62.798% \n",
            "[epoch:46, iter:1057] Loss: 0.889 | Acc: 62.926% \n",
            "[epoch:46, iter:1058] Loss: 0.898 | Acc: 62.772% \n",
            "Waiting Test...\n",
            "Test's ac is: 27.273%\n",
            "\n",
            "Epoch: 47\n",
            "[epoch:47, iter:1059] Loss: 0.694 | Acc: 71.875% \n",
            "[epoch:47, iter:1060] Loss: 0.723 | Acc: 73.438% \n",
            "[epoch:47, iter:1061] Loss: 0.767 | Acc: 70.833% \n",
            "[epoch:47, iter:1062] Loss: 0.791 | Acc: 67.969% \n",
            "[epoch:47, iter:1063] Loss: 0.824 | Acc: 65.625% \n",
            "[epoch:47, iter:1064] Loss: 0.899 | Acc: 62.500% \n",
            "[epoch:47, iter:1065] Loss: 0.937 | Acc: 62.054% \n",
            "[epoch:47, iter:1066] Loss: 0.943 | Acc: 62.109% \n",
            "[epoch:47, iter:1067] Loss: 0.969 | Acc: 60.764% \n",
            "[epoch:47, iter:1068] Loss: 0.934 | Acc: 62.188% \n",
            "[epoch:47, iter:1069] Loss: 0.928 | Acc: 61.932% \n",
            "[epoch:47, iter:1070] Loss: 0.914 | Acc: 63.281% \n",
            "[epoch:47, iter:1071] Loss: 0.915 | Acc: 63.221% \n",
            "[epoch:47, iter:1072] Loss: 0.911 | Acc: 63.393% \n",
            "[epoch:47, iter:1073] Loss: 0.911 | Acc: 62.917% \n",
            "[epoch:47, iter:1074] Loss: 0.910 | Acc: 62.891% \n",
            "[epoch:47, iter:1075] Loss: 0.903 | Acc: 63.419% \n",
            "[epoch:47, iter:1076] Loss: 0.911 | Acc: 63.021% \n",
            "[epoch:47, iter:1077] Loss: 0.911 | Acc: 62.829% \n",
            "[epoch:47, iter:1078] Loss: 0.907 | Acc: 63.438% \n",
            "[epoch:47, iter:1079] Loss: 0.905 | Acc: 63.839% \n",
            "[epoch:47, iter:1080] Loss: 0.896 | Acc: 64.062% \n",
            "[epoch:47, iter:1081] Loss: 0.894 | Acc: 64.266% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.848%\n",
            "\n",
            "Epoch: 48\n",
            "[epoch:48, iter:1082] Loss: 0.650 | Acc: 75.000% \n",
            "[epoch:48, iter:1083] Loss: 0.716 | Acc: 71.875% \n",
            "[epoch:48, iter:1084] Loss: 0.811 | Acc: 65.625% \n",
            "[epoch:48, iter:1085] Loss: 0.835 | Acc: 63.281% \n",
            "[epoch:48, iter:1086] Loss: 0.886 | Acc: 62.500% \n",
            "[epoch:48, iter:1087] Loss: 0.818 | Acc: 66.667% \n",
            "[epoch:48, iter:1088] Loss: 0.846 | Acc: 66.071% \n",
            "[epoch:48, iter:1089] Loss: 0.863 | Acc: 65.625% \n",
            "[epoch:48, iter:1090] Loss: 0.843 | Acc: 65.972% \n",
            "[epoch:48, iter:1091] Loss: 0.836 | Acc: 66.562% \n",
            "[epoch:48, iter:1092] Loss: 0.820 | Acc: 66.477% \n",
            "[epoch:48, iter:1093] Loss: 0.817 | Acc: 66.146% \n",
            "[epoch:48, iter:1094] Loss: 0.809 | Acc: 66.346% \n",
            "[epoch:48, iter:1095] Loss: 0.808 | Acc: 66.295% \n",
            "[epoch:48, iter:1096] Loss: 0.814 | Acc: 65.625% \n",
            "[epoch:48, iter:1097] Loss: 0.813 | Acc: 65.820% \n",
            "[epoch:48, iter:1098] Loss: 0.810 | Acc: 65.441% \n",
            "[epoch:48, iter:1099] Loss: 0.807 | Acc: 65.799% \n",
            "[epoch:48, iter:1100] Loss: 0.811 | Acc: 65.625% \n",
            "[epoch:48, iter:1101] Loss: 0.804 | Acc: 65.781% \n",
            "[epoch:48, iter:1102] Loss: 0.803 | Acc: 65.923% \n",
            "[epoch:48, iter:1103] Loss: 0.800 | Acc: 66.193% \n",
            "[epoch:48, iter:1104] Loss: 0.811 | Acc: 65.761% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.818%\n",
            "\n",
            "Epoch: 49\n",
            "[epoch:49, iter:1105] Loss: 0.892 | Acc: 62.500% \n",
            "[epoch:49, iter:1106] Loss: 0.953 | Acc: 60.938% \n",
            "[epoch:49, iter:1107] Loss: 0.781 | Acc: 69.792% \n",
            "[epoch:49, iter:1108] Loss: 0.809 | Acc: 67.188% \n",
            "[epoch:49, iter:1109] Loss: 0.771 | Acc: 68.125% \n",
            "[epoch:49, iter:1110] Loss: 0.802 | Acc: 66.667% \n",
            "[epoch:49, iter:1111] Loss: 0.828 | Acc: 64.732% \n",
            "[epoch:49, iter:1112] Loss: 0.832 | Acc: 64.062% \n",
            "[epoch:49, iter:1113] Loss: 0.812 | Acc: 65.625% \n",
            "[epoch:49, iter:1114] Loss: 0.812 | Acc: 65.625% \n",
            "[epoch:49, iter:1115] Loss: 0.805 | Acc: 66.477% \n",
            "[epoch:49, iter:1116] Loss: 0.795 | Acc: 66.927% \n",
            "[epoch:49, iter:1117] Loss: 0.816 | Acc: 65.865% \n",
            "[epoch:49, iter:1118] Loss: 0.832 | Acc: 65.402% \n",
            "[epoch:49, iter:1119] Loss: 0.850 | Acc: 64.583% \n",
            "[epoch:49, iter:1120] Loss: 0.853 | Acc: 64.844% \n",
            "[epoch:49, iter:1121] Loss: 0.855 | Acc: 64.338% \n",
            "[epoch:49, iter:1122] Loss: 0.859 | Acc: 64.583% \n",
            "[epoch:49, iter:1123] Loss: 0.866 | Acc: 64.309% \n",
            "[epoch:49, iter:1124] Loss: 0.870 | Acc: 63.906% \n",
            "[epoch:49, iter:1125] Loss: 0.880 | Acc: 63.839% \n",
            "[epoch:49, iter:1126] Loss: 0.883 | Acc: 63.920% \n",
            "[epoch:49, iter:1127] Loss: 0.886 | Acc: 63.859% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 50\n",
            "[epoch:50, iter:1128] Loss: 0.754 | Acc: 65.625% \n",
            "[epoch:50, iter:1129] Loss: 0.782 | Acc: 64.062% \n",
            "[epoch:50, iter:1130] Loss: 0.802 | Acc: 65.625% \n",
            "[epoch:50, iter:1131] Loss: 0.782 | Acc: 65.625% \n",
            "[epoch:50, iter:1132] Loss: 0.749 | Acc: 68.125% \n",
            "[epoch:50, iter:1133] Loss: 0.737 | Acc: 68.229% \n",
            "[epoch:50, iter:1134] Loss: 0.781 | Acc: 65.625% \n",
            "[epoch:50, iter:1135] Loss: 0.793 | Acc: 65.625% \n",
            "[epoch:50, iter:1136] Loss: 0.781 | Acc: 66.667% \n",
            "[epoch:50, iter:1137] Loss: 0.782 | Acc: 66.250% \n",
            "[epoch:50, iter:1138] Loss: 0.785 | Acc: 66.761% \n",
            "[epoch:50, iter:1139] Loss: 0.778 | Acc: 67.969% \n",
            "[epoch:50, iter:1140] Loss: 0.774 | Acc: 67.788% \n",
            "[epoch:50, iter:1141] Loss: 0.765 | Acc: 68.304% \n",
            "[epoch:50, iter:1142] Loss: 0.762 | Acc: 68.333% \n",
            "[epoch:50, iter:1143] Loss: 0.753 | Acc: 69.336% \n",
            "[epoch:50, iter:1144] Loss: 0.769 | Acc: 68.750% \n",
            "[epoch:50, iter:1145] Loss: 0.766 | Acc: 68.576% \n",
            "[epoch:50, iter:1146] Loss: 0.775 | Acc: 68.257% \n",
            "[epoch:50, iter:1147] Loss: 0.794 | Acc: 67.656% \n",
            "[epoch:50, iter:1148] Loss: 0.798 | Acc: 67.411% \n",
            "[epoch:50, iter:1149] Loss: 0.802 | Acc: 67.188% \n",
            "[epoch:50, iter:1150] Loss: 0.800 | Acc: 67.120% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.152%\n",
            "\n",
            "Epoch: 51\n",
            "[epoch:51, iter:1151] Loss: 0.625 | Acc: 75.000% \n",
            "[epoch:51, iter:1152] Loss: 0.796 | Acc: 68.750% \n",
            "[epoch:51, iter:1153] Loss: 0.697 | Acc: 72.917% \n",
            "[epoch:51, iter:1154] Loss: 0.709 | Acc: 70.312% \n",
            "[epoch:51, iter:1155] Loss: 0.747 | Acc: 68.750% \n",
            "[epoch:51, iter:1156] Loss: 0.760 | Acc: 65.625% \n",
            "[epoch:51, iter:1157] Loss: 0.775 | Acc: 65.625% \n",
            "[epoch:51, iter:1158] Loss: 0.799 | Acc: 65.625% \n",
            "[epoch:51, iter:1159] Loss: 0.816 | Acc: 64.931% \n",
            "[epoch:51, iter:1160] Loss: 0.823 | Acc: 65.000% \n",
            "[epoch:51, iter:1161] Loss: 0.825 | Acc: 65.341% \n",
            "[epoch:51, iter:1162] Loss: 0.814 | Acc: 65.365% \n",
            "[epoch:51, iter:1163] Loss: 0.826 | Acc: 64.183% \n",
            "[epoch:51, iter:1164] Loss: 0.839 | Acc: 63.616% \n",
            "[epoch:51, iter:1165] Loss: 0.827 | Acc: 64.375% \n",
            "[epoch:51, iter:1166] Loss: 0.822 | Acc: 63.867% \n",
            "[epoch:51, iter:1167] Loss: 0.832 | Acc: 63.603% \n",
            "[epoch:51, iter:1168] Loss: 0.841 | Acc: 63.021% \n",
            "[epoch:51, iter:1169] Loss: 0.844 | Acc: 62.993% \n",
            "[epoch:51, iter:1170] Loss: 0.844 | Acc: 63.281% \n",
            "[epoch:51, iter:1171] Loss: 0.850 | Acc: 62.946% \n",
            "[epoch:51, iter:1172] Loss: 0.846 | Acc: 63.210% \n",
            "[epoch:51, iter:1173] Loss: 0.854 | Acc: 62.636% \n",
            "Waiting Test...\n",
            "Test's ac is: 33.333%\n",
            "\n",
            "Epoch: 52\n",
            "[epoch:52, iter:1174] Loss: 0.846 | Acc: 68.750% \n",
            "[epoch:52, iter:1175] Loss: 0.800 | Acc: 67.188% \n",
            "[epoch:52, iter:1176] Loss: 0.793 | Acc: 67.708% \n",
            "[epoch:52, iter:1177] Loss: 0.791 | Acc: 67.188% \n",
            "[epoch:52, iter:1178] Loss: 0.791 | Acc: 67.500% \n",
            "[epoch:52, iter:1179] Loss: 0.797 | Acc: 66.667% \n",
            "[epoch:52, iter:1180] Loss: 0.770 | Acc: 67.857% \n",
            "[epoch:52, iter:1181] Loss: 0.809 | Acc: 64.453% \n",
            "[epoch:52, iter:1182] Loss: 0.810 | Acc: 64.236% \n",
            "[epoch:52, iter:1183] Loss: 0.801 | Acc: 64.375% \n",
            "[epoch:52, iter:1184] Loss: 0.801 | Acc: 65.057% \n",
            "[epoch:52, iter:1185] Loss: 0.796 | Acc: 66.146% \n",
            "[epoch:52, iter:1186] Loss: 0.783 | Acc: 67.548% \n",
            "[epoch:52, iter:1187] Loss: 0.776 | Acc: 67.634% \n",
            "[epoch:52, iter:1188] Loss: 0.777 | Acc: 67.500% \n",
            "[epoch:52, iter:1189] Loss: 0.790 | Acc: 67.188% \n",
            "[epoch:52, iter:1190] Loss: 0.790 | Acc: 67.096% \n",
            "[epoch:52, iter:1191] Loss: 0.799 | Acc: 66.146% \n",
            "[epoch:52, iter:1192] Loss: 0.800 | Acc: 66.118% \n",
            "[epoch:52, iter:1193] Loss: 0.791 | Acc: 66.875% \n",
            "[epoch:52, iter:1194] Loss: 0.788 | Acc: 67.262% \n",
            "[epoch:52, iter:1195] Loss: 0.788 | Acc: 67.188% \n",
            "[epoch:52, iter:1196] Loss: 0.788 | Acc: 66.984% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.152%\n",
            "\n",
            "Epoch: 53\n",
            "[epoch:53, iter:1197] Loss: 0.692 | Acc: 65.625% \n",
            "[epoch:53, iter:1198] Loss: 0.717 | Acc: 68.750% \n",
            "[epoch:53, iter:1199] Loss: 0.738 | Acc: 69.792% \n",
            "[epoch:53, iter:1200] Loss: 0.714 | Acc: 71.094% \n",
            "[epoch:53, iter:1201] Loss: 0.687 | Acc: 73.125% \n",
            "[epoch:53, iter:1202] Loss: 0.653 | Acc: 74.479% \n",
            "[epoch:53, iter:1203] Loss: 0.632 | Acc: 75.446% \n",
            "[epoch:53, iter:1204] Loss: 0.633 | Acc: 74.609% \n",
            "[epoch:53, iter:1205] Loss: 0.630 | Acc: 74.306% \n",
            "[epoch:53, iter:1206] Loss: 0.667 | Acc: 72.500% \n",
            "[epoch:53, iter:1207] Loss: 0.692 | Acc: 71.875% \n",
            "[epoch:53, iter:1208] Loss: 0.710 | Acc: 70.312% \n",
            "[epoch:53, iter:1209] Loss: 0.717 | Acc: 69.952% \n",
            "[epoch:53, iter:1210] Loss: 0.718 | Acc: 68.973% \n",
            "[epoch:53, iter:1211] Loss: 0.713 | Acc: 69.375% \n",
            "[epoch:53, iter:1212] Loss: 0.726 | Acc: 68.555% \n",
            "[epoch:53, iter:1213] Loss: 0.740 | Acc: 68.015% \n",
            "[epoch:53, iter:1214] Loss: 0.740 | Acc: 68.576% \n",
            "[epoch:53, iter:1215] Loss: 0.728 | Acc: 69.243% \n",
            "[epoch:53, iter:1216] Loss: 0.724 | Acc: 69.688% \n",
            "[epoch:53, iter:1217] Loss: 0.724 | Acc: 69.643% \n",
            "[epoch:53, iter:1218] Loss: 0.734 | Acc: 69.460% \n",
            "[epoch:53, iter:1219] Loss: 0.729 | Acc: 69.837% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.030%\n",
            "\n",
            "Epoch: 54\n",
            "[epoch:54, iter:1220] Loss: 0.709 | Acc: 68.750% \n",
            "[epoch:54, iter:1221] Loss: 0.691 | Acc: 70.312% \n",
            "[epoch:54, iter:1222] Loss: 0.715 | Acc: 69.792% \n",
            "[epoch:54, iter:1223] Loss: 0.737 | Acc: 71.094% \n",
            "[epoch:54, iter:1224] Loss: 0.687 | Acc: 73.750% \n",
            "[epoch:54, iter:1225] Loss: 0.658 | Acc: 75.521% \n",
            "[epoch:54, iter:1226] Loss: 0.640 | Acc: 75.893% \n",
            "[epoch:54, iter:1227] Loss: 0.656 | Acc: 74.219% \n",
            "[epoch:54, iter:1228] Loss: 0.664 | Acc: 73.958% \n",
            "[epoch:54, iter:1229] Loss: 0.687 | Acc: 72.188% \n",
            "[epoch:54, iter:1230] Loss: 0.705 | Acc: 72.159% \n",
            "[epoch:54, iter:1231] Loss: 0.692 | Acc: 73.177% \n",
            "[epoch:54, iter:1232] Loss: 0.686 | Acc: 73.077% \n",
            "[epoch:54, iter:1233] Loss: 0.688 | Acc: 72.545% \n",
            "[epoch:54, iter:1234] Loss: 0.683 | Acc: 72.917% \n",
            "[epoch:54, iter:1235] Loss: 0.704 | Acc: 71.680% \n",
            "[epoch:54, iter:1236] Loss: 0.697 | Acc: 71.875% \n",
            "[epoch:54, iter:1237] Loss: 0.703 | Acc: 71.528% \n",
            "[epoch:54, iter:1238] Loss: 0.710 | Acc: 70.888% \n",
            "[epoch:54, iter:1239] Loss: 0.718 | Acc: 70.781% \n",
            "[epoch:54, iter:1240] Loss: 0.713 | Acc: 71.280% \n",
            "[epoch:54, iter:1241] Loss: 0.722 | Acc: 71.165% \n",
            "[epoch:54, iter:1242] Loss: 0.712 | Acc: 71.603% \n",
            "Waiting Test...\n",
            "Test's ac is: 23.485%\n",
            "\n",
            "Epoch: 55\n",
            "[epoch:55, iter:1243] Loss: 0.707 | Acc: 68.750% \n",
            "[epoch:55, iter:1244] Loss: 0.604 | Acc: 75.000% \n",
            "[epoch:55, iter:1245] Loss: 0.658 | Acc: 72.917% \n",
            "[epoch:55, iter:1246] Loss: 0.663 | Acc: 72.656% \n",
            "[epoch:55, iter:1247] Loss: 0.672 | Acc: 71.875% \n",
            "[epoch:55, iter:1248] Loss: 0.688 | Acc: 71.875% \n",
            "[epoch:55, iter:1249] Loss: 0.710 | Acc: 71.429% \n",
            "[epoch:55, iter:1250] Loss: 0.699 | Acc: 71.875% \n",
            "[epoch:55, iter:1251] Loss: 0.759 | Acc: 69.444% \n",
            "[epoch:55, iter:1252] Loss: 0.773 | Acc: 68.438% \n",
            "[epoch:55, iter:1253] Loss: 0.783 | Acc: 67.614% \n",
            "[epoch:55, iter:1254] Loss: 0.798 | Acc: 66.927% \n",
            "[epoch:55, iter:1255] Loss: 0.785 | Acc: 67.308% \n",
            "[epoch:55, iter:1256] Loss: 0.785 | Acc: 66.964% \n",
            "[epoch:55, iter:1257] Loss: 0.786 | Acc: 66.458% \n",
            "[epoch:55, iter:1258] Loss: 0.772 | Acc: 67.188% \n",
            "[epoch:55, iter:1259] Loss: 0.796 | Acc: 66.544% \n",
            "[epoch:55, iter:1260] Loss: 0.795 | Acc: 66.840% \n",
            "[epoch:55, iter:1261] Loss: 0.789 | Acc: 67.105% \n",
            "[epoch:55, iter:1262] Loss: 0.794 | Acc: 67.031% \n",
            "[epoch:55, iter:1263] Loss: 0.803 | Acc: 66.815% \n",
            "[epoch:55, iter:1264] Loss: 0.812 | Acc: 66.335% \n",
            "[epoch:55, iter:1265] Loss: 0.820 | Acc: 65.897% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.121%\n",
            "\n",
            "Epoch: 56\n",
            "[epoch:56, iter:1266] Loss: 0.732 | Acc: 68.750% \n",
            "[epoch:56, iter:1267] Loss: 0.688 | Acc: 73.438% \n",
            "[epoch:56, iter:1268] Loss: 0.678 | Acc: 71.875% \n",
            "[epoch:56, iter:1269] Loss: 0.682 | Acc: 71.875% \n",
            "[epoch:56, iter:1270] Loss: 0.734 | Acc: 71.250% \n",
            "[epoch:56, iter:1271] Loss: 0.740 | Acc: 72.396% \n",
            "[epoch:56, iter:1272] Loss: 0.772 | Acc: 69.643% \n",
            "[epoch:56, iter:1273] Loss: 0.769 | Acc: 68.750% \n",
            "[epoch:56, iter:1274] Loss: 0.732 | Acc: 69.792% \n",
            "[epoch:56, iter:1275] Loss: 0.722 | Acc: 71.250% \n",
            "[epoch:56, iter:1276] Loss: 0.731 | Acc: 70.170% \n",
            "[epoch:56, iter:1277] Loss: 0.741 | Acc: 69.531% \n",
            "[epoch:56, iter:1278] Loss: 0.732 | Acc: 70.192% \n",
            "[epoch:56, iter:1279] Loss: 0.742 | Acc: 69.866% \n",
            "[epoch:56, iter:1280] Loss: 0.743 | Acc: 70.000% \n",
            "[epoch:56, iter:1281] Loss: 0.751 | Acc: 70.117% \n",
            "[epoch:56, iter:1282] Loss: 0.747 | Acc: 70.221% \n",
            "[epoch:56, iter:1283] Loss: 0.752 | Acc: 70.312% \n",
            "[epoch:56, iter:1284] Loss: 0.756 | Acc: 69.901% \n",
            "[epoch:56, iter:1285] Loss: 0.757 | Acc: 69.531% \n",
            "[epoch:56, iter:1286] Loss: 0.752 | Acc: 69.940% \n",
            "[epoch:56, iter:1287] Loss: 0.753 | Acc: 70.170% \n",
            "[epoch:56, iter:1288] Loss: 0.759 | Acc: 69.837% \n",
            "Waiting Test...\n",
            "Test's ac is: 25.000%\n",
            "\n",
            "Epoch: 57\n",
            "[epoch:57, iter:1289] Loss: 0.704 | Acc: 62.500% \n",
            "[epoch:57, iter:1290] Loss: 0.587 | Acc: 73.438% \n",
            "[epoch:57, iter:1291] Loss: 0.546 | Acc: 77.083% \n",
            "[epoch:57, iter:1292] Loss: 0.591 | Acc: 74.219% \n",
            "[epoch:57, iter:1293] Loss: 0.569 | Acc: 74.375% \n",
            "[epoch:57, iter:1294] Loss: 0.575 | Acc: 73.438% \n",
            "[epoch:57, iter:1295] Loss: 0.567 | Acc: 74.107% \n",
            "[epoch:57, iter:1296] Loss: 0.560 | Acc: 75.391% \n",
            "[epoch:57, iter:1297] Loss: 0.570 | Acc: 75.000% \n",
            "[epoch:57, iter:1298] Loss: 0.604 | Acc: 73.125% \n",
            "[epoch:57, iter:1299] Loss: 0.595 | Acc: 73.011% \n",
            "[epoch:57, iter:1300] Loss: 0.612 | Acc: 73.438% \n",
            "[epoch:57, iter:1301] Loss: 0.616 | Acc: 73.558% \n",
            "[epoch:57, iter:1302] Loss: 0.616 | Acc: 73.438% \n",
            "[epoch:57, iter:1303] Loss: 0.622 | Acc: 73.125% \n",
            "[epoch:57, iter:1304] Loss: 0.616 | Acc: 73.438% \n",
            "[epoch:57, iter:1305] Loss: 0.621 | Acc: 73.529% \n",
            "[epoch:57, iter:1306] Loss: 0.629 | Acc: 73.438% \n",
            "[epoch:57, iter:1307] Loss: 0.626 | Acc: 73.355% \n",
            "[epoch:57, iter:1308] Loss: 0.630 | Acc: 73.281% \n",
            "[epoch:57, iter:1309] Loss: 0.638 | Acc: 72.917% \n",
            "[epoch:57, iter:1310] Loss: 0.650 | Acc: 72.443% \n",
            "[epoch:57, iter:1311] Loss: 0.652 | Acc: 72.690% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.152%\n",
            "\n",
            "Epoch: 58\n",
            "[epoch:58, iter:1312] Loss: 0.944 | Acc: 68.750% \n",
            "[epoch:58, iter:1313] Loss: 0.969 | Acc: 67.188% \n",
            "[epoch:58, iter:1314] Loss: 0.905 | Acc: 68.750% \n",
            "[epoch:58, iter:1315] Loss: 0.817 | Acc: 71.094% \n",
            "[epoch:58, iter:1316] Loss: 0.835 | Acc: 69.375% \n",
            "[epoch:58, iter:1317] Loss: 0.815 | Acc: 68.750% \n",
            "[epoch:58, iter:1318] Loss: 0.829 | Acc: 68.750% \n",
            "[epoch:58, iter:1319] Loss: 0.781 | Acc: 70.312% \n",
            "[epoch:58, iter:1320] Loss: 0.799 | Acc: 69.097% \n",
            "[epoch:58, iter:1321] Loss: 0.817 | Acc: 67.500% \n",
            "[epoch:58, iter:1322] Loss: 0.803 | Acc: 69.034% \n",
            "[epoch:58, iter:1323] Loss: 0.777 | Acc: 69.792% \n",
            "[epoch:58, iter:1324] Loss: 0.759 | Acc: 70.673% \n",
            "[epoch:58, iter:1325] Loss: 0.753 | Acc: 70.312% \n",
            "[epoch:58, iter:1326] Loss: 0.737 | Acc: 71.042% \n",
            "[epoch:58, iter:1327] Loss: 0.730 | Acc: 71.680% \n",
            "[epoch:58, iter:1328] Loss: 0.729 | Acc: 71.507% \n",
            "[epoch:58, iter:1329] Loss: 0.743 | Acc: 70.833% \n",
            "[epoch:58, iter:1330] Loss: 0.756 | Acc: 70.230% \n",
            "[epoch:58, iter:1331] Loss: 0.760 | Acc: 70.000% \n",
            "[epoch:58, iter:1332] Loss: 0.756 | Acc: 70.089% \n",
            "[epoch:58, iter:1333] Loss: 0.746 | Acc: 70.739% \n",
            "[epoch:58, iter:1334] Loss: 0.749 | Acc: 70.516% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.121%\n",
            "\n",
            "Epoch: 59\n",
            "[epoch:59, iter:1335] Loss: 0.749 | Acc: 65.625% \n",
            "[epoch:59, iter:1336] Loss: 0.659 | Acc: 70.312% \n",
            "[epoch:59, iter:1337] Loss: 0.608 | Acc: 75.000% \n",
            "[epoch:59, iter:1338] Loss: 0.615 | Acc: 75.781% \n",
            "[epoch:59, iter:1339] Loss: 0.617 | Acc: 75.625% \n",
            "[epoch:59, iter:1340] Loss: 0.646 | Acc: 73.958% \n",
            "[epoch:59, iter:1341] Loss: 0.660 | Acc: 73.214% \n",
            "[epoch:59, iter:1342] Loss: 0.662 | Acc: 73.828% \n",
            "[epoch:59, iter:1343] Loss: 0.653 | Acc: 74.653% \n",
            "[epoch:59, iter:1344] Loss: 0.639 | Acc: 74.375% \n",
            "[epoch:59, iter:1345] Loss: 0.631 | Acc: 74.716% \n",
            "[epoch:59, iter:1346] Loss: 0.641 | Acc: 74.479% \n",
            "[epoch:59, iter:1347] Loss: 0.630 | Acc: 74.519% \n",
            "[epoch:59, iter:1348] Loss: 0.621 | Acc: 74.554% \n",
            "[epoch:59, iter:1349] Loss: 0.630 | Acc: 73.750% \n",
            "[epoch:59, iter:1350] Loss: 0.624 | Acc: 74.023% \n",
            "[epoch:59, iter:1351] Loss: 0.620 | Acc: 74.081% \n",
            "[epoch:59, iter:1352] Loss: 0.633 | Acc: 73.438% \n",
            "[epoch:59, iter:1353] Loss: 0.641 | Acc: 73.355% \n",
            "[epoch:59, iter:1354] Loss: 0.651 | Acc: 73.125% \n",
            "[epoch:59, iter:1355] Loss: 0.653 | Acc: 72.917% \n",
            "[epoch:59, iter:1356] Loss: 0.645 | Acc: 73.153% \n",
            "[epoch:59, iter:1357] Loss: 0.645 | Acc: 73.098% \n",
            "Waiting Test...\n",
            "Test's ac is: 29.545%\n",
            "\n",
            "Epoch: 60\n",
            "[epoch:60, iter:1358] Loss: 0.831 | Acc: 62.500% \n",
            "[epoch:60, iter:1359] Loss: 0.796 | Acc: 62.500% \n",
            "[epoch:60, iter:1360] Loss: 0.692 | Acc: 68.750% \n",
            "[epoch:60, iter:1361] Loss: 0.669 | Acc: 68.750% \n",
            "[epoch:60, iter:1362] Loss: 0.689 | Acc: 70.000% \n",
            "[epoch:60, iter:1363] Loss: 0.700 | Acc: 69.271% \n",
            "[epoch:60, iter:1364] Loss: 0.675 | Acc: 71.429% \n",
            "[epoch:60, iter:1365] Loss: 0.633 | Acc: 73.438% \n",
            "[epoch:60, iter:1366] Loss: 0.658 | Acc: 72.917% \n",
            "[epoch:60, iter:1367] Loss: 0.678 | Acc: 72.812% \n",
            "[epoch:60, iter:1368] Loss: 0.679 | Acc: 72.443% \n",
            "[epoch:60, iter:1369] Loss: 0.686 | Acc: 72.396% \n",
            "[epoch:60, iter:1370] Loss: 0.681 | Acc: 72.837% \n",
            "[epoch:60, iter:1371] Loss: 0.676 | Acc: 72.098% \n",
            "[epoch:60, iter:1372] Loss: 0.663 | Acc: 72.292% \n",
            "[epoch:60, iter:1373] Loss: 0.657 | Acc: 72.266% \n",
            "[epoch:60, iter:1374] Loss: 0.667 | Acc: 72.243% \n",
            "[epoch:60, iter:1375] Loss: 0.682 | Acc: 72.569% \n",
            "[epoch:60, iter:1376] Loss: 0.684 | Acc: 73.026% \n",
            "[epoch:60, iter:1377] Loss: 0.695 | Acc: 72.500% \n",
            "[epoch:60, iter:1378] Loss: 0.711 | Acc: 72.470% \n",
            "[epoch:60, iter:1379] Loss: 0.704 | Acc: 72.727% \n",
            "[epoch:60, iter:1380] Loss: 0.698 | Acc: 72.554% \n",
            "Waiting Test...\n",
            "Test's ac is: 17.424%\n",
            "\n",
            "Epoch: 61\n",
            "[epoch:61, iter:1381] Loss: 0.534 | Acc: 84.375% \n",
            "[epoch:61, iter:1382] Loss: 0.577 | Acc: 78.125% \n",
            "[epoch:61, iter:1383] Loss: 0.610 | Acc: 78.125% \n",
            "[epoch:61, iter:1384] Loss: 0.640 | Acc: 75.781% \n",
            "[epoch:61, iter:1385] Loss: 0.697 | Acc: 72.500% \n",
            "[epoch:61, iter:1386] Loss: 0.731 | Acc: 71.354% \n",
            "[epoch:61, iter:1387] Loss: 0.738 | Acc: 71.429% \n",
            "[epoch:61, iter:1388] Loss: 0.744 | Acc: 71.094% \n",
            "[epoch:61, iter:1389] Loss: 0.721 | Acc: 71.875% \n",
            "[epoch:61, iter:1390] Loss: 0.739 | Acc: 71.562% \n",
            "[epoch:61, iter:1391] Loss: 0.745 | Acc: 71.875% \n",
            "[epoch:61, iter:1392] Loss: 0.745 | Acc: 71.354% \n",
            "[epoch:61, iter:1393] Loss: 0.730 | Acc: 72.115% \n",
            "[epoch:61, iter:1394] Loss: 0.719 | Acc: 72.545% \n",
            "[epoch:61, iter:1395] Loss: 0.709 | Acc: 73.125% \n",
            "[epoch:61, iter:1396] Loss: 0.708 | Acc: 73.438% \n",
            "[epoch:61, iter:1397] Loss: 0.713 | Acc: 72.978% \n",
            "[epoch:61, iter:1398] Loss: 0.719 | Acc: 72.743% \n",
            "[epoch:61, iter:1399] Loss: 0.721 | Acc: 72.204% \n",
            "[epoch:61, iter:1400] Loss: 0.721 | Acc: 72.344% \n",
            "[epoch:61, iter:1401] Loss: 0.710 | Acc: 72.321% \n",
            "[epoch:61, iter:1402] Loss: 0.701 | Acc: 72.727% \n",
            "[epoch:61, iter:1403] Loss: 0.687 | Acc: 73.370% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 62\n",
            "[epoch:62, iter:1404] Loss: 0.902 | Acc: 68.750% \n",
            "[epoch:62, iter:1405] Loss: 0.715 | Acc: 75.000% \n",
            "[epoch:62, iter:1406] Loss: 0.756 | Acc: 72.917% \n",
            "[epoch:62, iter:1407] Loss: 0.709 | Acc: 74.219% \n",
            "[epoch:62, iter:1408] Loss: 0.693 | Acc: 73.125% \n",
            "[epoch:62, iter:1409] Loss: 0.670 | Acc: 73.958% \n",
            "[epoch:62, iter:1410] Loss: 0.659 | Acc: 73.661% \n",
            "[epoch:62, iter:1411] Loss: 0.648 | Acc: 75.000% \n",
            "[epoch:62, iter:1412] Loss: 0.652 | Acc: 75.000% \n",
            "[epoch:62, iter:1413] Loss: 0.637 | Acc: 75.312% \n",
            "[epoch:62, iter:1414] Loss: 0.621 | Acc: 76.136% \n",
            "[epoch:62, iter:1415] Loss: 0.617 | Acc: 75.781% \n",
            "[epoch:62, iter:1416] Loss: 0.604 | Acc: 76.442% \n",
            "[epoch:62, iter:1417] Loss: 0.596 | Acc: 76.786% \n",
            "[epoch:62, iter:1418] Loss: 0.597 | Acc: 76.667% \n",
            "[epoch:62, iter:1419] Loss: 0.588 | Acc: 76.758% \n",
            "[epoch:62, iter:1420] Loss: 0.609 | Acc: 76.103% \n",
            "[epoch:62, iter:1421] Loss: 0.615 | Acc: 75.868% \n",
            "[epoch:62, iter:1422] Loss: 0.605 | Acc: 75.987% \n",
            "[epoch:62, iter:1423] Loss: 0.627 | Acc: 75.469% \n",
            "[epoch:62, iter:1424] Loss: 0.629 | Acc: 75.149% \n",
            "[epoch:62, iter:1425] Loss: 0.622 | Acc: 75.710% \n",
            "[epoch:62, iter:1426] Loss: 0.639 | Acc: 75.408% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.091%\n",
            "\n",
            "Epoch: 63\n",
            "[epoch:63, iter:1427] Loss: 0.510 | Acc: 81.250% \n",
            "[epoch:63, iter:1428] Loss: 0.655 | Acc: 73.438% \n",
            "[epoch:63, iter:1429] Loss: 0.772 | Acc: 70.833% \n",
            "[epoch:63, iter:1430] Loss: 0.724 | Acc: 72.656% \n",
            "[epoch:63, iter:1431] Loss: 0.708 | Acc: 71.875% \n",
            "[epoch:63, iter:1432] Loss: 0.697 | Acc: 72.917% \n",
            "[epoch:63, iter:1433] Loss: 0.663 | Acc: 74.107% \n",
            "[epoch:63, iter:1434] Loss: 0.642 | Acc: 75.391% \n",
            "[epoch:63, iter:1435] Loss: 0.672 | Acc: 72.917% \n",
            "[epoch:63, iter:1436] Loss: 0.680 | Acc: 72.812% \n",
            "[epoch:63, iter:1437] Loss: 0.687 | Acc: 72.727% \n",
            "[epoch:63, iter:1438] Loss: 0.681 | Acc: 73.177% \n",
            "[epoch:63, iter:1439] Loss: 0.676 | Acc: 72.837% \n",
            "[epoch:63, iter:1440] Loss: 0.685 | Acc: 72.545% \n",
            "[epoch:63, iter:1441] Loss: 0.676 | Acc: 72.917% \n",
            "[epoch:63, iter:1442] Loss: 0.659 | Acc: 73.438% \n",
            "[epoch:63, iter:1443] Loss: 0.662 | Acc: 72.978% \n",
            "[epoch:63, iter:1444] Loss: 0.665 | Acc: 73.090% \n",
            "[epoch:63, iter:1445] Loss: 0.667 | Acc: 73.191% \n",
            "[epoch:63, iter:1446] Loss: 0.668 | Acc: 73.281% \n",
            "[epoch:63, iter:1447] Loss: 0.671 | Acc: 72.917% \n",
            "[epoch:63, iter:1448] Loss: 0.665 | Acc: 73.295% \n",
            "[epoch:63, iter:1449] Loss: 0.668 | Acc: 73.098% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.030%\n",
            "\n",
            "Epoch: 64\n",
            "[epoch:64, iter:1450] Loss: 0.744 | Acc: 68.750% \n",
            "[epoch:64, iter:1451] Loss: 0.606 | Acc: 76.562% \n",
            "[epoch:64, iter:1452] Loss: 0.657 | Acc: 72.917% \n",
            "[epoch:64, iter:1453] Loss: 0.639 | Acc: 74.219% \n",
            "[epoch:64, iter:1454] Loss: 0.616 | Acc: 75.000% \n",
            "[epoch:64, iter:1455] Loss: 0.622 | Acc: 75.521% \n",
            "[epoch:64, iter:1456] Loss: 0.619 | Acc: 75.446% \n",
            "[epoch:64, iter:1457] Loss: 0.614 | Acc: 75.781% \n",
            "[epoch:64, iter:1458] Loss: 0.613 | Acc: 75.000% \n",
            "[epoch:64, iter:1459] Loss: 0.669 | Acc: 73.438% \n",
            "[epoch:64, iter:1460] Loss: 0.648 | Acc: 74.432% \n",
            "[epoch:64, iter:1461] Loss: 0.620 | Acc: 76.042% \n",
            "[epoch:64, iter:1462] Loss: 0.594 | Acc: 77.644% \n",
            "[epoch:64, iter:1463] Loss: 0.593 | Acc: 77.455% \n",
            "[epoch:64, iter:1464] Loss: 0.575 | Acc: 78.333% \n",
            "[epoch:64, iter:1465] Loss: 0.563 | Acc: 78.516% \n",
            "[epoch:64, iter:1466] Loss: 0.580 | Acc: 77.757% \n",
            "[epoch:64, iter:1467] Loss: 0.585 | Acc: 77.604% \n",
            "[epoch:64, iter:1468] Loss: 0.596 | Acc: 77.138% \n",
            "[epoch:64, iter:1469] Loss: 0.594 | Acc: 77.344% \n",
            "[epoch:64, iter:1470] Loss: 0.577 | Acc: 78.125% \n",
            "[epoch:64, iter:1471] Loss: 0.574 | Acc: 78.125% \n",
            "[epoch:64, iter:1472] Loss: 0.572 | Acc: 78.397% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.909%\n",
            "\n",
            "Epoch: 65\n",
            "[epoch:65, iter:1473] Loss: 0.214 | Acc: 96.875% \n",
            "[epoch:65, iter:1474] Loss: 0.476 | Acc: 81.250% \n",
            "[epoch:65, iter:1475] Loss: 0.453 | Acc: 83.333% \n",
            "[epoch:65, iter:1476] Loss: 0.450 | Acc: 82.031% \n",
            "[epoch:65, iter:1477] Loss: 0.469 | Acc: 81.250% \n",
            "[epoch:65, iter:1478] Loss: 0.478 | Acc: 82.812% \n",
            "[epoch:65, iter:1479] Loss: 0.444 | Acc: 83.929% \n",
            "[epoch:65, iter:1480] Loss: 0.468 | Acc: 83.594% \n",
            "[epoch:65, iter:1481] Loss: 0.463 | Acc: 83.681% \n",
            "[epoch:65, iter:1482] Loss: 0.481 | Acc: 82.188% \n",
            "[epoch:65, iter:1483] Loss: 0.489 | Acc: 81.534% \n",
            "[epoch:65, iter:1484] Loss: 0.501 | Acc: 80.469% \n",
            "[epoch:65, iter:1485] Loss: 0.504 | Acc: 80.288% \n",
            "[epoch:65, iter:1486] Loss: 0.487 | Acc: 81.250% \n",
            "[epoch:65, iter:1487] Loss: 0.479 | Acc: 81.458% \n",
            "[epoch:65, iter:1488] Loss: 0.499 | Acc: 80.859% \n",
            "[epoch:65, iter:1489] Loss: 0.513 | Acc: 80.331% \n",
            "[epoch:65, iter:1490] Loss: 0.517 | Acc: 80.208% \n",
            "[epoch:65, iter:1491] Loss: 0.515 | Acc: 79.934% \n",
            "[epoch:65, iter:1492] Loss: 0.504 | Acc: 80.000% \n",
            "[epoch:65, iter:1493] Loss: 0.506 | Acc: 79.911% \n",
            "[epoch:65, iter:1494] Loss: 0.510 | Acc: 79.688% \n",
            "[epoch:65, iter:1495] Loss: 0.528 | Acc: 79.348% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 66\n",
            "[epoch:66, iter:1496] Loss: 0.361 | Acc: 90.625% \n",
            "[epoch:66, iter:1497] Loss: 0.570 | Acc: 79.688% \n",
            "[epoch:66, iter:1498] Loss: 0.531 | Acc: 80.208% \n",
            "[epoch:66, iter:1499] Loss: 0.461 | Acc: 83.594% \n",
            "[epoch:66, iter:1500] Loss: 0.423 | Acc: 85.000% \n",
            "[epoch:66, iter:1501] Loss: 0.440 | Acc: 83.333% \n",
            "[epoch:66, iter:1502] Loss: 0.455 | Acc: 81.696% \n",
            "[epoch:66, iter:1503] Loss: 0.469 | Acc: 80.859% \n",
            "[epoch:66, iter:1504] Loss: 0.468 | Acc: 81.250% \n",
            "[epoch:66, iter:1505] Loss: 0.529 | Acc: 79.062% \n",
            "[epoch:66, iter:1506] Loss: 0.566 | Acc: 78.125% \n",
            "[epoch:66, iter:1507] Loss: 0.564 | Acc: 76.823% \n",
            "[epoch:66, iter:1508] Loss: 0.564 | Acc: 77.644% \n",
            "[epoch:66, iter:1509] Loss: 0.570 | Acc: 77.232% \n",
            "[epoch:66, iter:1510] Loss: 0.560 | Acc: 77.292% \n",
            "[epoch:66, iter:1511] Loss: 0.565 | Acc: 77.148% \n",
            "[epoch:66, iter:1512] Loss: 0.554 | Acc: 77.757% \n",
            "[epoch:66, iter:1513] Loss: 0.560 | Acc: 77.604% \n",
            "[epoch:66, iter:1514] Loss: 0.568 | Acc: 77.138% \n",
            "[epoch:66, iter:1515] Loss: 0.575 | Acc: 76.406% \n",
            "[epoch:66, iter:1516] Loss: 0.581 | Acc: 76.042% \n",
            "[epoch:66, iter:1517] Loss: 0.583 | Acc: 75.994% \n",
            "[epoch:66, iter:1518] Loss: 0.586 | Acc: 75.679% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 67\n",
            "[epoch:67, iter:1519] Loss: 0.526 | Acc: 78.125% \n",
            "[epoch:67, iter:1520] Loss: 0.509 | Acc: 78.125% \n",
            "[epoch:67, iter:1521] Loss: 0.506 | Acc: 81.250% \n",
            "[epoch:67, iter:1522] Loss: 0.512 | Acc: 82.031% \n",
            "[epoch:67, iter:1523] Loss: 0.583 | Acc: 79.375% \n",
            "[epoch:67, iter:1524] Loss: 0.596 | Acc: 78.125% \n",
            "[epoch:67, iter:1525] Loss: 0.600 | Acc: 77.679% \n",
            "[epoch:67, iter:1526] Loss: 0.601 | Acc: 76.172% \n",
            "[epoch:67, iter:1527] Loss: 0.642 | Acc: 74.306% \n",
            "[epoch:67, iter:1528] Loss: 0.623 | Acc: 75.625% \n",
            "[epoch:67, iter:1529] Loss: 0.629 | Acc: 75.852% \n",
            "[epoch:67, iter:1530] Loss: 0.610 | Acc: 76.823% \n",
            "[epoch:67, iter:1531] Loss: 0.618 | Acc: 77.163% \n",
            "[epoch:67, iter:1532] Loss: 0.608 | Acc: 78.125% \n",
            "[epoch:67, iter:1533] Loss: 0.616 | Acc: 77.708% \n",
            "[epoch:67, iter:1534] Loss: 0.617 | Acc: 77.148% \n",
            "[epoch:67, iter:1535] Loss: 0.616 | Acc: 76.838% \n",
            "[epoch:67, iter:1536] Loss: 0.604 | Acc: 77.083% \n",
            "[epoch:67, iter:1537] Loss: 0.600 | Acc: 77.303% \n",
            "[epoch:67, iter:1538] Loss: 0.606 | Acc: 76.562% \n",
            "[epoch:67, iter:1539] Loss: 0.611 | Acc: 75.893% \n",
            "[epoch:67, iter:1540] Loss: 0.607 | Acc: 75.852% \n",
            "[epoch:67, iter:1541] Loss: 0.598 | Acc: 76.359% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.091%\n",
            "\n",
            "Epoch: 68\n",
            "[epoch:68, iter:1542] Loss: 0.306 | Acc: 84.375% \n",
            "[epoch:68, iter:1543] Loss: 0.387 | Acc: 79.688% \n",
            "[epoch:68, iter:1544] Loss: 0.377 | Acc: 80.208% \n",
            "[epoch:68, iter:1545] Loss: 0.436 | Acc: 78.125% \n",
            "[epoch:68, iter:1546] Loss: 0.427 | Acc: 80.000% \n",
            "[epoch:68, iter:1547] Loss: 0.425 | Acc: 81.771% \n",
            "[epoch:68, iter:1548] Loss: 0.469 | Acc: 82.143% \n",
            "[epoch:68, iter:1549] Loss: 0.462 | Acc: 82.422% \n",
            "[epoch:68, iter:1550] Loss: 0.505 | Acc: 80.556% \n",
            "[epoch:68, iter:1551] Loss: 0.490 | Acc: 81.562% \n",
            "[epoch:68, iter:1552] Loss: 0.486 | Acc: 81.818% \n",
            "[epoch:68, iter:1553] Loss: 0.503 | Acc: 80.729% \n",
            "[epoch:68, iter:1554] Loss: 0.485 | Acc: 81.250% \n",
            "[epoch:68, iter:1555] Loss: 0.478 | Acc: 81.696% \n",
            "[epoch:68, iter:1556] Loss: 0.472 | Acc: 81.667% \n",
            "[epoch:68, iter:1557] Loss: 0.473 | Acc: 81.641% \n",
            "[epoch:68, iter:1558] Loss: 0.468 | Acc: 81.801% \n",
            "[epoch:68, iter:1559] Loss: 0.465 | Acc: 81.944% \n",
            "[epoch:68, iter:1560] Loss: 0.473 | Acc: 81.086% \n",
            "[epoch:68, iter:1561] Loss: 0.468 | Acc: 81.562% \n",
            "[epoch:68, iter:1562] Loss: 0.466 | Acc: 81.696% \n",
            "[epoch:68, iter:1563] Loss: 0.467 | Acc: 81.818% \n",
            "[epoch:68, iter:1564] Loss: 0.465 | Acc: 81.929% \n",
            "Waiting Test...\n",
            "Test's ac is: 42.424%\n",
            "\n",
            "Epoch: 69\n",
            "[epoch:69, iter:1565] Loss: 0.528 | Acc: 81.250% \n",
            "[epoch:69, iter:1566] Loss: 0.519 | Acc: 84.375% \n",
            "[epoch:69, iter:1567] Loss: 0.474 | Acc: 85.417% \n",
            "[epoch:69, iter:1568] Loss: 0.472 | Acc: 84.375% \n",
            "[epoch:69, iter:1569] Loss: 0.424 | Acc: 85.625% \n",
            "[epoch:69, iter:1570] Loss: 0.416 | Acc: 85.417% \n",
            "[epoch:69, iter:1571] Loss: 0.424 | Acc: 85.714% \n",
            "[epoch:69, iter:1572] Loss: 0.407 | Acc: 86.328% \n",
            "[epoch:69, iter:1573] Loss: 0.403 | Acc: 86.458% \n",
            "[epoch:69, iter:1574] Loss: 0.389 | Acc: 86.875% \n",
            "[epoch:69, iter:1575] Loss: 0.398 | Acc: 85.795% \n",
            "[epoch:69, iter:1576] Loss: 0.395 | Acc: 85.677% \n",
            "[epoch:69, iter:1577] Loss: 0.399 | Acc: 85.577% \n",
            "[epoch:69, iter:1578] Loss: 0.401 | Acc: 85.268% \n",
            "[epoch:69, iter:1579] Loss: 0.404 | Acc: 85.417% \n",
            "[epoch:69, iter:1580] Loss: 0.397 | Acc: 85.547% \n",
            "[epoch:69, iter:1581] Loss: 0.399 | Acc: 85.662% \n",
            "[epoch:69, iter:1582] Loss: 0.401 | Acc: 85.764% \n",
            "[epoch:69, iter:1583] Loss: 0.421 | Acc: 84.704% \n",
            "[epoch:69, iter:1584] Loss: 0.436 | Acc: 84.531% \n",
            "[epoch:69, iter:1585] Loss: 0.433 | Acc: 84.524% \n",
            "[epoch:69, iter:1586] Loss: 0.450 | Acc: 83.665% \n",
            "[epoch:69, iter:1587] Loss: 0.469 | Acc: 83.016% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 70\n",
            "[epoch:70, iter:1588] Loss: 0.550 | Acc: 71.875% \n",
            "[epoch:70, iter:1589] Loss: 0.645 | Acc: 70.312% \n",
            "[epoch:70, iter:1590] Loss: 0.527 | Acc: 77.083% \n",
            "[epoch:70, iter:1591] Loss: 0.575 | Acc: 78.125% \n",
            "[epoch:70, iter:1592] Loss: 0.592 | Acc: 76.875% \n",
            "[epoch:70, iter:1593] Loss: 0.573 | Acc: 77.083% \n",
            "[epoch:70, iter:1594] Loss: 0.644 | Acc: 74.554% \n",
            "[epoch:70, iter:1595] Loss: 0.644 | Acc: 74.219% \n",
            "[epoch:70, iter:1596] Loss: 0.663 | Acc: 74.306% \n",
            "[epoch:70, iter:1597] Loss: 0.691 | Acc: 73.438% \n",
            "[epoch:70, iter:1598] Loss: 0.719 | Acc: 71.875% \n",
            "[epoch:70, iter:1599] Loss: 0.705 | Acc: 72.396% \n",
            "[epoch:70, iter:1600] Loss: 0.687 | Acc: 73.558% \n",
            "[epoch:70, iter:1601] Loss: 0.731 | Acc: 71.652% \n",
            "[epoch:70, iter:1602] Loss: 0.716 | Acc: 72.292% \n",
            "[epoch:70, iter:1603] Loss: 0.710 | Acc: 73.047% \n",
            "[epoch:70, iter:1604] Loss: 0.731 | Acc: 72.610% \n",
            "[epoch:70, iter:1605] Loss: 0.732 | Acc: 72.396% \n",
            "[epoch:70, iter:1606] Loss: 0.721 | Acc: 73.026% \n",
            "[epoch:70, iter:1607] Loss: 0.714 | Acc: 73.125% \n",
            "[epoch:70, iter:1608] Loss: 0.705 | Acc: 73.661% \n",
            "[epoch:70, iter:1609] Loss: 0.702 | Acc: 73.580% \n",
            "[epoch:70, iter:1610] Loss: 0.695 | Acc: 73.913% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 71\n",
            "[epoch:71, iter:1611] Loss: 0.453 | Acc: 84.375% \n",
            "[epoch:71, iter:1612] Loss: 0.502 | Acc: 79.688% \n",
            "[epoch:71, iter:1613] Loss: 0.496 | Acc: 79.167% \n",
            "[epoch:71, iter:1614] Loss: 0.486 | Acc: 81.250% \n",
            "[epoch:71, iter:1615] Loss: 0.462 | Acc: 82.500% \n",
            "[epoch:71, iter:1616] Loss: 0.498 | Acc: 80.208% \n",
            "[epoch:71, iter:1617] Loss: 0.481 | Acc: 80.804% \n",
            "[epoch:71, iter:1618] Loss: 0.478 | Acc: 81.641% \n",
            "[epoch:71, iter:1619] Loss: 0.488 | Acc: 81.250% \n",
            "[epoch:71, iter:1620] Loss: 0.489 | Acc: 80.938% \n",
            "[epoch:71, iter:1621] Loss: 0.486 | Acc: 80.966% \n",
            "[epoch:71, iter:1622] Loss: 0.482 | Acc: 80.469% \n",
            "[epoch:71, iter:1623] Loss: 0.469 | Acc: 81.250% \n",
            "[epoch:71, iter:1624] Loss: 0.457 | Acc: 81.920% \n",
            "[epoch:71, iter:1625] Loss: 0.457 | Acc: 82.083% \n",
            "[epoch:71, iter:1626] Loss: 0.471 | Acc: 81.445% \n",
            "[epoch:71, iter:1627] Loss: 0.460 | Acc: 81.985% \n",
            "[epoch:71, iter:1628] Loss: 0.459 | Acc: 82.292% \n",
            "[epoch:71, iter:1629] Loss: 0.466 | Acc: 82.072% \n",
            "[epoch:71, iter:1630] Loss: 0.474 | Acc: 81.875% \n",
            "[epoch:71, iter:1631] Loss: 0.487 | Acc: 81.250% \n",
            "[epoch:71, iter:1632] Loss: 0.485 | Acc: 81.534% \n",
            "[epoch:71, iter:1633] Loss: 0.485 | Acc: 81.250% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 72\n",
            "[epoch:72, iter:1634] Loss: 0.521 | Acc: 78.125% \n",
            "[epoch:72, iter:1635] Loss: 0.417 | Acc: 81.250% \n",
            "[epoch:72, iter:1636] Loss: 0.454 | Acc: 79.167% \n",
            "[epoch:72, iter:1637] Loss: 0.480 | Acc: 80.469% \n",
            "[epoch:72, iter:1638] Loss: 0.487 | Acc: 80.000% \n",
            "[epoch:72, iter:1639] Loss: 0.510 | Acc: 79.688% \n",
            "[epoch:72, iter:1640] Loss: 0.508 | Acc: 79.464% \n",
            "[epoch:72, iter:1641] Loss: 0.494 | Acc: 79.297% \n",
            "[epoch:72, iter:1642] Loss: 0.489 | Acc: 79.514% \n",
            "[epoch:72, iter:1643] Loss: 0.479 | Acc: 80.312% \n",
            "[epoch:72, iter:1644] Loss: 0.464 | Acc: 80.966% \n",
            "[epoch:72, iter:1645] Loss: 0.462 | Acc: 81.250% \n",
            "[epoch:72, iter:1646] Loss: 0.472 | Acc: 81.010% \n",
            "[epoch:72, iter:1647] Loss: 0.489 | Acc: 80.580% \n",
            "[epoch:72, iter:1648] Loss: 0.484 | Acc: 80.833% \n",
            "[epoch:72, iter:1649] Loss: 0.483 | Acc: 80.664% \n",
            "[epoch:72, iter:1650] Loss: 0.509 | Acc: 79.228% \n",
            "[epoch:72, iter:1651] Loss: 0.502 | Acc: 79.167% \n",
            "[epoch:72, iter:1652] Loss: 0.508 | Acc: 78.783% \n",
            "[epoch:72, iter:1653] Loss: 0.505 | Acc: 79.062% \n",
            "[epoch:72, iter:1654] Loss: 0.512 | Acc: 78.869% \n",
            "[epoch:72, iter:1655] Loss: 0.507 | Acc: 78.693% \n",
            "[epoch:72, iter:1656] Loss: 0.499 | Acc: 79.076% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 73\n",
            "[epoch:73, iter:1657] Loss: 0.260 | Acc: 90.625% \n",
            "[epoch:73, iter:1658] Loss: 0.312 | Acc: 85.938% \n",
            "[epoch:73, iter:1659] Loss: 0.369 | Acc: 84.375% \n",
            "[epoch:73, iter:1660] Loss: 0.370 | Acc: 85.156% \n",
            "[epoch:73, iter:1661] Loss: 0.366 | Acc: 85.625% \n",
            "[epoch:73, iter:1662] Loss: 0.351 | Acc: 86.979% \n",
            "[epoch:73, iter:1663] Loss: 0.339 | Acc: 87.500% \n",
            "[epoch:73, iter:1664] Loss: 0.333 | Acc: 88.281% \n",
            "[epoch:73, iter:1665] Loss: 0.331 | Acc: 88.194% \n",
            "[epoch:73, iter:1666] Loss: 0.324 | Acc: 88.438% \n",
            "[epoch:73, iter:1667] Loss: 0.327 | Acc: 88.636% \n",
            "[epoch:73, iter:1668] Loss: 0.329 | Acc: 89.062% \n",
            "[epoch:73, iter:1669] Loss: 0.353 | Acc: 87.740% \n",
            "[epoch:73, iter:1670] Loss: 0.349 | Acc: 88.170% \n",
            "[epoch:73, iter:1671] Loss: 0.361 | Acc: 87.292% \n",
            "[epoch:73, iter:1672] Loss: 0.354 | Acc: 87.500% \n",
            "[epoch:73, iter:1673] Loss: 0.360 | Acc: 86.949% \n",
            "[epoch:73, iter:1674] Loss: 0.357 | Acc: 86.979% \n",
            "[epoch:73, iter:1675] Loss: 0.353 | Acc: 87.007% \n",
            "[epoch:73, iter:1676] Loss: 0.368 | Acc: 86.406% \n",
            "[epoch:73, iter:1677] Loss: 0.384 | Acc: 85.565% \n",
            "[epoch:73, iter:1678] Loss: 0.402 | Acc: 84.659% \n",
            "[epoch:73, iter:1679] Loss: 0.409 | Acc: 84.511% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.788%\n",
            "\n",
            "Epoch: 74\n",
            "[epoch:74, iter:1680] Loss: 0.378 | Acc: 81.250% \n",
            "[epoch:74, iter:1681] Loss: 0.295 | Acc: 85.938% \n",
            "[epoch:74, iter:1682] Loss: 0.316 | Acc: 86.458% \n",
            "[epoch:74, iter:1683] Loss: 0.340 | Acc: 84.375% \n",
            "[epoch:74, iter:1684] Loss: 0.418 | Acc: 81.875% \n",
            "[epoch:74, iter:1685] Loss: 0.400 | Acc: 83.333% \n",
            "[epoch:74, iter:1686] Loss: 0.454 | Acc: 82.143% \n",
            "[epoch:74, iter:1687] Loss: 0.442 | Acc: 82.812% \n",
            "[epoch:74, iter:1688] Loss: 0.425 | Acc: 82.986% \n",
            "[epoch:74, iter:1689] Loss: 0.450 | Acc: 82.812% \n",
            "[epoch:74, iter:1690] Loss: 0.463 | Acc: 82.102% \n",
            "[epoch:74, iter:1691] Loss: 0.464 | Acc: 82.031% \n",
            "[epoch:74, iter:1692] Loss: 0.482 | Acc: 80.769% \n",
            "[epoch:74, iter:1693] Loss: 0.481 | Acc: 80.580% \n",
            "[epoch:74, iter:1694] Loss: 0.468 | Acc: 80.833% \n",
            "[epoch:74, iter:1695] Loss: 0.475 | Acc: 81.055% \n",
            "[epoch:74, iter:1696] Loss: 0.494 | Acc: 80.515% \n",
            "[epoch:74, iter:1697] Loss: 0.497 | Acc: 79.861% \n",
            "[epoch:74, iter:1698] Loss: 0.509 | Acc: 78.947% \n",
            "[epoch:74, iter:1699] Loss: 0.502 | Acc: 79.219% \n",
            "[epoch:74, iter:1700] Loss: 0.506 | Acc: 79.018% \n",
            "[epoch:74, iter:1701] Loss: 0.506 | Acc: 78.835% \n",
            "[epoch:74, iter:1702] Loss: 0.509 | Acc: 79.212% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.061%\n",
            "\n",
            "Epoch: 75\n",
            "[epoch:75, iter:1703] Loss: 0.511 | Acc: 78.125% \n",
            "[epoch:75, iter:1704] Loss: 0.497 | Acc: 76.562% \n",
            "[epoch:75, iter:1705] Loss: 0.726 | Acc: 69.792% \n",
            "[epoch:75, iter:1706] Loss: 0.678 | Acc: 72.656% \n",
            "[epoch:75, iter:1707] Loss: 0.660 | Acc: 74.375% \n",
            "[epoch:75, iter:1708] Loss: 0.599 | Acc: 76.042% \n",
            "[epoch:75, iter:1709] Loss: 0.594 | Acc: 75.446% \n",
            "[epoch:75, iter:1710] Loss: 0.597 | Acc: 75.000% \n",
            "[epoch:75, iter:1711] Loss: 0.598 | Acc: 75.000% \n",
            "[epoch:75, iter:1712] Loss: 0.582 | Acc: 75.938% \n",
            "[epoch:75, iter:1713] Loss: 0.549 | Acc: 77.557% \n",
            "[epoch:75, iter:1714] Loss: 0.538 | Acc: 77.865% \n",
            "[epoch:75, iter:1715] Loss: 0.531 | Acc: 77.885% \n",
            "[epoch:75, iter:1716] Loss: 0.516 | Acc: 78.795% \n",
            "[epoch:75, iter:1717] Loss: 0.540 | Acc: 78.333% \n",
            "[epoch:75, iter:1718] Loss: 0.528 | Acc: 79.102% \n",
            "[epoch:75, iter:1719] Loss: 0.549 | Acc: 78.493% \n",
            "[epoch:75, iter:1720] Loss: 0.535 | Acc: 79.167% \n",
            "[epoch:75, iter:1721] Loss: 0.531 | Acc: 79.112% \n",
            "[epoch:75, iter:1722] Loss: 0.529 | Acc: 79.375% \n",
            "[epoch:75, iter:1723] Loss: 0.528 | Acc: 79.464% \n",
            "[epoch:75, iter:1724] Loss: 0.516 | Acc: 79.830% \n",
            "[epoch:75, iter:1725] Loss: 0.511 | Acc: 80.163% \n",
            "Waiting Test...\n",
            "Test's ac is: 39.394%\n",
            "\n",
            "Epoch: 76\n",
            "[epoch:76, iter:1726] Loss: 0.226 | Acc: 93.750% \n",
            "[epoch:76, iter:1727] Loss: 0.313 | Acc: 87.500% \n",
            "[epoch:76, iter:1728] Loss: 0.297 | Acc: 89.583% \n",
            "[epoch:76, iter:1729] Loss: 0.300 | Acc: 90.625% \n",
            "[epoch:76, iter:1730] Loss: 0.358 | Acc: 89.375% \n",
            "[epoch:76, iter:1731] Loss: 0.340 | Acc: 89.062% \n",
            "[epoch:76, iter:1732] Loss: 0.336 | Acc: 88.839% \n",
            "[epoch:76, iter:1733] Loss: 0.327 | Acc: 89.062% \n",
            "[epoch:76, iter:1734] Loss: 0.337 | Acc: 88.542% \n",
            "[epoch:76, iter:1735] Loss: 0.361 | Acc: 87.188% \n",
            "[epoch:76, iter:1736] Loss: 0.341 | Acc: 88.352% \n",
            "[epoch:76, iter:1737] Loss: 0.345 | Acc: 88.281% \n",
            "[epoch:76, iter:1738] Loss: 0.376 | Acc: 86.779% \n",
            "[epoch:76, iter:1739] Loss: 0.368 | Acc: 87.054% \n",
            "[epoch:76, iter:1740] Loss: 0.369 | Acc: 87.083% \n",
            "[epoch:76, iter:1741] Loss: 0.368 | Acc: 86.914% \n",
            "[epoch:76, iter:1742] Loss: 0.383 | Acc: 86.029% \n",
            "[epoch:76, iter:1743] Loss: 0.383 | Acc: 85.764% \n",
            "[epoch:76, iter:1744] Loss: 0.385 | Acc: 85.691% \n",
            "[epoch:76, iter:1745] Loss: 0.378 | Acc: 86.094% \n",
            "[epoch:76, iter:1746] Loss: 0.373 | Acc: 86.310% \n",
            "[epoch:76, iter:1747] Loss: 0.377 | Acc: 85.795% \n",
            "[epoch:76, iter:1748] Loss: 0.376 | Acc: 85.734% \n",
            "Waiting Test...\n",
            "Test's ac is: 27.273%\n",
            "\n",
            "Epoch: 77\n",
            "[epoch:77, iter:1749] Loss: 0.551 | Acc: 78.125% \n",
            "[epoch:77, iter:1750] Loss: 0.424 | Acc: 82.812% \n",
            "[epoch:77, iter:1751] Loss: 0.372 | Acc: 83.333% \n",
            "[epoch:77, iter:1752] Loss: 0.392 | Acc: 82.812% \n",
            "[epoch:77, iter:1753] Loss: 0.400 | Acc: 81.250% \n",
            "[epoch:77, iter:1754] Loss: 0.402 | Acc: 81.250% \n",
            "[epoch:77, iter:1755] Loss: 0.414 | Acc: 80.804% \n",
            "[epoch:77, iter:1756] Loss: 0.401 | Acc: 82.031% \n",
            "[epoch:77, iter:1757] Loss: 0.408 | Acc: 81.597% \n",
            "[epoch:77, iter:1758] Loss: 0.405 | Acc: 81.562% \n",
            "[epoch:77, iter:1759] Loss: 0.385 | Acc: 82.955% \n",
            "[epoch:77, iter:1760] Loss: 0.376 | Acc: 83.594% \n",
            "[epoch:77, iter:1761] Loss: 0.399 | Acc: 82.692% \n",
            "[epoch:77, iter:1762] Loss: 0.393 | Acc: 83.036% \n",
            "[epoch:77, iter:1763] Loss: 0.398 | Acc: 82.917% \n",
            "[epoch:77, iter:1764] Loss: 0.388 | Acc: 83.398% \n",
            "[epoch:77, iter:1765] Loss: 0.390 | Acc: 82.904% \n",
            "[epoch:77, iter:1766] Loss: 0.386 | Acc: 83.160% \n",
            "[epoch:77, iter:1767] Loss: 0.375 | Acc: 83.717% \n",
            "[epoch:77, iter:1768] Loss: 0.374 | Acc: 83.594% \n",
            "[epoch:77, iter:1769] Loss: 0.375 | Acc: 83.482% \n",
            "[epoch:77, iter:1770] Loss: 0.376 | Acc: 83.381% \n",
            "[epoch:77, iter:1771] Loss: 0.368 | Acc: 83.832% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 78\n",
            "[epoch:78, iter:1772] Loss: 0.411 | Acc: 84.375% \n",
            "[epoch:78, iter:1773] Loss: 0.387 | Acc: 85.938% \n",
            "[epoch:78, iter:1774] Loss: 0.339 | Acc: 88.542% \n",
            "[epoch:78, iter:1775] Loss: 0.326 | Acc: 89.062% \n",
            "[epoch:78, iter:1776] Loss: 0.385 | Acc: 88.125% \n",
            "[epoch:78, iter:1777] Loss: 0.399 | Acc: 88.021% \n",
            "[epoch:78, iter:1778] Loss: 0.393 | Acc: 86.607% \n",
            "[epoch:78, iter:1779] Loss: 0.395 | Acc: 87.500% \n",
            "[epoch:78, iter:1780] Loss: 0.376 | Acc: 88.194% \n",
            "[epoch:78, iter:1781] Loss: 0.385 | Acc: 87.812% \n",
            "[epoch:78, iter:1782] Loss: 0.382 | Acc: 87.784% \n",
            "[epoch:78, iter:1783] Loss: 0.376 | Acc: 87.500% \n",
            "[epoch:78, iter:1784] Loss: 0.376 | Acc: 87.500% \n",
            "[epoch:78, iter:1785] Loss: 0.375 | Acc: 87.277% \n",
            "[epoch:78, iter:1786] Loss: 0.376 | Acc: 86.458% \n",
            "[epoch:78, iter:1787] Loss: 0.385 | Acc: 86.719% \n",
            "[epoch:78, iter:1788] Loss: 0.389 | Acc: 86.029% \n",
            "[epoch:78, iter:1789] Loss: 0.394 | Acc: 85.764% \n",
            "[epoch:78, iter:1790] Loss: 0.403 | Acc: 85.197% \n",
            "[epoch:78, iter:1791] Loss: 0.404 | Acc: 85.312% \n",
            "[epoch:78, iter:1792] Loss: 0.400 | Acc: 85.565% \n",
            "[epoch:78, iter:1793] Loss: 0.407 | Acc: 85.511% \n",
            "[epoch:78, iter:1794] Loss: 0.400 | Acc: 85.734% \n",
            "Waiting Test...\n",
            "Test's ac is: 28.788%\n",
            "\n",
            "Epoch: 79\n",
            "[epoch:79, iter:1795] Loss: 0.269 | Acc: 87.500% \n",
            "[epoch:79, iter:1796] Loss: 0.358 | Acc: 82.812% \n",
            "[epoch:79, iter:1797] Loss: 0.340 | Acc: 84.375% \n",
            "[epoch:79, iter:1798] Loss: 0.344 | Acc: 83.594% \n",
            "[epoch:79, iter:1799] Loss: 0.398 | Acc: 82.500% \n",
            "[epoch:79, iter:1800] Loss: 0.380 | Acc: 83.333% \n",
            "[epoch:79, iter:1801] Loss: 0.397 | Acc: 83.929% \n",
            "[epoch:79, iter:1802] Loss: 0.427 | Acc: 82.812% \n",
            "[epoch:79, iter:1803] Loss: 0.406 | Acc: 83.333% \n",
            "[epoch:79, iter:1804] Loss: 0.405 | Acc: 82.812% \n",
            "[epoch:79, iter:1805] Loss: 0.430 | Acc: 82.102% \n",
            "[epoch:79, iter:1806] Loss: 0.418 | Acc: 82.292% \n",
            "[epoch:79, iter:1807] Loss: 0.440 | Acc: 81.010% \n",
            "[epoch:79, iter:1808] Loss: 0.448 | Acc: 81.027% \n",
            "[epoch:79, iter:1809] Loss: 0.440 | Acc: 81.458% \n",
            "[epoch:79, iter:1810] Loss: 0.428 | Acc: 81.836% \n",
            "[epoch:79, iter:1811] Loss: 0.430 | Acc: 82.353% \n",
            "[epoch:79, iter:1812] Loss: 0.437 | Acc: 81.597% \n",
            "[epoch:79, iter:1813] Loss: 0.439 | Acc: 81.250% \n",
            "[epoch:79, iter:1814] Loss: 0.438 | Acc: 81.406% \n",
            "[epoch:79, iter:1815] Loss: 0.457 | Acc: 80.506% \n",
            "[epoch:79, iter:1816] Loss: 0.468 | Acc: 80.540% \n",
            "[epoch:79, iter:1817] Loss: 0.455 | Acc: 81.114% \n",
            "Waiting Test...\n",
            "Test's ac is: 24.242%\n",
            "\n",
            "Epoch: 80\n",
            "[epoch:80, iter:1818] Loss: 0.407 | Acc: 81.250% \n",
            "[epoch:80, iter:1819] Loss: 0.336 | Acc: 82.812% \n",
            "[epoch:80, iter:1820] Loss: 0.365 | Acc: 82.292% \n",
            "[epoch:80, iter:1821] Loss: 0.372 | Acc: 82.031% \n",
            "[epoch:80, iter:1822] Loss: 0.389 | Acc: 82.500% \n",
            "[epoch:80, iter:1823] Loss: 0.446 | Acc: 79.167% \n",
            "[epoch:80, iter:1824] Loss: 0.503 | Acc: 78.125% \n",
            "[epoch:80, iter:1825] Loss: 0.473 | Acc: 79.688% \n",
            "[epoch:80, iter:1826] Loss: 0.483 | Acc: 79.861% \n",
            "[epoch:80, iter:1827] Loss: 0.480 | Acc: 80.312% \n",
            "[epoch:80, iter:1828] Loss: 0.528 | Acc: 80.114% \n",
            "[epoch:80, iter:1829] Loss: 0.533 | Acc: 80.208% \n",
            "[epoch:80, iter:1830] Loss: 0.534 | Acc: 79.808% \n",
            "[epoch:80, iter:1831] Loss: 0.529 | Acc: 80.134% \n",
            "[epoch:80, iter:1832] Loss: 0.519 | Acc: 80.417% \n",
            "[epoch:80, iter:1833] Loss: 0.533 | Acc: 79.492% \n",
            "[epoch:80, iter:1834] Loss: 0.522 | Acc: 79.779% \n",
            "[epoch:80, iter:1835] Loss: 0.515 | Acc: 79.688% \n",
            "[epoch:80, iter:1836] Loss: 0.527 | Acc: 78.783% \n",
            "[epoch:80, iter:1837] Loss: 0.530 | Acc: 78.906% \n",
            "[epoch:80, iter:1838] Loss: 0.523 | Acc: 79.018% \n",
            "[epoch:80, iter:1839] Loss: 0.518 | Acc: 79.119% \n",
            "[epoch:80, iter:1840] Loss: 0.508 | Acc: 79.620% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.848%\n",
            "\n",
            "Epoch: 81\n",
            "[epoch:81, iter:1841] Loss: 0.353 | Acc: 93.750% \n",
            "[epoch:81, iter:1842] Loss: 0.284 | Acc: 95.312% \n",
            "[epoch:81, iter:1843] Loss: 0.328 | Acc: 90.625% \n",
            "[epoch:81, iter:1844] Loss: 0.324 | Acc: 90.625% \n",
            "[epoch:81, iter:1845] Loss: 0.332 | Acc: 88.750% \n",
            "[epoch:81, iter:1846] Loss: 0.330 | Acc: 89.583% \n",
            "[epoch:81, iter:1847] Loss: 0.342 | Acc: 87.946% \n",
            "[epoch:81, iter:1848] Loss: 0.364 | Acc: 86.328% \n",
            "[epoch:81, iter:1849] Loss: 0.351 | Acc: 87.153% \n",
            "[epoch:81, iter:1850] Loss: 0.336 | Acc: 87.500% \n",
            "[epoch:81, iter:1851] Loss: 0.323 | Acc: 88.352% \n",
            "[epoch:81, iter:1852] Loss: 0.316 | Acc: 88.802% \n",
            "[epoch:81, iter:1853] Loss: 0.330 | Acc: 88.702% \n",
            "[epoch:81, iter:1854] Loss: 0.352 | Acc: 87.946% \n",
            "[epoch:81, iter:1855] Loss: 0.335 | Acc: 88.750% \n",
            "[epoch:81, iter:1856] Loss: 0.332 | Acc: 88.477% \n",
            "[epoch:81, iter:1857] Loss: 0.330 | Acc: 88.235% \n",
            "[epoch:81, iter:1858] Loss: 0.340 | Acc: 87.674% \n",
            "[epoch:81, iter:1859] Loss: 0.348 | Acc: 86.842% \n",
            "[epoch:81, iter:1860] Loss: 0.352 | Acc: 86.719% \n",
            "[epoch:81, iter:1861] Loss: 0.346 | Acc: 87.054% \n",
            "[epoch:81, iter:1862] Loss: 0.340 | Acc: 87.358% \n",
            "[epoch:81, iter:1863] Loss: 0.334 | Acc: 87.364% \n",
            "Waiting Test...\n",
            "Test's ac is: 32.576%\n",
            "\n",
            "Epoch: 82\n",
            "[epoch:82, iter:1864] Loss: 0.236 | Acc: 93.750% \n",
            "[epoch:82, iter:1865] Loss: 0.243 | Acc: 92.188% \n",
            "[epoch:82, iter:1866] Loss: 0.250 | Acc: 91.667% \n",
            "[epoch:82, iter:1867] Loss: 0.241 | Acc: 91.406% \n",
            "[epoch:82, iter:1868] Loss: 0.269 | Acc: 90.000% \n",
            "[epoch:82, iter:1869] Loss: 0.278 | Acc: 90.104% \n",
            "[epoch:82, iter:1870] Loss: 0.268 | Acc: 90.179% \n",
            "[epoch:82, iter:1871] Loss: 0.253 | Acc: 91.016% \n",
            "[epoch:82, iter:1872] Loss: 0.264 | Acc: 90.278% \n",
            "[epoch:82, iter:1873] Loss: 0.246 | Acc: 91.250% \n",
            "[epoch:82, iter:1874] Loss: 0.260 | Acc: 91.193% \n",
            "[epoch:82, iter:1875] Loss: 0.250 | Acc: 91.667% \n",
            "[epoch:82, iter:1876] Loss: 0.248 | Acc: 91.587% \n",
            "[epoch:82, iter:1877] Loss: 0.256 | Acc: 91.295% \n",
            "[epoch:82, iter:1878] Loss: 0.258 | Acc: 91.250% \n",
            "[epoch:82, iter:1879] Loss: 0.285 | Acc: 90.625% \n",
            "[epoch:82, iter:1880] Loss: 0.283 | Acc: 90.809% \n",
            "[epoch:82, iter:1881] Loss: 0.299 | Acc: 90.104% \n",
            "[epoch:82, iter:1882] Loss: 0.323 | Acc: 88.816% \n",
            "[epoch:82, iter:1883] Loss: 0.318 | Acc: 89.062% \n",
            "[epoch:82, iter:1884] Loss: 0.317 | Acc: 89.137% \n",
            "[epoch:82, iter:1885] Loss: 0.316 | Acc: 88.778% \n",
            "[epoch:82, iter:1886] Loss: 0.318 | Acc: 88.315% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 83\n",
            "[epoch:83, iter:1887] Loss: 0.302 | Acc: 93.750% \n",
            "[epoch:83, iter:1888] Loss: 0.294 | Acc: 89.062% \n",
            "[epoch:83, iter:1889] Loss: 0.252 | Acc: 89.583% \n",
            "[epoch:83, iter:1890] Loss: 0.287 | Acc: 89.844% \n",
            "[epoch:83, iter:1891] Loss: 0.295 | Acc: 90.000% \n",
            "[epoch:83, iter:1892] Loss: 0.312 | Acc: 88.542% \n",
            "[epoch:83, iter:1893] Loss: 0.326 | Acc: 87.054% \n",
            "[epoch:83, iter:1894] Loss: 0.325 | Acc: 87.500% \n",
            "[epoch:83, iter:1895] Loss: 0.312 | Acc: 88.194% \n",
            "[epoch:83, iter:1896] Loss: 0.308 | Acc: 88.125% \n",
            "[epoch:83, iter:1897] Loss: 0.298 | Acc: 88.636% \n",
            "[epoch:83, iter:1898] Loss: 0.285 | Acc: 89.062% \n",
            "[epoch:83, iter:1899] Loss: 0.285 | Acc: 89.183% \n",
            "[epoch:83, iter:1900] Loss: 0.293 | Acc: 88.839% \n",
            "[epoch:83, iter:1901] Loss: 0.302 | Acc: 88.333% \n",
            "[epoch:83, iter:1902] Loss: 0.310 | Acc: 88.672% \n",
            "[epoch:83, iter:1903] Loss: 0.314 | Acc: 88.235% \n",
            "[epoch:83, iter:1904] Loss: 0.319 | Acc: 88.021% \n",
            "[epoch:83, iter:1905] Loss: 0.312 | Acc: 88.322% \n",
            "[epoch:83, iter:1906] Loss: 0.317 | Acc: 88.125% \n",
            "[epoch:83, iter:1907] Loss: 0.315 | Acc: 88.244% \n",
            "[epoch:83, iter:1908] Loss: 0.313 | Acc: 88.068% \n",
            "[epoch:83, iter:1909] Loss: 0.316 | Acc: 88.043% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 84\n",
            "[epoch:84, iter:1910] Loss: 0.139 | Acc: 93.750% \n",
            "[epoch:84, iter:1911] Loss: 0.282 | Acc: 92.188% \n",
            "[epoch:84, iter:1912] Loss: 0.328 | Acc: 88.542% \n",
            "[epoch:84, iter:1913] Loss: 0.356 | Acc: 86.719% \n",
            "[epoch:84, iter:1914] Loss: 0.326 | Acc: 87.500% \n",
            "[epoch:84, iter:1915] Loss: 0.380 | Acc: 83.854% \n",
            "[epoch:84, iter:1916] Loss: 0.371 | Acc: 83.929% \n",
            "[epoch:84, iter:1917] Loss: 0.357 | Acc: 85.547% \n",
            "[epoch:84, iter:1918] Loss: 0.349 | Acc: 86.111% \n",
            "[epoch:84, iter:1919] Loss: 0.339 | Acc: 86.562% \n",
            "[epoch:84, iter:1920] Loss: 0.324 | Acc: 87.500% \n",
            "[epoch:84, iter:1921] Loss: 0.326 | Acc: 87.500% \n",
            "[epoch:84, iter:1922] Loss: 0.320 | Acc: 88.221% \n",
            "[epoch:84, iter:1923] Loss: 0.330 | Acc: 87.500% \n",
            "[epoch:84, iter:1924] Loss: 0.319 | Acc: 87.917% \n",
            "[epoch:84, iter:1925] Loss: 0.317 | Acc: 87.695% \n",
            "[epoch:84, iter:1926] Loss: 0.332 | Acc: 86.949% \n",
            "[epoch:84, iter:1927] Loss: 0.318 | Acc: 87.500% \n",
            "[epoch:84, iter:1928] Loss: 0.311 | Acc: 87.829% \n",
            "[epoch:84, iter:1929] Loss: 0.309 | Acc: 87.969% \n",
            "[epoch:84, iter:1930] Loss: 0.304 | Acc: 88.244% \n",
            "[epoch:84, iter:1931] Loss: 0.302 | Acc: 88.210% \n",
            "[epoch:84, iter:1932] Loss: 0.300 | Acc: 88.315% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.909%\n",
            "\n",
            "Epoch: 85\n",
            "[epoch:85, iter:1933] Loss: 0.285 | Acc: 90.625% \n",
            "[epoch:85, iter:1934] Loss: 0.367 | Acc: 87.500% \n",
            "[epoch:85, iter:1935] Loss: 0.317 | Acc: 88.542% \n",
            "[epoch:85, iter:1936] Loss: 0.302 | Acc: 89.844% \n",
            "[epoch:85, iter:1937] Loss: 0.266 | Acc: 90.625% \n",
            "[epoch:85, iter:1938] Loss: 0.244 | Acc: 91.146% \n",
            "[epoch:85, iter:1939] Loss: 0.254 | Acc: 90.625% \n",
            "[epoch:85, iter:1940] Loss: 0.238 | Acc: 91.016% \n",
            "[epoch:85, iter:1941] Loss: 0.260 | Acc: 90.278% \n",
            "[epoch:85, iter:1942] Loss: 0.257 | Acc: 90.312% \n",
            "[epoch:85, iter:1943] Loss: 0.253 | Acc: 90.909% \n",
            "[epoch:85, iter:1944] Loss: 0.266 | Acc: 90.625% \n",
            "[epoch:85, iter:1945] Loss: 0.285 | Acc: 89.423% \n",
            "[epoch:85, iter:1946] Loss: 0.280 | Acc: 89.732% \n",
            "[epoch:85, iter:1947] Loss: 0.289 | Acc: 89.583% \n",
            "[epoch:85, iter:1948] Loss: 0.286 | Acc: 89.648% \n",
            "[epoch:85, iter:1949] Loss: 0.285 | Acc: 89.706% \n",
            "[epoch:85, iter:1950] Loss: 0.284 | Acc: 89.583% \n",
            "[epoch:85, iter:1951] Loss: 0.279 | Acc: 89.803% \n",
            "[epoch:85, iter:1952] Loss: 0.275 | Acc: 90.000% \n",
            "[epoch:85, iter:1953] Loss: 0.272 | Acc: 90.030% \n",
            "[epoch:85, iter:1954] Loss: 0.267 | Acc: 89.915% \n",
            "[epoch:85, iter:1955] Loss: 0.265 | Acc: 89.946% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 86\n",
            "[epoch:86, iter:1956] Loss: 0.105 | Acc: 96.875% \n",
            "[epoch:86, iter:1957] Loss: 0.137 | Acc: 95.312% \n",
            "[epoch:86, iter:1958] Loss: 0.300 | Acc: 90.625% \n",
            "[epoch:86, iter:1959] Loss: 0.266 | Acc: 91.406% \n",
            "[epoch:86, iter:1960] Loss: 0.272 | Acc: 89.375% \n",
            "[epoch:86, iter:1961] Loss: 0.253 | Acc: 90.104% \n",
            "[epoch:86, iter:1962] Loss: 0.255 | Acc: 90.179% \n",
            "[epoch:86, iter:1963] Loss: 0.239 | Acc: 91.016% \n",
            "[epoch:86, iter:1964] Loss: 0.233 | Acc: 90.972% \n",
            "[epoch:86, iter:1965] Loss: 0.235 | Acc: 90.312% \n",
            "[epoch:86, iter:1966] Loss: 0.256 | Acc: 89.773% \n",
            "[epoch:86, iter:1967] Loss: 0.258 | Acc: 89.583% \n",
            "[epoch:86, iter:1968] Loss: 0.247 | Acc: 90.144% \n",
            "[epoch:86, iter:1969] Loss: 0.251 | Acc: 89.955% \n",
            "[epoch:86, iter:1970] Loss: 0.246 | Acc: 90.417% \n",
            "[epoch:86, iter:1971] Loss: 0.247 | Acc: 90.625% \n",
            "[epoch:86, iter:1972] Loss: 0.239 | Acc: 90.809% \n",
            "[epoch:86, iter:1973] Loss: 0.235 | Acc: 90.799% \n",
            "[epoch:86, iter:1974] Loss: 0.235 | Acc: 90.789% \n",
            "[epoch:86, iter:1975] Loss: 0.239 | Acc: 90.781% \n",
            "[epoch:86, iter:1976] Loss: 0.238 | Acc: 90.923% \n",
            "[epoch:86, iter:1977] Loss: 0.233 | Acc: 91.193% \n",
            "[epoch:86, iter:1978] Loss: 0.261 | Acc: 90.217% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.152%\n",
            "\n",
            "Epoch: 87\n",
            "[epoch:87, iter:1979] Loss: 0.139 | Acc: 96.875% \n",
            "[epoch:87, iter:1980] Loss: 0.126 | Acc: 98.438% \n",
            "[epoch:87, iter:1981] Loss: 0.121 | Acc: 98.958% \n",
            "[epoch:87, iter:1982] Loss: 0.169 | Acc: 94.531% \n",
            "[epoch:87, iter:1983] Loss: 0.170 | Acc: 94.375% \n",
            "[epoch:87, iter:1984] Loss: 0.168 | Acc: 94.271% \n",
            "[epoch:87, iter:1985] Loss: 0.174 | Acc: 93.750% \n",
            "[epoch:87, iter:1986] Loss: 0.204 | Acc: 93.359% \n",
            "[epoch:87, iter:1987] Loss: 0.210 | Acc: 92.708% \n",
            "[epoch:87, iter:1988] Loss: 0.217 | Acc: 92.188% \n",
            "[epoch:87, iter:1989] Loss: 0.213 | Acc: 92.330% \n",
            "[epoch:87, iter:1990] Loss: 0.216 | Acc: 92.188% \n",
            "[epoch:87, iter:1991] Loss: 0.218 | Acc: 91.827% \n",
            "[epoch:87, iter:1992] Loss: 0.211 | Acc: 92.188% \n",
            "[epoch:87, iter:1993] Loss: 0.216 | Acc: 91.875% \n",
            "[epoch:87, iter:1994] Loss: 0.213 | Acc: 91.992% \n",
            "[epoch:87, iter:1995] Loss: 0.225 | Acc: 91.544% \n",
            "[epoch:87, iter:1996] Loss: 0.225 | Acc: 91.667% \n",
            "[epoch:87, iter:1997] Loss: 0.219 | Acc: 91.776% \n",
            "[epoch:87, iter:1998] Loss: 0.220 | Acc: 91.719% \n",
            "[epoch:87, iter:1999] Loss: 0.218 | Acc: 91.667% \n",
            "[epoch:87, iter:2000] Loss: 0.217 | Acc: 91.761% \n",
            "[epoch:87, iter:2001] Loss: 0.213 | Acc: 91.984% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 88\n",
            "[epoch:88, iter:2002] Loss: 0.156 | Acc: 96.875% \n",
            "[epoch:88, iter:2003] Loss: 0.184 | Acc: 92.188% \n",
            "[epoch:88, iter:2004] Loss: 0.214 | Acc: 91.667% \n",
            "[epoch:88, iter:2005] Loss: 0.267 | Acc: 89.844% \n",
            "[epoch:88, iter:2006] Loss: 0.234 | Acc: 91.875% \n",
            "[epoch:88, iter:2007] Loss: 0.219 | Acc: 92.188% \n",
            "[epoch:88, iter:2008] Loss: 0.219 | Acc: 92.857% \n",
            "[epoch:88, iter:2009] Loss: 0.198 | Acc: 93.359% \n",
            "[epoch:88, iter:2010] Loss: 0.190 | Acc: 93.403% \n",
            "[epoch:88, iter:2011] Loss: 0.198 | Acc: 92.812% \n",
            "[epoch:88, iter:2012] Loss: 0.227 | Acc: 92.330% \n",
            "[epoch:88, iter:2013] Loss: 0.226 | Acc: 92.188% \n",
            "[epoch:88, iter:2014] Loss: 0.235 | Acc: 91.587% \n",
            "[epoch:88, iter:2015] Loss: 0.237 | Acc: 91.518% \n",
            "[epoch:88, iter:2016] Loss: 0.238 | Acc: 91.458% \n",
            "[epoch:88, iter:2017] Loss: 0.237 | Acc: 91.602% \n",
            "[epoch:88, iter:2018] Loss: 0.243 | Acc: 91.728% \n",
            "[epoch:88, iter:2019] Loss: 0.247 | Acc: 91.319% \n",
            "[epoch:88, iter:2020] Loss: 0.240 | Acc: 91.612% \n",
            "[epoch:88, iter:2021] Loss: 0.257 | Acc: 91.250% \n",
            "[epoch:88, iter:2022] Loss: 0.267 | Acc: 90.774% \n",
            "[epoch:88, iter:2023] Loss: 0.269 | Acc: 90.767% \n",
            "[epoch:88, iter:2024] Loss: 0.270 | Acc: 90.625% \n",
            "Waiting Test...\n",
            "Test's ac is: 38.636%\n",
            "\n",
            "Epoch: 89\n",
            "[epoch:89, iter:2025] Loss: 0.323 | Acc: 81.250% \n",
            "[epoch:89, iter:2026] Loss: 0.304 | Acc: 85.938% \n",
            "[epoch:89, iter:2027] Loss: 0.337 | Acc: 88.542% \n",
            "[epoch:89, iter:2028] Loss: 0.302 | Acc: 89.844% \n",
            "[epoch:89, iter:2029] Loss: 0.321 | Acc: 89.375% \n",
            "[epoch:89, iter:2030] Loss: 0.328 | Acc: 89.583% \n",
            "[epoch:89, iter:2031] Loss: 0.316 | Acc: 89.732% \n",
            "[epoch:89, iter:2032] Loss: 0.297 | Acc: 89.844% \n",
            "[epoch:89, iter:2033] Loss: 0.294 | Acc: 90.278% \n",
            "[epoch:89, iter:2034] Loss: 0.347 | Acc: 89.062% \n",
            "[epoch:89, iter:2035] Loss: 0.323 | Acc: 90.057% \n",
            "[epoch:89, iter:2036] Loss: 0.339 | Acc: 89.583% \n",
            "[epoch:89, iter:2037] Loss: 0.335 | Acc: 89.663% \n",
            "[epoch:89, iter:2038] Loss: 0.330 | Acc: 89.509% \n",
            "[epoch:89, iter:2039] Loss: 0.323 | Acc: 89.792% \n",
            "[epoch:89, iter:2040] Loss: 0.346 | Acc: 88.867% \n",
            "[epoch:89, iter:2041] Loss: 0.352 | Acc: 88.235% \n",
            "[epoch:89, iter:2042] Loss: 0.349 | Acc: 87.847% \n",
            "[epoch:89, iter:2043] Loss: 0.362 | Acc: 87.829% \n",
            "[epoch:89, iter:2044] Loss: 0.353 | Acc: 87.969% \n",
            "[epoch:89, iter:2045] Loss: 0.358 | Acc: 88.095% \n",
            "[epoch:89, iter:2046] Loss: 0.372 | Acc: 87.784% \n",
            "[epoch:89, iter:2047] Loss: 0.382 | Acc: 87.636% \n",
            "Waiting Test...\n",
            "Test's ac is: 34.091%\n",
            "\n",
            "Epoch: 90\n",
            "[epoch:90, iter:2048] Loss: 0.431 | Acc: 87.500% \n",
            "[epoch:90, iter:2049] Loss: 0.396 | Acc: 85.938% \n",
            "[epoch:90, iter:2050] Loss: 0.394 | Acc: 86.458% \n",
            "[epoch:90, iter:2051] Loss: 0.371 | Acc: 86.719% \n",
            "[epoch:90, iter:2052] Loss: 0.366 | Acc: 86.875% \n",
            "[epoch:90, iter:2053] Loss: 0.343 | Acc: 88.021% \n",
            "[epoch:90, iter:2054] Loss: 0.338 | Acc: 88.393% \n",
            "[epoch:90, iter:2055] Loss: 0.313 | Acc: 89.062% \n",
            "[epoch:90, iter:2056] Loss: 0.319 | Acc: 88.889% \n",
            "[epoch:90, iter:2057] Loss: 0.341 | Acc: 87.188% \n",
            "[epoch:90, iter:2058] Loss: 0.345 | Acc: 87.500% \n",
            "[epoch:90, iter:2059] Loss: 0.347 | Acc: 87.240% \n",
            "[epoch:90, iter:2060] Loss: 0.343 | Acc: 87.740% \n",
            "[epoch:90, iter:2061] Loss: 0.334 | Acc: 88.393% \n",
            "[epoch:90, iter:2062] Loss: 0.321 | Acc: 88.958% \n",
            "[epoch:90, iter:2063] Loss: 0.318 | Acc: 89.258% \n",
            "[epoch:90, iter:2064] Loss: 0.330 | Acc: 88.971% \n",
            "[epoch:90, iter:2065] Loss: 0.334 | Acc: 88.542% \n",
            "[epoch:90, iter:2066] Loss: 0.337 | Acc: 88.322% \n",
            "[epoch:90, iter:2067] Loss: 0.342 | Acc: 87.969% \n",
            "[epoch:90, iter:2068] Loss: 0.352 | Acc: 87.500% \n",
            "[epoch:90, iter:2069] Loss: 0.363 | Acc: 87.216% \n",
            "[epoch:90, iter:2070] Loss: 0.357 | Acc: 87.636% \n",
            "Waiting Test...\n",
            "Test's ac is: 37.879%\n",
            "\n",
            "Epoch: 91\n",
            "[epoch:91, iter:2071] Loss: 0.172 | Acc: 93.750% \n",
            "[epoch:91, iter:2072] Loss: 0.219 | Acc: 92.188% \n",
            "[epoch:91, iter:2073] Loss: 0.202 | Acc: 92.708% \n",
            "[epoch:91, iter:2074] Loss: 0.280 | Acc: 89.062% \n",
            "[epoch:91, iter:2075] Loss: 0.299 | Acc: 88.750% \n",
            "[epoch:91, iter:2076] Loss: 0.299 | Acc: 88.542% \n",
            "[epoch:91, iter:2077] Loss: 0.292 | Acc: 89.286% \n",
            "[epoch:91, iter:2078] Loss: 0.289 | Acc: 89.453% \n",
            "[epoch:91, iter:2079] Loss: 0.291 | Acc: 89.236% \n",
            "[epoch:91, iter:2080] Loss: 0.333 | Acc: 87.188% \n",
            "[epoch:91, iter:2081] Loss: 0.345 | Acc: 87.216% \n",
            "[epoch:91, iter:2082] Loss: 0.329 | Acc: 87.500% \n",
            "[epoch:91, iter:2083] Loss: 0.326 | Acc: 87.500% \n",
            "[epoch:91, iter:2084] Loss: 0.329 | Acc: 87.277% \n",
            "[epoch:91, iter:2085] Loss: 0.321 | Acc: 87.500% \n",
            "[epoch:91, iter:2086] Loss: 0.340 | Acc: 86.914% \n",
            "[epoch:91, iter:2087] Loss: 0.338 | Acc: 87.132% \n",
            "[epoch:91, iter:2088] Loss: 0.334 | Acc: 87.153% \n",
            "[epoch:91, iter:2089] Loss: 0.332 | Acc: 87.500% \n",
            "[epoch:91, iter:2090] Loss: 0.337 | Acc: 87.344% \n",
            "[epoch:91, iter:2091] Loss: 0.335 | Acc: 87.351% \n",
            "[epoch:91, iter:2092] Loss: 0.348 | Acc: 86.932% \n",
            "[epoch:91, iter:2093] Loss: 0.348 | Acc: 87.092% \n",
            "Waiting Test...\n",
            "Test's ac is: 35.606%\n",
            "\n",
            "Epoch: 92\n",
            "[epoch:92, iter:2094] Loss: 0.129 | Acc: 100.000% \n",
            "[epoch:92, iter:2095] Loss: 0.141 | Acc: 95.312% \n",
            "[epoch:92, iter:2096] Loss: 0.133 | Acc: 95.833% \n",
            "[epoch:92, iter:2097] Loss: 0.214 | Acc: 94.531% \n",
            "[epoch:92, iter:2098] Loss: 0.261 | Acc: 91.250% \n",
            "[epoch:92, iter:2099] Loss: 0.269 | Acc: 90.625% \n",
            "[epoch:92, iter:2100] Loss: 0.285 | Acc: 89.286% \n",
            "[epoch:92, iter:2101] Loss: 0.262 | Acc: 90.234% \n",
            "[epoch:92, iter:2102] Loss: 0.257 | Acc: 90.625% \n",
            "[epoch:92, iter:2103] Loss: 0.261 | Acc: 90.938% \n",
            "[epoch:92, iter:2104] Loss: 0.303 | Acc: 89.773% \n",
            "[epoch:92, iter:2105] Loss: 0.300 | Acc: 90.104% \n",
            "[epoch:92, iter:2106] Loss: 0.290 | Acc: 90.625% \n",
            "[epoch:92, iter:2107] Loss: 0.311 | Acc: 89.509% \n",
            "[epoch:92, iter:2108] Loss: 0.301 | Acc: 90.000% \n",
            "[epoch:92, iter:2109] Loss: 0.302 | Acc: 89.844% \n",
            "[epoch:92, iter:2110] Loss: 0.310 | Acc: 89.522% \n",
            "[epoch:92, iter:2111] Loss: 0.306 | Acc: 89.931% \n",
            "[epoch:92, iter:2112] Loss: 0.311 | Acc: 89.638% \n",
            "[epoch:92, iter:2113] Loss: 0.302 | Acc: 89.844% \n",
            "[epoch:92, iter:2114] Loss: 0.298 | Acc: 89.732% \n",
            "[epoch:92, iter:2115] Loss: 0.304 | Acc: 89.773% \n",
            "[epoch:92, iter:2116] Loss: 0.297 | Acc: 90.082% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.909%\n",
            "\n",
            "Epoch: 93\n",
            "[epoch:93, iter:2117] Loss: 0.198 | Acc: 93.750% \n",
            "[epoch:93, iter:2118] Loss: 0.162 | Acc: 95.312% \n",
            "[epoch:93, iter:2119] Loss: 0.160 | Acc: 94.792% \n",
            "[epoch:93, iter:2120] Loss: 0.182 | Acc: 93.750% \n",
            "[epoch:93, iter:2121] Loss: 0.202 | Acc: 93.125% \n",
            "[epoch:93, iter:2122] Loss: 0.183 | Acc: 93.750% \n",
            "[epoch:93, iter:2123] Loss: 0.193 | Acc: 93.750% \n",
            "[epoch:93, iter:2124] Loss: 0.196 | Acc: 92.969% \n",
            "[epoch:93, iter:2125] Loss: 0.198 | Acc: 93.056% \n",
            "[epoch:93, iter:2126] Loss: 0.202 | Acc: 92.812% \n",
            "[epoch:93, iter:2127] Loss: 0.203 | Acc: 92.614% \n",
            "[epoch:93, iter:2128] Loss: 0.203 | Acc: 92.448% \n",
            "[epoch:93, iter:2129] Loss: 0.210 | Acc: 92.067% \n",
            "[epoch:93, iter:2130] Loss: 0.203 | Acc: 92.411% \n",
            "[epoch:93, iter:2131] Loss: 0.194 | Acc: 92.708% \n",
            "[epoch:93, iter:2132] Loss: 0.191 | Acc: 92.969% \n",
            "[epoch:93, iter:2133] Loss: 0.188 | Acc: 93.199% \n",
            "[epoch:93, iter:2134] Loss: 0.193 | Acc: 92.708% \n",
            "[epoch:93, iter:2135] Loss: 0.200 | Acc: 92.270% \n",
            "[epoch:93, iter:2136] Loss: 0.207 | Acc: 92.188% \n",
            "[epoch:93, iter:2137] Loss: 0.209 | Acc: 92.113% \n",
            "[epoch:93, iter:2138] Loss: 0.205 | Acc: 92.188% \n",
            "[epoch:93, iter:2139] Loss: 0.203 | Acc: 92.255% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.061%\n",
            "\n",
            "Epoch: 94\n",
            "[epoch:94, iter:2140] Loss: 0.095 | Acc: 96.875% \n",
            "[epoch:94, iter:2141] Loss: 0.138 | Acc: 95.312% \n",
            "[epoch:94, iter:2142] Loss: 0.156 | Acc: 92.708% \n",
            "[epoch:94, iter:2143] Loss: 0.168 | Acc: 92.188% \n",
            "[epoch:94, iter:2144] Loss: 0.152 | Acc: 93.750% \n",
            "[epoch:94, iter:2145] Loss: 0.162 | Acc: 92.708% \n",
            "[epoch:94, iter:2146] Loss: 0.207 | Acc: 91.071% \n",
            "[epoch:94, iter:2147] Loss: 0.211 | Acc: 91.016% \n",
            "[epoch:94, iter:2148] Loss: 0.197 | Acc: 92.014% \n",
            "[epoch:94, iter:2149] Loss: 0.231 | Acc: 91.250% \n",
            "[epoch:94, iter:2150] Loss: 0.254 | Acc: 90.909% \n",
            "[epoch:94, iter:2151] Loss: 0.242 | Acc: 91.406% \n",
            "[epoch:94, iter:2152] Loss: 0.235 | Acc: 91.346% \n",
            "[epoch:94, iter:2153] Loss: 0.232 | Acc: 91.518% \n",
            "[epoch:94, iter:2154] Loss: 0.234 | Acc: 91.250% \n",
            "[epoch:94, iter:2155] Loss: 0.234 | Acc: 91.406% \n",
            "[epoch:94, iter:2156] Loss: 0.267 | Acc: 90.441% \n",
            "[epoch:94, iter:2157] Loss: 0.259 | Acc: 90.625% \n",
            "[epoch:94, iter:2158] Loss: 0.256 | Acc: 90.789% \n",
            "[epoch:94, iter:2159] Loss: 0.251 | Acc: 90.938% \n",
            "[epoch:94, iter:2160] Loss: 0.247 | Acc: 90.923% \n",
            "[epoch:94, iter:2161] Loss: 0.255 | Acc: 90.483% \n",
            "[epoch:94, iter:2162] Loss: 0.262 | Acc: 90.082% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.152%\n",
            "\n",
            "Epoch: 95\n",
            "[epoch:95, iter:2163] Loss: 0.191 | Acc: 90.625% \n",
            "[epoch:95, iter:2164] Loss: 0.246 | Acc: 92.188% \n",
            "[epoch:95, iter:2165] Loss: 0.193 | Acc: 92.708% \n",
            "[epoch:95, iter:2166] Loss: 0.217 | Acc: 92.969% \n",
            "[epoch:95, iter:2167] Loss: 0.223 | Acc: 91.875% \n",
            "[epoch:95, iter:2168] Loss: 0.221 | Acc: 92.188% \n",
            "[epoch:95, iter:2169] Loss: 0.220 | Acc: 92.411% \n",
            "[epoch:95, iter:2170] Loss: 0.234 | Acc: 92.188% \n",
            "[epoch:95, iter:2171] Loss: 0.224 | Acc: 92.708% \n",
            "[epoch:95, iter:2172] Loss: 0.212 | Acc: 93.125% \n",
            "[epoch:95, iter:2173] Loss: 0.198 | Acc: 93.750% \n",
            "[epoch:95, iter:2174] Loss: 0.207 | Acc: 92.708% \n",
            "[epoch:95, iter:2175] Loss: 0.199 | Acc: 93.029% \n",
            "[epoch:95, iter:2176] Loss: 0.212 | Acc: 92.188% \n",
            "[epoch:95, iter:2177] Loss: 0.204 | Acc: 92.500% \n",
            "[epoch:95, iter:2178] Loss: 0.198 | Acc: 92.578% \n",
            "[epoch:95, iter:2179] Loss: 0.195 | Acc: 92.647% \n",
            "[epoch:95, iter:2180] Loss: 0.188 | Acc: 93.056% \n",
            "[epoch:95, iter:2181] Loss: 0.184 | Acc: 93.257% \n",
            "[epoch:95, iter:2182] Loss: 0.188 | Acc: 92.969% \n",
            "[epoch:95, iter:2183] Loss: 0.200 | Acc: 93.006% \n",
            "[epoch:95, iter:2184] Loss: 0.200 | Acc: 93.182% \n",
            "[epoch:95, iter:2185] Loss: 0.195 | Acc: 93.478% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.061%\n",
            "\n",
            "Epoch: 96\n",
            "[epoch:96, iter:2186] Loss: 0.154 | Acc: 90.625% \n",
            "[epoch:96, iter:2187] Loss: 0.135 | Acc: 93.750% \n",
            "[epoch:96, iter:2188] Loss: 0.145 | Acc: 92.708% \n",
            "[epoch:96, iter:2189] Loss: 0.133 | Acc: 92.969% \n",
            "[epoch:96, iter:2190] Loss: 0.155 | Acc: 93.750% \n",
            "[epoch:96, iter:2191] Loss: 0.137 | Acc: 94.792% \n",
            "[epoch:96, iter:2192] Loss: 0.125 | Acc: 95.536% \n",
            "[epoch:96, iter:2193] Loss: 0.131 | Acc: 95.703% \n",
            "[epoch:96, iter:2194] Loss: 0.128 | Acc: 95.833% \n",
            "[epoch:96, iter:2195] Loss: 0.137 | Acc: 95.625% \n",
            "[epoch:96, iter:2196] Loss: 0.132 | Acc: 95.739% \n",
            "[epoch:96, iter:2197] Loss: 0.140 | Acc: 95.573% \n",
            "[epoch:96, iter:2198] Loss: 0.142 | Acc: 95.433% \n",
            "[epoch:96, iter:2199] Loss: 0.155 | Acc: 94.643% \n",
            "[epoch:96, iter:2200] Loss: 0.165 | Acc: 94.167% \n",
            "[epoch:96, iter:2201] Loss: 0.164 | Acc: 93.945% \n",
            "[epoch:96, iter:2202] Loss: 0.159 | Acc: 94.301% \n",
            "[epoch:96, iter:2203] Loss: 0.153 | Acc: 94.618% \n",
            "[epoch:96, iter:2204] Loss: 0.153 | Acc: 94.243% \n",
            "[epoch:96, iter:2205] Loss: 0.164 | Acc: 94.062% \n",
            "[epoch:96, iter:2206] Loss: 0.164 | Acc: 93.899% \n",
            "[epoch:96, iter:2207] Loss: 0.158 | Acc: 94.176% \n",
            "[epoch:96, iter:2208] Loss: 0.154 | Acc: 94.429% \n",
            "Waiting Test...\n",
            "Test's ac is: 36.364%\n",
            "\n",
            "Epoch: 97\n",
            "[epoch:97, iter:2209] Loss: 0.133 | Acc: 96.875% \n",
            "[epoch:97, iter:2210] Loss: 0.282 | Acc: 90.625% \n",
            "[epoch:97, iter:2211] Loss: 0.230 | Acc: 91.667% \n",
            "[epoch:97, iter:2212] Loss: 0.232 | Acc: 92.188% \n",
            "[epoch:97, iter:2213] Loss: 0.191 | Acc: 93.750% \n",
            "[epoch:97, iter:2214] Loss: 0.184 | Acc: 93.750% \n",
            "[epoch:97, iter:2215] Loss: 0.175 | Acc: 94.196% \n",
            "[epoch:97, iter:2216] Loss: 0.203 | Acc: 93.359% \n",
            "[epoch:97, iter:2217] Loss: 0.203 | Acc: 93.403% \n",
            "[epoch:97, iter:2218] Loss: 0.192 | Acc: 93.750% \n",
            "[epoch:97, iter:2219] Loss: 0.193 | Acc: 93.466% \n",
            "[epoch:97, iter:2220] Loss: 0.194 | Acc: 93.750% \n",
            "[epoch:97, iter:2221] Loss: 0.193 | Acc: 93.269% \n",
            "[epoch:97, iter:2222] Loss: 0.193 | Acc: 93.304% \n",
            "[epoch:97, iter:2223] Loss: 0.189 | Acc: 93.542% \n",
            "[epoch:97, iter:2224] Loss: 0.185 | Acc: 93.555% \n",
            "[epoch:97, iter:2225] Loss: 0.193 | Acc: 93.382% \n",
            "[epoch:97, iter:2226] Loss: 0.187 | Acc: 93.576% \n",
            "[epoch:97, iter:2227] Loss: 0.184 | Acc: 93.750% \n",
            "[epoch:97, iter:2228] Loss: 0.182 | Acc: 93.594% \n",
            "[epoch:97, iter:2229] Loss: 0.181 | Acc: 93.601% \n",
            "[epoch:97, iter:2230] Loss: 0.178 | Acc: 93.750% \n",
            "[epoch:97, iter:2231] Loss: 0.173 | Acc: 93.886% \n",
            "Waiting Test...\n",
            "Test's ac is: 33.333%\n",
            "\n",
            "Epoch: 98\n",
            "[epoch:98, iter:2232] Loss: 0.135 | Acc: 93.750% \n",
            "[epoch:98, iter:2233] Loss: 0.133 | Acc: 93.750% \n",
            "[epoch:98, iter:2234] Loss: 0.141 | Acc: 93.750% \n",
            "[epoch:98, iter:2235] Loss: 0.121 | Acc: 95.312% \n",
            "[epoch:98, iter:2236] Loss: 0.152 | Acc: 93.750% \n",
            "[epoch:98, iter:2237] Loss: 0.134 | Acc: 94.792% \n",
            "[epoch:98, iter:2238] Loss: 0.124 | Acc: 95.089% \n",
            "[epoch:98, iter:2239] Loss: 0.159 | Acc: 94.141% \n",
            "[epoch:98, iter:2240] Loss: 0.165 | Acc: 94.097% \n",
            "[epoch:98, iter:2241] Loss: 0.153 | Acc: 94.375% \n",
            "[epoch:98, iter:2242] Loss: 0.148 | Acc: 94.886% \n",
            "[epoch:98, iter:2243] Loss: 0.154 | Acc: 94.531% \n",
            "[epoch:98, iter:2244] Loss: 0.165 | Acc: 94.231% \n",
            "[epoch:98, iter:2245] Loss: 0.173 | Acc: 93.750% \n",
            "[epoch:98, iter:2246] Loss: 0.170 | Acc: 93.750% \n",
            "[epoch:98, iter:2247] Loss: 0.170 | Acc: 93.750% \n",
            "[epoch:98, iter:2248] Loss: 0.168 | Acc: 93.934% \n",
            "[epoch:98, iter:2249] Loss: 0.173 | Acc: 93.576% \n",
            "[epoch:98, iter:2250] Loss: 0.169 | Acc: 93.750% \n",
            "[epoch:98, iter:2251] Loss: 0.185 | Acc: 93.438% \n",
            "[epoch:98, iter:2252] Loss: 0.195 | Acc: 93.006% \n",
            "[epoch:98, iter:2253] Loss: 0.209 | Acc: 92.898% \n",
            "[epoch:98, iter:2254] Loss: 0.203 | Acc: 93.071% \n",
            "Waiting Test...\n",
            "Test's ac is: 31.061%\n",
            "\n",
            "Epoch: 99\n",
            "[epoch:99, iter:2255] Loss: 0.102 | Acc: 100.000% \n",
            "[epoch:99, iter:2256] Loss: 0.198 | Acc: 96.875% \n",
            "[epoch:99, iter:2257] Loss: 0.219 | Acc: 94.792% \n",
            "[epoch:99, iter:2258] Loss: 0.263 | Acc: 92.188% \n",
            "[epoch:99, iter:2259] Loss: 0.293 | Acc: 91.875% \n",
            "[epoch:99, iter:2260] Loss: 0.315 | Acc: 90.104% \n",
            "[epoch:99, iter:2261] Loss: 0.289 | Acc: 91.071% \n",
            "[epoch:99, iter:2262] Loss: 0.282 | Acc: 91.016% \n",
            "[epoch:99, iter:2263] Loss: 0.295 | Acc: 90.625% \n",
            "[epoch:99, iter:2264] Loss: 0.278 | Acc: 91.250% \n",
            "[epoch:99, iter:2265] Loss: 0.275 | Acc: 91.193% \n",
            "[epoch:99, iter:2266] Loss: 0.281 | Acc: 90.625% \n",
            "[epoch:99, iter:2267] Loss: 0.281 | Acc: 90.865% \n",
            "[epoch:99, iter:2268] Loss: 0.272 | Acc: 91.071% \n",
            "[epoch:99, iter:2269] Loss: 0.296 | Acc: 90.000% \n",
            "[epoch:99, iter:2270] Loss: 0.315 | Acc: 89.844% \n",
            "[epoch:99, iter:2271] Loss: 0.310 | Acc: 90.074% \n",
            "[epoch:99, iter:2272] Loss: 0.300 | Acc: 90.451% \n",
            "[epoch:99, iter:2273] Loss: 0.297 | Acc: 90.296% \n",
            "[epoch:99, iter:2274] Loss: 0.291 | Acc: 90.625% \n",
            "[epoch:99, iter:2275] Loss: 0.294 | Acc: 90.476% \n",
            "[epoch:99, iter:2276] Loss: 0.290 | Acc: 90.483% \n",
            "[epoch:99, iter:2277] Loss: 0.287 | Acc: 90.625% \n",
            "Waiting Test...\n",
            "Test's ac is: 40.909%\n",
            "\n",
            "Epoch: 100\n",
            "[epoch:100, iter:2278] Loss: 0.202 | Acc: 93.750% \n",
            "[epoch:100, iter:2279] Loss: 0.207 | Acc: 93.750% \n",
            "[epoch:100, iter:2280] Loss: 0.205 | Acc: 92.708% \n",
            "[epoch:100, iter:2281] Loss: 0.219 | Acc: 93.750% \n",
            "[epoch:100, iter:2282] Loss: 0.199 | Acc: 94.375% \n",
            "[epoch:100, iter:2283] Loss: 0.205 | Acc: 93.750% \n",
            "[epoch:100, iter:2284] Loss: 0.197 | Acc: 93.750% \n",
            "[epoch:100, iter:2285] Loss: 0.242 | Acc: 93.750% \n",
            "[epoch:100, iter:2286] Loss: 0.227 | Acc: 94.097% \n",
            "[epoch:100, iter:2287] Loss: 0.261 | Acc: 93.125% \n",
            "[epoch:100, iter:2288] Loss: 0.242 | Acc: 93.750% \n",
            "[epoch:100, iter:2289] Loss: 0.245 | Acc: 93.490% \n",
            "[epoch:100, iter:2290] Loss: 0.261 | Acc: 92.548% \n",
            "[epoch:100, iter:2291] Loss: 0.258 | Acc: 92.411% \n",
            "[epoch:100, iter:2292] Loss: 0.253 | Acc: 92.500% \n",
            "[epoch:100, iter:2293] Loss: 0.256 | Acc: 91.992% \n",
            "[epoch:100, iter:2294] Loss: 0.262 | Acc: 91.728% \n",
            "[epoch:100, iter:2295] Loss: 0.272 | Acc: 91.319% \n",
            "[epoch:100, iter:2296] Loss: 0.269 | Acc: 91.283% \n",
            "[epoch:100, iter:2297] Loss: 0.269 | Acc: 91.094% \n",
            "[epoch:100, iter:2298] Loss: 0.272 | Acc: 90.625% \n",
            "[epoch:100, iter:2299] Loss: 0.272 | Acc: 90.625% \n",
            "[epoch:100, iter:2300] Loss: 0.276 | Acc: 90.489% \n",
            "Waiting Test...\n",
            "Test's ac is: 47.727%\n",
            "Train has finished, total epoch is 100\n"
          ]
        }
      ],
      "source": [
        "history = {'train_loss': [], 'train_acc': [], \n",
        "           'valid_loss': [], 'valid_acc': [],\n",
        "           'test_loss': [], 'test_acc': [], 'step_loss': []}\n",
        "\n",
        "#train\n",
        "for epoch in range(pre_epoch, EPOCH):\n",
        "    print('\\nEpoch: %d' % (epoch + 1))\n",
        "    net.train()\n",
        "    sum_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        #prepare dataset\n",
        "        length = len(trainloader)\n",
        "        inputs, labels = data\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #forward & backward\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        #print ac & loss in each batch\n",
        "        sum_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels.data).cpu().sum()\n",
        "\n",
        "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
        "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
        "    history['train_loss'].append(sum_loss)\n",
        "    history['train_acc'].append(100 * correct / total)\n",
        "    \n",
        "    #get the ac with testdataset in each epoch\n",
        "    print('Waiting Test...')\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in testloader:\n",
        "            net.eval()\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum()\n",
        "        \n",
        "\n",
        "        history['test_acc'].append(100 * correct / total)    \n",
        "        print('Test\\'s ac is: %.3f%%' % (100 * correct / total))\n",
        "\n",
        "print('Train has finished, total epoch is %d' % EPOCH)\n",
        "\n",
        "# plot_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk5O3Y8_Ro69"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "o_aflOWKGbi6",
        "44LeXIJKwFZQ",
        "MbR-yzBmklEv",
        "EMULqzxuv5rG",
        "qJuZ48FormXW",
        "PQL4IVupDmQg",
        "bSIWwDsNHauz",
        "AwdusXNJGfqg",
        "IO2bKkvRGx6-",
        "gS3uZ_ADGdkm",
        "VFh9c8v5IoM9",
        "XBF3IrqHMRn9",
        "XCq7PAqOMAej",
        "Ubyhu_2QpF3h",
        "UDyMmKX6e3wl",
        "UT6wjhN-Z_eY",
        "3M5NAOt2cnsK",
        "hdjUxI0hdi0v",
        "wN4162ixeK9w",
        "eQlRP4LrOMlk",
        "n1qYAemsZVGI",
        "rJGy_VeJMRbc",
        "aZkugf5yMbfG",
        "TAIvhiHIMfZK",
        "yOuzoYWn_4wj",
        "Qu8s_8E4Lq6X",
        "uHawo_dHLyUB",
        "icTQXIOKi3OI",
        "-gyBySB0i3OJ",
        "NrxRO1B94cRL"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "83e92b1f3f21fdb4659571439a9645cff8fd2717e8d35e987f7eae31f7f6dd34"
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}