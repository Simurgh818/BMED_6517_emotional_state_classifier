{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simurgh818/BMED_6517_emotional_state_classifier/blob/main/DEAP_CNN_DataAugmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTiKd_g15Kl0",
        "outputId": "7a73ca2e-63b5-49ef-8db5-135eb0b28f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     0K .......... .......... .......... .......... .......... 12.6M\n",
            "    50K .......... .......... .......... .......... .......... 14.6M\n",
            "   100K .......... .......... .......... .......... .......... 14.4M\n",
            "   150K .......... .......... ..                               12.9M=0.01sCloning into 'BMED_6517_emotional_state_classifier'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 136 (delta 5), reused 12 (delta 1), pack-reused 114\u001b[K\n",
            "Receiving objects: 100% (136/136), 78.29 MiB | 17.26 MiB/s, done.\n",
            "Resolving deltas: 100% (49/49), done.\n"
          ]
        }
      ],
      "source": [
        "#importing our git repo\n",
        "import os\n",
        "if not os.path.exists('/content/BMED_6517_emotional_state_classifier'):\n",
        "  !wget https://github.com/Simurgh818/BMED_6517_emotional_state_classifier/blob/main/requirements.txt -q --show-progress --progress=dot\n",
        "  !git clone https://github.com/Simurgh818/BMED_6517_emotional_state_classifier.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKKDN0tIXKTt",
        "outputId": "20b5aa5a-b907-414c-9b1f-f0c03764e035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 19:25:16--  https://drive.google.com/drive/folders/1_9n-kRKkpnCC2wVovOJsIXOyY3BeW1TB?usp=sharing\n",
            "Resolving drive.google.com (drive.google.com)... 142.251.12.101, 142.251.12.113, 142.251.12.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.251.12.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘1_9n-kRKkpnCC2wVovOJsIXOyY3BeW1TB?usp=sharing’\n",
            "\n",
            "1_9n-kRKkpnCC2wVovO     [  <=>               ] 221.02K   842KB/s    in 0.3s    \n",
            "\n",
            "2022-12-02 19:25:18 (842 KB/s) - ‘1_9n-kRKkpnCC2wVovOJsIXOyY3BeW1TB?usp=sharing’ saved [226320]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing the preprocessed dataset files\n",
        "!wget https://drive.google.com/drive/folders/1_9n-kRKkpnCC2wVovOJsIXOyY3BeW1TB?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPTiWGmT7qwu",
        "outputId": "64d72974-649a-4eb1-8937-47c750d4fc11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(880, 5, 32, 32)\n",
            "(880, 5, 512)\n",
            "(880, 32, 6)\n",
            "(880,)\n",
            "(880,)\n",
            "(880,)\n"
          ]
        }
      ],
      "source": [
        "# import data from numpy arrays\n",
        "import numpy as np\n",
        "\n",
        "loaded_features = np.load('/content/BMED_6517_emotional_state_classifier/results/npy/EEG_features.npy', allow_pickle=True)\n",
        "\n",
        "connectivityMatrix = loaded_features.item().get('connectivity_matrix')\n",
        "connectivityLinear = loaded_features.item().get('connectivity_linear')\n",
        "wavelet = loaded_features.item().get('waveletEntropy')\n",
        "Valence = loaded_features.item().get('Valence')\n",
        "Arousal = loaded_features.item().get('Arousal')\n",
        "Classes = loaded_features.item().get('Classes')\n",
        "\n",
        "print(connectivityMatrix.shape)\n",
        "print(connectivityLinear.shape)\n",
        "print(wavelet.shape)\n",
        "print(Valence.shape)\n",
        "print(Arousal.shape)\n",
        "print(Classes.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0N8fbUuUbqYp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing Deep Learning Libraries\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.models import Model,Sequential\n",
        "from keras.optimizers import Adam,SGD,RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8YfwL18POR_d"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l2teHjzaOeHr"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#dataset_labels = np.load('content/gdrive/MyDrive/Colab Notebooks/Copy of labels_1_22.npy', mmap_mode='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ofakMc12O3EG"
      },
      "outputs": [],
      "source": [
        "#dataset_name1 = 'Copy of bipolar_feats.npy'\n",
        "\n",
        "#dataset_bipolarfts = np.load(dataset_name1, encoding='bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YYNle4ynO_uM"
      },
      "outputs": [],
      "source": [
        "#dataset_name2 = 'Copy of labels_1_22.npy'\n",
        "\n",
        "#dataset_labels = np.load(dataset_name2, encoding='bytes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q3o_RfZLPRoI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.datasets import load_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phTMsRTyi6T8",
        "outputId": "fbef99ca-c7a7-4844-ae7e-566718b82d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(880,)\n",
            "[0. 1. 2. 3.]\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(Classes))\n",
        "print(np.unique(Classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bStEfQ5h4t1",
        "outputId": "89512462-9e11-4ed1-cbbe-bcf37895b757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[172]\n"
          ]
        }
      ],
      "source": [
        "# Class balance check:\n",
        "labels = ['Classes']\n",
        "zeros = [Classes[Classes == 0].shape[0]]\n",
        "ones = [Classes[Classes == 1].shape[0]]\n",
        "twos = [Classes[Classes == 2].shape[0]]\n",
        "threes = [Classes[Classes == 3].shape[0]]\n",
        "\n",
        "x = np.arange(1)  # the label locations\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "print(ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "eq2q6c7NniMF",
        "outputId": "772235f2-ad4f-4bd1-91e4-01d8d7578eb0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - 1.5*width, zeros, width, label='zeros')\n",
        "rects2 = ax.bar(x - width/2, ones, width, label='ones')\n",
        "rects3 = ax.bar(x + width/2, twos, width, label='twos')\n",
        "rects4 = ax.bar(x + 1.5*width, threes, width, label='threes')\n",
        "\n",
        "ax.set_title('The numbers of each class')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACiGDaBJh1YO",
        "outputId": "4abb90ca-e18c-4c4a-9beb-10eac6706021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512,) \n",
            " 128*4 is:  512\n",
            "(512, 5, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "# Rebalance classes based on class 1 = 172: Take the first 172 from class 0,2 and 3.\n",
        "zero_mask = (Classes == 0)\n",
        "one_mask = (Classes == 1)\n",
        "two_mask = (Classes == 2)\n",
        "three_mask = (Classes == 3)\n",
        "size = 128\n",
        "\n",
        "Classes_bl = np.concatenate([Classes[zero_mask][:size],Classes[one_mask][:size],\n",
        "                            Classes[two_mask][:size],Classes[three_mask][:size]])\n",
        "print(np.shape(Classes_bl),'\\n 128*4 is: ', 128*4)\n",
        "\n",
        "connectivityMatrix_bl = np.concatenate([connectivityMatrix[zero_mask][:size],connectivityMatrix[one_mask][:size],\n",
        "                            connectivityMatrix[two_mask][:size],connectivityMatrix[three_mask][:size]])\n",
        "print(np.shape(connectivityMatrix_bl))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Classes_bl[Classes_bl == 0].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UntIH3oLMy1",
        "outputId": "5b9777ea-c4b0-40f6-da68-7c9de205313e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVukc0CcuTdR",
        "outputId": "c72880df-e04d-483a-ae0b-179eb191ff6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valence shape is:  (512,)\n",
            "Arousal shape is:  (512,)\n"
          ]
        }
      ],
      "source": [
        "# balancing valence and arrousal\n",
        "Valence_bl = np.concatenate([Valence[zero_mask][:size],Valence[one_mask][:size],\n",
        "                            Valence[two_mask][:size],Valence[three_mask][:size]])\n",
        "print('Valence shape is: ', np.shape(Valence_bl))\n",
        "\n",
        "Arousal_bl = np.concatenate([Arousal[zero_mask][:size],Arousal[one_mask][:size],\n",
        "                            Arousal[two_mask][:size],Arousal[three_mask][:size]])\n",
        "print('Arousal shape is: ', np.shape(Arousal_bl))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_bl = [Classes_bl[Classes_bl == 0].shape[0]]\n",
        "ones_bl = [Classes_bl[Classes_bl == 1].shape[0]]\n",
        "twos_bl = [Classes_bl[Classes_bl == 2].shape[0]]\n",
        "threes_bl = [Classes_bl[Classes_bl == 3].shape[0]]\n",
        "x = np.arange(1)  # the label locations\n",
        "fig2, ax2 = plt.subplots()\n",
        "rects1 = ax2.bar(x - 1.5*width, zeros_bl, width, label='zeros_bl')\n",
        "rects2 = ax2.bar(x - width/2, ones_bl, width, label='ones_bl')\n",
        "rects3 = ax2.bar(x + width/2, twos_bl, width, label='twos_bl')\n",
        "rects4 = ax2.bar(x + 1.5*width, threes_bl, width, label='threes_bl')\n",
        "\n",
        "ax2.set_title('The numbers of each class')\n",
        "ax2.set_xticks(x)\n",
        "ax2.set_xticklabels(labels)\n",
        "ax2.legend()\n",
        "\n",
        "fig2.tight_layout()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "dfzl5-1-J_Uf",
        "outputId": "6d2e2408-147d-4a9a-cf89-0bede812021a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gfXgpkvKs812"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "scD6EPk0s9I3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyU4fNdmCL-l",
        "outputId": "03ba7c5f-13a1-4a9c-baf1-042de02ec5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1. 2. 3.]\n",
            "(512,)\n",
            "[0. 1.]\n",
            "(512, 4)\n",
            "[ 86. 123. 132. 171.]\n"
          ]
        }
      ],
      "source": [
        "# Algorithm 1 for Convolutional Neural Model :\n",
        "##Require: Training EEG Dataset nntrX, Training Valence/Arousal Values nntrY, Testing subject’s EEG\n",
        "#Dataset nnteX, Testing Valence/Arousal Values nnteY\n",
        "# cnn = model(trainX, trainY )\n",
        "\n",
        "#x = dataset_bipolarfts\n",
        "x = connectivityMatrix_bl\n",
        "#y = dataset_labels[1:881]\n",
        "y = np.vstack([Valence_bl,Arousal_bl]).T\n",
        "#x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "y[np.where(y<4.5)] = 0\n",
        "y[np.where(y>=4.5)] = 1\n",
        "y_4_class = y[:,0]*2+y[:,1]\n",
        "print(np.unique(y_4_class))\n",
        "print(y_4_class.shape)\n",
        "y_one_hot = np.zeros((y.shape[0],4))\n",
        "y_one_hot[np.where(y_4_class==0),0] = 1\n",
        "y_one_hot[np.where(y_4_class==1),1] = 1\n",
        "y_one_hot[np.where(y_4_class==2),2] = 1\n",
        "y_one_hot[np.where(y_4_class==3),3] = 1\n",
        "print(np.unique(y_one_hot))\n",
        "print(y_one_hot.shape)\n",
        "print(np.sum(y_one_hot,axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dgqnDGha6IE",
        "outputId": "aac9adf9-d896-44fc-923b-974bae12f096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(160, 5, 32, 32)\n",
            "(352, 5, 32, 32)\n",
            "(352, 4)\n"
          ]
        }
      ],
      "source": [
        "val_size = 4\n",
        "y_test = y_one_hot[:val_size*40,:]\n",
        "x_test = x[:val_size*40,:,:,:]\n",
        "y_train = y_one_hot[val_size*40:,:]\n",
        "x_train = x[val_size*40:,:,:,:]\n",
        "print(x_test.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1zFYJl5heF2R"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D, MaxPooling2D, Activation, concatenate\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.metrics import CategoricalAccuracy,CategoricalCrossentropy,Precision,Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gc1zs7Lfex41"
      },
      "outputs": [],
      "source": [
        "from keras.layers.activation.relu import ReLU\n",
        "def make_CNN_layers(input_mat):\n",
        "  # layer 1\n",
        "  model = Conv2D(16,(3,3),padding='same',input_shape=input_shape)(input_mat)\n",
        "  model = ReLU()(model)\n",
        "  model = MaxPooling2D((2,2),padding='same')(model)\n",
        "  model = Dropout(0.2)(model)\n",
        "\n",
        "  # layer 2\n",
        "  model = Conv2D(32,(3,3),padding='same')(model)\n",
        "  model = ReLU()(model)\n",
        "  model = MaxPooling2D((2,2),padding='same')(model)\n",
        "  model = Dropout(0.2)(model)\n",
        "\n",
        "  #layer 3\n",
        "  model = Conv2D(64,(3,3),padding='same')(model)\n",
        "  model = ReLU()(model)\n",
        "  model = MaxPooling2D((2,2),padding='same')(model)\n",
        "  model = Dropout(0.5)(model)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "djeO0LSKdSAQ"
      },
      "outputs": [],
      "source": [
        "input_shape = x_test[0,0].shape\n",
        "input_shape = (32,32,1)\n",
        "delta_input = Input(shape = input_shape)\n",
        "delta_model = make_CNN_layers(delta_input)\n",
        "\n",
        "theta_input = Input(shape = input_shape)\n",
        "theta_model = make_CNN_layers(theta_input)\n",
        "\n",
        "alpha_input = Input(shape = input_shape)\n",
        "alpha_model = make_CNN_layers(alpha_input)\n",
        "\n",
        "beta_input = Input(shape = input_shape)\n",
        "beta_model = make_CNN_layers(beta_input)\n",
        "\n",
        "gamma_input = Input(shape = input_shape)\n",
        "gamma_model = make_CNN_layers(gamma_input)\n",
        "\n",
        "conv = concatenate([delta_model,theta_model,alpha_model,beta_model,gamma_model])\n",
        "\n",
        "conv = Flatten()(conv)\n",
        "\n",
        "dense = Dense(512)(conv)\n",
        "dense = ReLU()(dense)\n",
        "dense = Dropout(0.3)(dense)\n",
        "\n",
        "output = Dense(4,activation='softmax')(dense)\n",
        "\n",
        "model = Model(inputs=[delta_input,theta_input,alpha_input,beta_input,gamma_input],\n",
        "              outputs=[output])\n",
        "\n",
        "opt = optimizers.SGD(learning_rate=1e-2, momentum=0)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc',Recall(),Precision()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sspGx1ekjYhR",
        "outputId": "f7167f94-a9f7-4ce4-be4d-a3b5ae406bad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_31 (InputLayer)          [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_32 (InputLayer)          [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_33 (InputLayer)          [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_34 (InputLayer)          [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_35 (InputLayer)          [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 32, 32, 16)   160         ['input_31[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 32, 32, 16)   160         ['input_32[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 32, 32, 16)   160         ['input_33[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_99 (Conv2D)             (None, 32, 32, 16)   160         ['input_34[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 32, 32, 16)   160         ['input_35[0][0]']               \n",
            "                                                                                                  \n",
            " re_lu_96 (ReLU)                (None, 32, 32, 16)   0           ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_99 (ReLU)                (None, 32, 32, 16)   0           ['conv2d_93[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_102 (ReLU)               (None, 32, 32, 16)   0           ['conv2d_96[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_105 (ReLU)               (None, 32, 32, 16)   0           ['conv2d_99[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_108 (ReLU)               (None, 32, 32, 16)   0           ['conv2d_102[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_90 (MaxPooling2D  (None, 16, 16, 16)  0           ['re_lu_96[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_93 (MaxPooling2D  (None, 16, 16, 16)  0           ['re_lu_99[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_96 (MaxPooling2D  (None, 16, 16, 16)  0           ['re_lu_102[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_99 (MaxPooling2D  (None, 16, 16, 16)  0           ['re_lu_105[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_102 (MaxPooling2  (None, 16, 16, 16)  0           ['re_lu_108[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout_96 (Dropout)           (None, 16, 16, 16)   0           ['max_pooling2d_90[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_99 (Dropout)           (None, 16, 16, 16)   0           ['max_pooling2d_93[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_102 (Dropout)          (None, 16, 16, 16)   0           ['max_pooling2d_96[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_105 (Dropout)          (None, 16, 16, 16)   0           ['max_pooling2d_99[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_108 (Dropout)          (None, 16, 16, 16)   0           ['max_pooling2d_102[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 16, 16, 32)   4640        ['dropout_96[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 16, 16, 32)   4640        ['dropout_99[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 16, 16, 32)   4640        ['dropout_102[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 16, 16, 32)   4640        ['dropout_105[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 16, 16, 32)   4640        ['dropout_108[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_97 (ReLU)                (None, 16, 16, 32)   0           ['conv2d_91[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_100 (ReLU)               (None, 16, 16, 32)   0           ['conv2d_94[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_103 (ReLU)               (None, 16, 16, 32)   0           ['conv2d_97[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_106 (ReLU)               (None, 16, 16, 32)   0           ['conv2d_100[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_109 (ReLU)               (None, 16, 16, 32)   0           ['conv2d_103[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_91 (MaxPooling2D  (None, 8, 8, 32)    0           ['re_lu_97[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_94 (MaxPooling2D  (None, 8, 8, 32)    0           ['re_lu_100[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_97 (MaxPooling2D  (None, 8, 8, 32)    0           ['re_lu_103[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_100 (MaxPooling2  (None, 8, 8, 32)    0           ['re_lu_106[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_103 (MaxPooling2  (None, 8, 8, 32)    0           ['re_lu_109[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout_97 (Dropout)           (None, 8, 8, 32)     0           ['max_pooling2d_91[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_100 (Dropout)          (None, 8, 8, 32)     0           ['max_pooling2d_94[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_103 (Dropout)          (None, 8, 8, 32)     0           ['max_pooling2d_97[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_106 (Dropout)          (None, 8, 8, 32)     0           ['max_pooling2d_100[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_109 (Dropout)          (None, 8, 8, 32)     0           ['max_pooling2d_103[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 8, 8, 64)     18496       ['dropout_97[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 8, 8, 64)     18496       ['dropout_100[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 8, 8, 64)     18496       ['dropout_103[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 8, 8, 64)     18496       ['dropout_106[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 8, 8, 64)     18496       ['dropout_109[0][0]']            \n",
            "                                                                                                  \n",
            " re_lu_98 (ReLU)                (None, 8, 8, 64)     0           ['conv2d_92[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_101 (ReLU)               (None, 8, 8, 64)     0           ['conv2d_95[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_104 (ReLU)               (None, 8, 8, 64)     0           ['conv2d_98[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_107 (ReLU)               (None, 8, 8, 64)     0           ['conv2d_101[0][0]']             \n",
            "                                                                                                  \n",
            " re_lu_110 (ReLU)               (None, 8, 8, 64)     0           ['conv2d_104[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d_92 (MaxPooling2D  (None, 4, 4, 64)    0           ['re_lu_98[0][0]']               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_95 (MaxPooling2D  (None, 4, 4, 64)    0           ['re_lu_101[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_98 (MaxPooling2D  (None, 4, 4, 64)    0           ['re_lu_104[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_101 (MaxPooling2  (None, 4, 4, 64)    0           ['re_lu_107[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " max_pooling2d_104 (MaxPooling2  (None, 4, 4, 64)    0           ['re_lu_110[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout_98 (Dropout)           (None, 4, 4, 64)     0           ['max_pooling2d_92[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_101 (Dropout)          (None, 4, 4, 64)     0           ['max_pooling2d_95[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_104 (Dropout)          (None, 4, 4, 64)     0           ['max_pooling2d_98[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_107 (Dropout)          (None, 4, 4, 64)     0           ['max_pooling2d_101[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_110 (Dropout)          (None, 4, 4, 64)     0           ['max_pooling2d_104[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate)    (None, 4, 4, 320)    0           ['dropout_98[0][0]',             \n",
            "                                                                  'dropout_101[0][0]',            \n",
            "                                                                  'dropout_104[0][0]',            \n",
            "                                                                  'dropout_107[0][0]',            \n",
            "                                                                  'dropout_110[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 5120)         0           ['concatenate_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 512)          2621952     ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " re_lu_111 (ReLU)               (None, 512)          0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_111 (Dropout)          (None, 512)          0           ['re_lu_111[0][0]']              \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 4)            2052        ['dropout_111[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,740,484\n",
            "Trainable params: 2,740,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_delta = x_train[:,0,:,:]\n",
        "x_theta = x_train[:,1,:,:]\n",
        "x_alpha = x_train[:,2,:,:]\n",
        "x_beta = x_train[:,3,:,:]\n",
        "x_gamma = x_train[:,4,:,:]\n",
        "validation_data=([x_delta[:40],x_theta[:40],x_alpha[:40],x_beta[:40],x_gamma[:40]],y_train[:40])"
      ],
      "metadata": {
        "id": "n0lyC-YhphlO"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation: cropping\n",
        "x_delta = x_train[:,0,:,:]\n",
        "print(np.shape(x_delta))\n",
        "rnd_idx = int(np.round(np.random.rand(1)*100)[0])\n",
        "print(rnd_idx)\n",
        "x_delta_clip = x_train[rnd_idx:rnd_idx+100,0,:,:]\n",
        "print(np.shape(x_delta_clip))\n",
        "x_delta_aug = np.append(x_delta,x_delta_clip, axis=0)\n",
        "print(np.shape(x_delta_aug))\n",
        "\n",
        "x_theta = x_train[:,1,:,:]\n",
        "x_theta_clip = x_train[rnd_idx:rnd_idx+100,1,:,:]\n",
        "x_theta_aug = np.append(x_theta,x_theta_clip, axis=0)\n",
        "\n",
        "x_alpha = x_train[:,2,:,:]\n",
        "x_alpha_clip = x_train[rnd_idx:rnd_idx+100,2,:,:]\n",
        "x_alpha_aug = np.append(x_alpha,x_alpha_clip, axis=0)\n",
        "\n",
        "x_beta = x_train[:,3,:,:]\n",
        "x_beta_clip = x_train[rnd_idx:rnd_idx+100,3,:,:]\n",
        "x_beta_aug = np.append(x_beta,x_beta_clip, axis=0)\n",
        "\n",
        "x_gamma = x_train[:,4,:,:]\n",
        "x_gamma_clip = x_train[rnd_idx:rnd_idx+100,4,:,:]\n",
        "x_gamma_aug = np.append(x_gamma,x_gamma_clip, axis=0)\n",
        "\n",
        "y_clip = y_train[rnd_idx:rnd_idx+100]\n",
        "y_train_aug = np.append(y_train,y_clip, axis=0)\n",
        "print(np.shape(y_train_aug))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaaW295Zjp0E",
        "outputId": "fb3ba727-1f77-4321-a69e-85e155e9e4fe"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(352, 32, 32)\n",
            "45\n",
            "(100, 32, 32)\n",
            "(452, 32, 32)\n",
            "(452, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FutIrekXjult",
        "outputId": "6ab43dcd-6198-4db6-f36a-55218110af20"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.2287 - acc: 0.3977 - recall_5: 0.0085 - precision_5: 0.4286        \n",
            "Epoch 1: val_loss improved from inf to 1.47447, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 2s 65ms/step - loss: 1.2224 - acc: 0.3859 - recall_5: 0.0194 - precision_5: 0.6154 - val_loss: 1.4745 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 2/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1278 - acc: 0.4148 - recall_5: 0.0511 - precision_5: 0.5000\n",
            "Epoch 2: val_loss improved from 1.47447 to 1.34860, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.1351 - acc: 0.3981 - recall_5: 0.0485 - precision_5: 0.4878 - val_loss: 1.3486 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 3/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1271 - acc: 0.3892 - recall_5: 0.0312 - precision_5: 0.4231\n",
            "Epoch 3: val_loss did not improve from 1.34860\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1231 - acc: 0.3932 - recall_5: 0.0388 - precision_5: 0.4000 - val_loss: 1.4004 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 4/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1393 - acc: 0.3977 - recall_5: 0.0312 - precision_5: 0.2750\n",
            "Epoch 4: val_loss did not improve from 1.34860\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1355 - acc: 0.3932 - recall_5: 0.0316 - precision_5: 0.2766 - val_loss: 1.4533 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 5/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.1168 - acc: 0.3719 - recall_5: 0.0469 - precision_5: 0.3947\n",
            "Epoch 5: val_loss did not improve from 1.34860\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.1097 - acc: 0.3811 - recall_5: 0.0558 - precision_5: 0.3966 - val_loss: 1.3921 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 6/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0939 - acc: 0.4031 - recall_5: 0.0500 - precision_5: 0.4103\n",
            "Epoch 6: val_loss improved from 1.34860 to 1.33814, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.0990 - acc: 0.3908 - recall_5: 0.0461 - precision_5: 0.4043 - val_loss: 1.3381 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 7/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.1121 - acc: 0.3403 - recall_5: 0.0521 - precision_5: 0.3333\n",
            "Epoch 7: val_loss improved from 1.33814 to 1.30565, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 1.1287 - acc: 0.3325 - recall_5: 0.0437 - precision_5: 0.3158 - val_loss: 1.3057 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 8/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0761 - acc: 0.4219 - recall_5: 0.0812 - precision_5: 0.4483\n",
            "Epoch 8: val_loss did not improve from 1.30565\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0908 - acc: 0.4053 - recall_5: 0.0704 - precision_5: 0.4085 - val_loss: 1.3113 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 9/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.1275 - acc: 0.3406 - recall_5: 0.0312 - precision_5: 0.2500\n",
            "Epoch 9: val_loss did not improve from 1.30565\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1230 - acc: 0.3495 - recall_5: 0.0413 - precision_5: 0.2931 - val_loss: 1.3337 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 10/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1332 - acc: 0.3750 - recall_5: 0.0426 - precision_5: 0.2727\n",
            "Epoch 10: val_loss improved from 1.30565 to 1.25815, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 1.1375 - acc: 0.3665 - recall_5: 0.0461 - precision_5: 0.2754 - val_loss: 1.2581 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 11/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1123 - acc: 0.3636 - recall_5: 0.0256 - precision_5: 0.3103\n",
            "Epoch 11: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1111 - acc: 0.3617 - recall_5: 0.0316 - precision_5: 0.3250 - val_loss: 1.3737 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 12/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1023 - acc: 0.3949 - recall_5: 0.0568 - precision_5: 0.3922\n",
            "Epoch 12: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1022 - acc: 0.3811 - recall_5: 0.0510 - precision_5: 0.3818 - val_loss: 1.3250 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 13/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0983 - acc: 0.3580 - recall_5: 0.0398 - precision_5: 0.3590\n",
            "Epoch 13: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1012 - acc: 0.3641 - recall_5: 0.0388 - precision_5: 0.3721 - val_loss: 1.2684 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 14/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.1000 - acc: 0.3969 - recall_5: 0.0406 - precision_5: 0.4643\n",
            "Epoch 14: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1036 - acc: 0.4029 - recall_5: 0.0510 - precision_5: 0.5250 - val_loss: 1.2694 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 15/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1147 - acc: 0.3722 - recall_5: 0.0256 - precision_5: 0.3333\n",
            "Epoch 15: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1095 - acc: 0.3811 - recall_5: 0.0316 - precision_5: 0.4194 - val_loss: 1.2751 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 16/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1213 - acc: 0.3438 - recall_5: 0.0284 - precision_5: 0.3846\n",
            "Epoch 16: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1160 - acc: 0.3617 - recall_5: 0.0243 - precision_5: 0.3704 - val_loss: 1.2965 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 17/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1051 - acc: 0.3636 - recall_5: 0.0199 - precision_5: 0.3684        \n",
            "Epoch 17: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0991 - acc: 0.3738 - recall_5: 0.0243 - precision_5: 0.3846 - val_loss: 1.3205 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 18/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0926 - acc: 0.4062 - recall_5: 0.0312 - precision_5: 0.3704\n",
            "Epoch 18: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0980 - acc: 0.4126 - recall_5: 0.0267 - precision_5: 0.3438 - val_loss: 1.2961 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 19/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1175 - acc: 0.3494 - recall_5: 0.0142 - precision_5: 0.1923\n",
            "Epoch 19: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1111 - acc: 0.3519 - recall_5: 0.0121 - precision_5: 0.1613 - val_loss: 1.3094 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 20/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1105 - acc: 0.3636 - recall_5: 0.0312 - precision_5: 0.5789\n",
            "Epoch 20: val_loss did not improve from 1.25815\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1044 - acc: 0.3714 - recall_5: 0.0267 - precision_5: 0.5500 - val_loss: 1.3025 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 21/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0836 - acc: 0.3523 - recall_5: 0.0426 - precision_5: 0.3846\n",
            "Epoch 21: val_loss improved from 1.25815 to 1.25595, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.0904 - acc: 0.3641 - recall_5: 0.0388 - precision_5: 0.3810 - val_loss: 1.2559 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 22/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0838 - acc: 0.4062 - recall_5: 0.0341 - precision_5: 0.3871\n",
            "Epoch 22: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0980 - acc: 0.3908 - recall_5: 0.0291 - precision_5: 0.3429 - val_loss: 1.2604 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 23/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1053 - acc: 0.3494 - recall_5: 0.0114 - precision_5: 0.4444\n",
            "Epoch 23: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1033 - acc: 0.3519 - recall_5: 0.0121 - precision_5: 0.3846 - val_loss: 1.3121 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 24/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0927 - acc: 0.3688 - recall_5: 0.0188 - precision_5: 0.2857\n",
            "Epoch 24: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.1100 - acc: 0.3374 - recall_5: 0.0243 - precision_5: 0.3448 - val_loss: 1.2752 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 25/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0981 - acc: 0.3844 - recall_5: 0.0125 - precision_5: 0.3077\n",
            "Epoch 25: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0969 - acc: 0.3908 - recall_5: 0.0121 - precision_5: 0.2778 - val_loss: 1.3073 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 26/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0681 - acc: 0.4148 - recall_5: 0.0312 - precision_5: 0.4231\n",
            "Epoch 26: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0741 - acc: 0.4102 - recall_5: 0.0291 - precision_5: 0.4286 - val_loss: 1.2614 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 27/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0936 - acc: 0.3778 - recall_5: 0.0369 - precision_5: 0.5200\n",
            "Epoch 27: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0861 - acc: 0.3956 - recall_5: 0.0340 - precision_5: 0.5185 - val_loss: 1.3044 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 28/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.1024 - acc: 0.3750 - recall_5: 0.0188 - precision_5: 0.3333\n",
            "Epoch 28: val_loss did not improve from 1.25595\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0938 - acc: 0.3811 - recall_5: 0.0146 - precision_5: 0.3158 - val_loss: 1.3255 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 29/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0787 - acc: 0.3920 - recall_5: 0.0284 - precision_5: 0.3704\n",
            "Epoch 29: val_loss improved from 1.25595 to 1.24524, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.0850 - acc: 0.3908 - recall_5: 0.0243 - precision_5: 0.3448 - val_loss: 1.2452 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 30/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0789 - acc: 0.3920 - recall_5: 0.0483 - precision_5: 0.4595\n",
            "Epoch 30: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0781 - acc: 0.3811 - recall_5: 0.0437 - precision_5: 0.4737 - val_loss: 1.2618 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 31/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.1037 - acc: 0.3750 - recall_5: 0.0188 - precision_5: 0.3750\n",
            "Epoch 31: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0979 - acc: 0.3835 - recall_5: 0.0146 - precision_5: 0.3158 - val_loss: 1.2932 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 32/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0968 - acc: 0.3636 - recall_5: 0.0511 - precision_5: 0.4286\n",
            "Epoch 32: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0923 - acc: 0.3641 - recall_5: 0.0437 - precision_5: 0.4186 - val_loss: 1.3081 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 33/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0812 - acc: 0.3807 - recall_5: 0.0085 - precision_5: 0.1667\n",
            "Epoch 33: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 1.0914 - acc: 0.3641 - recall_5: 0.0073 - precision_5: 0.1500 - val_loss: 1.3006 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 34/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0856 - acc: 0.4034 - recall_5: 0.0227 - precision_5: 0.3200\n",
            "Epoch 34: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0891 - acc: 0.4053 - recall_5: 0.0267 - precision_5: 0.3793 - val_loss: 1.2814 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 35/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0901 - acc: 0.3938 - recall_5: 0.0063 - precision_5: 0.1818\n",
            "Epoch 35: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0878 - acc: 0.4029 - recall_5: 0.0097 - precision_5: 0.2667 - val_loss: 1.2657 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 36/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1066 - acc: 0.3636 - recall_5: 0.0114 - precision_5: 0.3333\n",
            "Epoch 36: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1070 - acc: 0.3544 - recall_5: 0.0121 - precision_5: 0.3333 - val_loss: 1.2823 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 37/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0904 - acc: 0.3693 - recall_5: 0.0028 - precision_5: 0.0909\n",
            "Epoch 37: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0893 - acc: 0.3568 - recall_5: 0.0024 - precision_5: 0.0909 - val_loss: 1.2849 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 38/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0791 - acc: 0.3938 - recall_5: 0.0219 - precision_5: 0.3500\n",
            "Epoch 38: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0809 - acc: 0.3908 - recall_5: 0.0218 - precision_5: 0.3600 - val_loss: 1.2659 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 39/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0797 - acc: 0.3920 - recall_5: 0.0057 - precision_5: 0.2857\n",
            "Epoch 39: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0825 - acc: 0.3908 - recall_5: 0.0073 - precision_5: 0.3750 - val_loss: 1.2755 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 40/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0853 - acc: 0.3920 - recall_5: 0.0142 - precision_5: 0.3125\n",
            "Epoch 40: val_loss did not improve from 1.24524\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0813 - acc: 0.4078 - recall_5: 0.0146 - precision_5: 0.3529 - val_loss: 1.2627 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 41/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0957 - acc: 0.3608 - recall_5: 0.0057 - precision_5: 0.1538\n",
            "Epoch 41: val_loss improved from 1.24524 to 1.22237, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 1.0981 - acc: 0.3689 - recall_5: 0.0073 - precision_5: 0.1765 - val_loss: 1.2224 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 42/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0921 - acc: 0.3523 - recall_5: 0.0057 - precision_5: 0.2857\n",
            "Epoch 42: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0886 - acc: 0.3714 - recall_5: 0.0049 - precision_5: 0.2857 - val_loss: 1.2848 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 43/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.1003 - acc: 0.3381 - recall_5: 0.0114 - precision_5: 0.2500\n",
            "Epoch 43: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.1010 - acc: 0.3398 - recall_5: 0.0097 - precision_5: 0.2500 - val_loss: 1.2540 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 44/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0932 - acc: 0.3778 - recall_5: 0.0114 - precision_5: 0.3636\n",
            "Epoch 44: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0939 - acc: 0.3762 - recall_5: 0.0121 - precision_5: 0.3571 - val_loss: 1.2638 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 45/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0880 - acc: 0.3594 - recall_5: 0.0031 - precision_5: 0.3333        \n",
            "Epoch 45: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0942 - acc: 0.3519 - recall_5: 0.0024 - precision_5: 0.2500 - val_loss: 1.2346 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 46/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0852 - acc: 0.3949 - recall_5: 0.0085 - precision_5: 0.3750        \n",
            "Epoch 46: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0838 - acc: 0.3956 - recall_5: 0.0073 - precision_5: 0.3750 - val_loss: 1.2673 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 47/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0944 - acc: 0.3864 - recall_5: 0.0114 - precision_5: 0.2353\n",
            "Epoch 47: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0945 - acc: 0.3835 - recall_5: 0.0097 - precision_5: 0.2222 - val_loss: 1.2684 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 48/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0981 - acc: 0.3500 - recall_5: 0.0094 - precision_5: 0.6000\n",
            "Epoch 48: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0836 - acc: 0.3859 - recall_5: 0.0073 - precision_5: 0.5000 - val_loss: 1.2872 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 49/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0698 - acc: 0.3920 - recall_5: 0.0057 - precision_5: 0.2222\n",
            "Epoch 49: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0833 - acc: 0.3786 - recall_5: 0.0073 - precision_5: 0.2143 - val_loss: 1.2413 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 50/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0822 - acc: 0.4034 - recall_5: 0.0284 - precision_5: 0.3704\n",
            "Epoch 50: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0909 - acc: 0.3932 - recall_5: 0.0243 - precision_5: 0.3704 - val_loss: 1.2390 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 51/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0961 - acc: 0.3608 - recall_5: 0.0085 - precision_5: 0.7500\n",
            "Epoch 51: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0950 - acc: 0.3689 - recall_5: 0.0097 - precision_5: 0.8000 - val_loss: 1.2707 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 52/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0927 - acc: 0.3807 - recall_5: 0.0057 - precision_5: 0.1538\n",
            "Epoch 52: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.1023 - acc: 0.3641 - recall_5: 0.0049 - precision_5: 0.1429 - val_loss: 1.2434 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 53/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0969 - acc: 0.3750 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 53: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0849 - acc: 0.3956 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - val_loss: 1.2942 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 54/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0777 - acc: 0.3892 - recall_5: 0.0085 - precision_5: 0.4286\n",
            "Epoch 54: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0782 - acc: 0.3956 - recall_5: 0.0073 - precision_5: 0.4286 - val_loss: 1.2673 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 55/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0881 - acc: 0.3807 - recall_5: 0.0057 - precision_5: 0.5000\n",
            "Epoch 55: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0890 - acc: 0.3738 - recall_5: 0.0049 - precision_5: 0.3333 - val_loss: 1.2613 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 56/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0720 - acc: 0.3892 - recall_5: 0.0028 - precision_5: 0.2000\n",
            "Epoch 56: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0749 - acc: 0.3932 - recall_5: 0.0049 - precision_5: 0.3333 - val_loss: 1.2370 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 57/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0764 - acc: 0.4119 - recall_5: 0.0114 - precision_5: 0.5714\n",
            "Epoch 57: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0827 - acc: 0.4029 - recall_5: 0.0097 - precision_5: 0.5000 - val_loss: 1.2436 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 58/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0704 - acc: 0.4034 - recall_5: 0.0199 - precision_5: 0.4375\n",
            "Epoch 58: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0762 - acc: 0.3859 - recall_5: 0.0170 - precision_5: 0.4375 - val_loss: 1.2525 - val_acc: 0.1250 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 59/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0742 - acc: 0.4119 - recall_5: 0.0028 - precision_5: 0.3333        \n",
            "Epoch 59: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0761 - acc: 0.4175 - recall_5: 0.0024 - precision_5: 0.3333 - val_loss: 1.2596 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 60/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0944 - acc: 0.3267 - recall_5: 0.0057 - precision_5: 0.5000\n",
            "Epoch 60: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0882 - acc: 0.3325 - recall_5: 0.0049 - precision_5: 0.5000 - val_loss: 1.3008 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 61/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0852 - acc: 0.3864 - recall_5: 0.0114 - precision_5: 0.4444\n",
            "Epoch 61: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0803 - acc: 0.3932 - recall_5: 0.0121 - precision_5: 0.4545 - val_loss: 1.2708 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 62/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0755 - acc: 0.3920 - recall_5: 0.0085 - precision_5: 0.3333\n",
            "Epoch 62: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0810 - acc: 0.3835 - recall_5: 0.0073 - precision_5: 0.2500 - val_loss: 1.2694 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 63/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0701 - acc: 0.4119 - recall_5: 0.0114 - precision_5: 0.3077\n",
            "Epoch 63: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0755 - acc: 0.4005 - recall_5: 0.0097 - precision_5: 0.3077 - val_loss: 1.2417 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 64/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0646 - acc: 0.3949 - recall_5: 0.0142 - precision_5: 0.7143\n",
            "Epoch 64: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0683 - acc: 0.4005 - recall_5: 0.0121 - precision_5: 0.7143 - val_loss: 1.2513 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 65/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0591 - acc: 0.4290 - recall_5: 0.0227 - precision_5: 0.6667\n",
            "Epoch 65: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0681 - acc: 0.4078 - recall_5: 0.0194 - precision_5: 0.6154 - val_loss: 1.2348 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 66/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0759 - acc: 0.3977 - recall_5: 0.0028 - precision_5: 0.1667\n",
            "Epoch 66: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0774 - acc: 0.3908 - recall_5: 0.0024 - precision_5: 0.1429 - val_loss: 1.2658 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 67/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0746 - acc: 0.3906 - recall_5: 0.0156 - precision_5: 0.4545\n",
            "Epoch 67: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0738 - acc: 0.3908 - recall_5: 0.0146 - precision_5: 0.4615 - val_loss: 1.2796 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 68/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0649 - acc: 0.4403 - recall_5: 0.0170 - precision_5: 0.6667\n",
            "Epoch 68: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0702 - acc: 0.4320 - recall_5: 0.0146 - precision_5: 0.6000 - val_loss: 1.2628 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 69/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0853 - acc: 0.3835 - recall_5: 0.0057 - precision_5: 0.4000\n",
            "Epoch 69: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0868 - acc: 0.3641 - recall_5: 0.0049 - precision_5: 0.4000 - val_loss: 1.2634 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 70/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0711 - acc: 0.4148 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 70: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0695 - acc: 0.4053 - recall_5: 0.0024 - precision_5: 0.3333 - val_loss: 1.3046 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 71/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0753 - acc: 0.3665 - recall_5: 0.0199 - precision_5: 0.7000\n",
            "Epoch 71: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0770 - acc: 0.3665 - recall_5: 0.0170 - precision_5: 0.7000 - val_loss: 1.2846 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 72/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0869 - acc: 0.3892 - recall_5: 0.0085 - precision_5: 0.4286\n",
            "Epoch 72: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0806 - acc: 0.4029 - recall_5: 0.0073 - precision_5: 0.4286 - val_loss: 1.2848 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 73/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0740 - acc: 0.4091 - recall_5: 0.0057 - precision_5: 0.5000        \n",
            "Epoch 73: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0697 - acc: 0.4102 - recall_5: 0.0073 - precision_5: 0.6000 - val_loss: 1.3097 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 74/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0679 - acc: 0.4094 - recall_5: 0.0375 - precision_5: 0.5217\n",
            "Epoch 74: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0759 - acc: 0.3981 - recall_5: 0.0316 - precision_5: 0.4643 - val_loss: 1.2872 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 75/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0779 - acc: 0.3722 - recall_5: 0.0057 - precision_5: 0.2500\n",
            "Epoch 75: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0856 - acc: 0.3665 - recall_5: 0.0049 - precision_5: 0.2222 - val_loss: 1.2840 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 76/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0668 - acc: 0.4261 - recall_5: 0.0057 - precision_5: 0.6667\n",
            "Epoch 76: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0655 - acc: 0.4126 - recall_5: 0.0049 - precision_5: 0.4000 - val_loss: 1.3227 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 77/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0822 - acc: 0.3466 - recall_5: 0.0085 - precision_5: 0.3750\n",
            "Epoch 77: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0794 - acc: 0.3617 - recall_5: 0.0073 - precision_5: 0.3750 - val_loss: 1.3116 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 78/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0824 - acc: 0.4006 - recall_5: 0.0057 - precision_5: 0.2222\n",
            "Epoch 78: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0699 - acc: 0.4175 - recall_5: 0.0073 - precision_5: 0.2727 - val_loss: 1.3255 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 79/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0716 - acc: 0.3969 - recall_5: 0.0031 - precision_5: 0.3333        \n",
            "Epoch 79: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0687 - acc: 0.4005 - recall_5: 0.0121 - precision_5: 0.7143 - val_loss: 1.2685 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 80/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0657 - acc: 0.4261 - recall_5: 0.0085 - precision_5: 0.5000        \n",
            "Epoch 80: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0723 - acc: 0.4150 - recall_5: 0.0121 - precision_5: 0.4545 - val_loss: 1.2678 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 81/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0913 - acc: 0.3778 - recall_5: 0.0057 - precision_5: 0.2857        \n",
            "Epoch 81: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0921 - acc: 0.3714 - recall_5: 0.0049 - precision_5: 0.2857 - val_loss: 1.2562 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 82/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0714 - acc: 0.3722 - recall_5: 0.0028 - precision_5: 1.0000        \n",
            "Epoch 82: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0710 - acc: 0.3762 - recall_5: 0.0073 - precision_5: 0.7500 - val_loss: 1.3026 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 83/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0738 - acc: 0.3835 - recall_5: 0.0057 - precision_5: 0.5000        \n",
            "Epoch 83: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0636 - acc: 0.3956 - recall_5: 0.0073 - precision_5: 0.5000 - val_loss: 1.3297 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 84/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0641 - acc: 0.3969 - recall_5: 0.0156 - precision_5: 0.5000\n",
            "Epoch 84: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0627 - acc: 0.4029 - recall_5: 0.0170 - precision_5: 0.5833 - val_loss: 1.2715 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 85/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0768 - acc: 0.4034 - recall_5: 0.0028 - precision_5: 0.2000        \n",
            "Epoch 85: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0704 - acc: 0.4150 - recall_5: 0.0024 - precision_5: 0.2000 - val_loss: 1.3267 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 86/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0785 - acc: 0.4233 - recall_5: 0.0028 - precision_5: 0.1667        \n",
            "Epoch 86: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0707 - acc: 0.4248 - recall_5: 0.0097 - precision_5: 0.4000 - val_loss: 1.3210 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 87/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0582 - acc: 0.4340 - recall_5: 0.0139 - precision_5: 0.2222\n",
            "Epoch 87: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0655 - acc: 0.4223 - recall_5: 0.0121 - precision_5: 0.2381 - val_loss: 1.2410 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 88/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0743 - acc: 0.4062 - recall_5: 0.0057 - precision_5: 0.4000        \n",
            "Epoch 88: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0737 - acc: 0.4005 - recall_5: 0.0049 - precision_5: 0.3333 - val_loss: 1.3025 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 89/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0711 - acc: 0.3812 - recall_5: 0.0063 - precision_5: 0.5000\n",
            "Epoch 89: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0729 - acc: 0.3859 - recall_5: 0.0049 - precision_5: 0.2857 - val_loss: 1.3073 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 90/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0860 - acc: 0.3807 - recall_5: 0.0028 - precision_5: 0.3333\n",
            "Epoch 90: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0767 - acc: 0.3981 - recall_5: 0.0049 - precision_5: 0.4000 - val_loss: 1.3398 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 91/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0620 - acc: 0.4148 - recall_5: 0.0114 - precision_5: 0.6667\n",
            "Epoch 91: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0706 - acc: 0.4029 - recall_5: 0.0121 - precision_5: 0.6250 - val_loss: 1.2877 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 92/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0577 - acc: 0.3906 - recall_5: 0.0250 - precision_5: 0.6667\n",
            "Epoch 92: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0666 - acc: 0.3786 - recall_5: 0.0194 - precision_5: 0.6667 - val_loss: 1.3105 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 93/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0843 - acc: 0.3608 - recall_5: 0.0057 - precision_5: 0.5000\n",
            "Epoch 93: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0803 - acc: 0.3786 - recall_5: 0.0049 - precision_5: 0.5000 - val_loss: 1.3348 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 94/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0788 - acc: 0.4176 - recall_5: 0.0085 - precision_5: 0.6000\n",
            "Epoch 94: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0738 - acc: 0.4150 - recall_5: 0.0146 - precision_5: 0.7500 - val_loss: 1.3294 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 95/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0743 - acc: 0.3750 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 95: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0716 - acc: 0.3811 - recall_5: 0.0024 - precision_5: 0.2000 - val_loss: 1.3036 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 96/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0638 - acc: 0.3892 - recall_5: 0.0114 - precision_5: 0.6667\n",
            "Epoch 96: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0595 - acc: 0.3956 - recall_5: 0.0097 - precision_5: 0.6667 - val_loss: 1.3089 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 97/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0592 - acc: 0.4344 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 97: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0667 - acc: 0.4175 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - val_loss: 1.3078 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 98/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0683 - acc: 0.3977 - recall_5: 0.0114 - precision_5: 1.0000\n",
            "Epoch 98: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 14ms/step - loss: 1.0723 - acc: 0.3981 - recall_5: 0.0097 - precision_5: 1.0000 - val_loss: 1.3009 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 99/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0536 - acc: 0.4097 - recall_5: 0.0035 - precision_5: 0.2500\n",
            "Epoch 99: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0631 - acc: 0.4005 - recall_5: 0.0049 - precision_5: 0.4000 - val_loss: 1.2550 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 100/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0616 - acc: 0.4375 - recall_5: 0.0057 - precision_5: 1.0000        \n",
            "Epoch 100: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0610 - acc: 0.4417 - recall_5: 0.0049 - precision_5: 0.6667 - val_loss: 1.2927 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 101/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0633 - acc: 0.3969 - recall_5: 0.0094 - precision_5: 0.5000\n",
            "Epoch 101: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0642 - acc: 0.3956 - recall_5: 0.0146 - precision_5: 0.5455 - val_loss: 1.2875 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 102/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0733 - acc: 0.4148 - recall_5: 0.0085 - precision_5: 0.3000\n",
            "Epoch 102: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0648 - acc: 0.4296 - recall_5: 0.0121 - precision_5: 0.4167 - val_loss: 1.3192 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 103/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0659 - acc: 0.3750 - recall_5: 0.0199 - precision_5: 0.5385\n",
            "Epoch 103: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0707 - acc: 0.3883 - recall_5: 0.0170 - precision_5: 0.5385 - val_loss: 1.2740 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 104/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0666 - acc: 0.4313 - recall_5: 0.0063 - precision_5: 0.4000        \n",
            "Epoch 104: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0618 - acc: 0.4248 - recall_5: 0.0049 - precision_5: 0.3333 - val_loss: 1.3547 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 105/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0570 - acc: 0.4250 - recall_5: 0.0125 - precision_5: 0.5714\n",
            "Epoch 105: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0597 - acc: 0.4223 - recall_5: 0.0097 - precision_5: 0.5000 - val_loss: 1.2979 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 106/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0652 - acc: 0.4187 - recall_5: 0.0063 - precision_5: 0.2857\n",
            "Epoch 106: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0685 - acc: 0.4150 - recall_5: 0.0049 - precision_5: 0.2222 - val_loss: 1.2843 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 107/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0584 - acc: 0.4000 - recall_5: 0.0094 - precision_5: 0.7500        \n",
            "Epoch 107: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0616 - acc: 0.3932 - recall_5: 0.0073 - precision_5: 0.7500 - val_loss: 1.2619 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 108/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0825 - acc: 0.3551 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 108: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0754 - acc: 0.3568 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - val_loss: 1.3541 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 109/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0661 - acc: 0.3889 - recall_5: 0.0104 - precision_5: 0.3000\n",
            "Epoch 109: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0640 - acc: 0.3981 - recall_5: 0.0073 - precision_5: 0.1875 - val_loss: 1.3458 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 110/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0564 - acc: 0.4091 - recall_5: 0.0057 - precision_5: 0.3333        \n",
            "Epoch 110: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0602 - acc: 0.3932 - recall_5: 0.0073 - precision_5: 0.4286 - val_loss: 1.3301 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 111/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0507 - acc: 0.4132 - recall_5: 0.0104 - precision_5: 0.6000\n",
            "Epoch 111: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0670 - acc: 0.4175 - recall_5: 0.0097 - precision_5: 0.6667 - val_loss: 1.3268 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 112/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0627 - acc: 0.3812 - recall_5: 0.0063 - precision_5: 1.0000\n",
            "Epoch 112: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0690 - acc: 0.3762 - recall_5: 0.0049 - precision_5: 0.5000 - val_loss: 1.3089 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 113/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0542 - acc: 0.4631 - recall_5: 0.0028 - precision_5: 1.0000        \n",
            "Epoch 113: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0512 - acc: 0.4782 - recall_5: 0.0024 - precision_5: 1.0000 - val_loss: 1.3370 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 114/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0670 - acc: 0.3562 - recall_5: 0.0125 - precision_5: 0.5000\n",
            "Epoch 114: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0660 - acc: 0.3714 - recall_5: 0.0097 - precision_5: 0.4444 - val_loss: 1.3429 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 115/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0696 - acc: 0.4062 - recall_5: 0.0142 - precision_5: 0.6250\n",
            "Epoch 115: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0712 - acc: 0.3932 - recall_5: 0.0121 - precision_5: 0.6250 - val_loss: 1.3029 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 116/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0607 - acc: 0.4219 - recall_5: 0.0063 - precision_5: 1.0000\n",
            "Epoch 116: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0655 - acc: 0.4150 - recall_5: 0.0049 - precision_5: 0.6667 - val_loss: 1.2922 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 117/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0577 - acc: 0.4290 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00\n",
            "Epoch 117: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0579 - acc: 0.4369 - recall_5: 0.0000e+00 - precision_5: 0.0000e+00 - val_loss: 1.3321 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 118/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0559 - acc: 0.4469 - recall_5: 0.0156 - precision_5: 0.5556\n",
            "Epoch 118: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0608 - acc: 0.4248 - recall_5: 0.0121 - precision_5: 0.4545 - val_loss: 1.2995 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 119/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0584 - acc: 0.4097 - recall_5: 0.0069 - precision_5: 1.0000\n",
            "Epoch 119: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0584 - acc: 0.4102 - recall_5: 0.0073 - precision_5: 0.5000 - val_loss: 1.3654 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 120/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0458 - acc: 0.4281 - recall_5: 0.0094 - precision_5: 0.3750\n",
            "Epoch 120: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0543 - acc: 0.4296 - recall_5: 0.0121 - precision_5: 0.4545 - val_loss: 1.3059 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 121/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0472 - acc: 0.4318 - recall_5: 0.0170 - precision_5: 0.5455\n",
            "Epoch 121: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0552 - acc: 0.4248 - recall_5: 0.0146 - precision_5: 0.5455 - val_loss: 1.2712 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 122/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0544 - acc: 0.4031 - recall_5: 0.0156 - precision_5: 0.7143        \n",
            "Epoch 122: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0593 - acc: 0.4053 - recall_5: 0.0194 - precision_5: 0.7273 - val_loss: 1.2833 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0624 - acc: 0.4272 - recall_5: 0.0049 - precision_5: 0.2857\n",
            "Epoch 123: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0624 - acc: 0.4272 - recall_5: 0.0049 - precision_5: 0.2857 - val_loss: 1.3463 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 124/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0408 - acc: 0.4437 - recall_5: 0.0156 - precision_5: 0.3846        \n",
            "Epoch 124: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0482 - acc: 0.4417 - recall_5: 0.0121 - precision_5: 0.3125 - val_loss: 1.2973 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 125/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0439 - acc: 0.4403 - recall_5: 0.0142 - precision_5: 0.4167\n",
            "Epoch 125: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0532 - acc: 0.4272 - recall_5: 0.0121 - precision_5: 0.4167 - val_loss: 1.3122 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 126/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0578 - acc: 0.4250 - recall_5: 0.0219 - precision_5: 0.5000\n",
            "Epoch 126: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0662 - acc: 0.4150 - recall_5: 0.0170 - precision_5: 0.4375 - val_loss: 1.3003 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 127/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0639 - acc: 0.4250 - recall_5: 0.0094 - precision_5: 0.5000        \n",
            "Epoch 127: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0596 - acc: 0.4369 - recall_5: 0.0097 - precision_5: 0.5000 - val_loss: 1.3418 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 128/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0695 - acc: 0.4125 - recall_5: 0.0031 - precision_5: 0.3333        \n",
            "Epoch 128: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0566 - acc: 0.4150 - recall_5: 0.0097 - precision_5: 0.5000 - val_loss: 1.3944 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 129/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0585 - acc: 0.4375 - recall_5: 0.0281 - precision_5: 0.6429\n",
            "Epoch 129: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0559 - acc: 0.4248 - recall_5: 0.0218 - precision_5: 0.6000 - val_loss: 1.3592 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 130/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0349 - acc: 0.4410 - recall_5: 0.0174 - precision_5: 0.8333\n",
            "Epoch 130: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0457 - acc: 0.4272 - recall_5: 0.0170 - precision_5: 0.7000 - val_loss: 1.3144 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 131/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0628 - acc: 0.4594 - recall_5: 0.0063 - precision_5: 0.6667\n",
            "Epoch 131: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0557 - acc: 0.4709 - recall_5: 0.0097 - precision_5: 0.8000 - val_loss: 1.3747 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 132/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0548 - acc: 0.4125 - recall_5: 0.0125 - precision_5: 0.4444\n",
            "Epoch 132: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0623 - acc: 0.4005 - recall_5: 0.0121 - precision_5: 0.4167 - val_loss: 1.3541 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 133/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0632 - acc: 0.4375 - recall_5: 0.0035 - precision_5: 0.2500\n",
            "Epoch 133: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0556 - acc: 0.4466 - recall_5: 0.0073 - precision_5: 0.5000 - val_loss: 1.3803 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 134/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0446 - acc: 0.4132 - recall_5: 0.0243 - precision_5: 0.4667\n",
            "Epoch 134: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0508 - acc: 0.4175 - recall_5: 0.0194 - precision_5: 0.4444 - val_loss: 1.2920 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 135/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0509 - acc: 0.4201 - recall_5: 0.0208 - precision_5: 0.5000\n",
            "Epoch 135: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0547 - acc: 0.4150 - recall_5: 0.0170 - precision_5: 0.5000 - val_loss: 1.2708 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 136/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0534 - acc: 0.4375 - recall_5: 0.0085 - precision_5: 0.3750\n",
            "Epoch 136: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0543 - acc: 0.4345 - recall_5: 0.0097 - precision_5: 0.4000 - val_loss: 1.3119 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 137/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0562 - acc: 0.4062 - recall_5: 0.0199 - precision_5: 0.7778\n",
            "Epoch 137: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0652 - acc: 0.3932 - recall_5: 0.0194 - precision_5: 0.7273 - val_loss: 1.3169 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 138/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0691 - acc: 0.4236 - recall_5: 0.0069 - precision_5: 0.4000\n",
            "Epoch 138: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0567 - acc: 0.4393 - recall_5: 0.0121 - precision_5: 0.6250 - val_loss: 1.3639 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 139/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0421 - acc: 0.3938 - recall_5: 0.0094 - precision_5: 0.6000\n",
            "Epoch 139: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0529 - acc: 0.4029 - recall_5: 0.0073 - precision_5: 0.6000 - val_loss: 1.3126 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 140/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0511 - acc: 0.4219 - recall_5: 0.0250 - precision_5: 0.5714\n",
            "Epoch 140: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0430 - acc: 0.4490 - recall_5: 0.0194 - precision_5: 0.5000 - val_loss: 1.3588 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 141/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0278 - acc: 0.4625 - recall_5: 0.0312 - precision_5: 0.4762\n",
            "Epoch 141: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0370 - acc: 0.4539 - recall_5: 0.0243 - precision_5: 0.4762 - val_loss: 1.3187 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0529 - acc: 0.4515 - recall_5: 0.0121 - precision_5: 0.6250\n",
            "Epoch 142: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0529 - acc: 0.4515 - recall_5: 0.0121 - precision_5: 0.6250 - val_loss: 1.2879 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 143/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0372 - acc: 0.4719 - recall_5: 0.0281 - precision_5: 0.4500\n",
            "Epoch 143: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0456 - acc: 0.4612 - recall_5: 0.0218 - precision_5: 0.4286 - val_loss: 1.2767 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 144/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0549 - acc: 0.4318 - recall_5: 0.0142 - precision_5: 0.2381\n",
            "Epoch 144: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0536 - acc: 0.4417 - recall_5: 0.0121 - precision_5: 0.2381 - val_loss: 1.3008 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 145/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0608 - acc: 0.4167 - recall_5: 0.0243 - precision_5: 0.7778\n",
            "Epoch 145: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0562 - acc: 0.4345 - recall_5: 0.0218 - precision_5: 0.8182 - val_loss: 1.2960 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0374 - acc: 0.4466 - recall_5: 0.0267 - precision_5: 0.5238\n",
            "Epoch 146: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0374 - acc: 0.4466 - recall_5: 0.0267 - precision_5: 0.5238 - val_loss: 1.2974 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 147/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0573 - acc: 0.4531 - recall_5: 0.0219 - precision_5: 0.7778\n",
            "Epoch 147: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0499 - acc: 0.4490 - recall_5: 0.0218 - precision_5: 0.7500 - val_loss: 1.3148 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 148/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0430 - acc: 0.4375 - recall_5: 0.0188 - precision_5: 0.5455\n",
            "Epoch 148: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0404 - acc: 0.4442 - recall_5: 0.0267 - precision_5: 0.6875 - val_loss: 1.2493 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 149/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0232 - acc: 0.4563 - recall_5: 0.0219 - precision_5: 0.6364\n",
            "Epoch 149: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0346 - acc: 0.4417 - recall_5: 0.0194 - precision_5: 0.6154 - val_loss: 1.3331 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 150/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0376 - acc: 0.4781 - recall_5: 0.0031 - precision_5: 0.2000        \n",
            "Epoch 150: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0389 - acc: 0.4709 - recall_5: 0.0097 - precision_5: 0.5000 - val_loss: 1.3266 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 151/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.0563 - acc: 0.4453 - recall_5: 0.0234 - precision_5: 0.4737\n",
            "Epoch 151: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0563 - acc: 0.4442 - recall_5: 0.0243 - precision_5: 0.5000 - val_loss: 1.3500 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 152/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0474 - acc: 0.4545 - recall_5: 0.0227 - precision_5: 0.5000\n",
            "Epoch 152: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0471 - acc: 0.4515 - recall_5: 0.0194 - precision_5: 0.4211 - val_loss: 1.3939 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0342 - acc: 0.4684 - recall_5: 0.0364 - precision_5: 0.6522\n",
            "Epoch 153: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0342 - acc: 0.4684 - recall_5: 0.0364 - precision_5: 0.6522 - val_loss: 1.4163 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0340 - acc: 0.4612 - recall_5: 0.0413 - precision_5: 0.7391\n",
            "Epoch 154: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0340 - acc: 0.4612 - recall_5: 0.0413 - precision_5: 0.7391 - val_loss: 1.3246 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0316 - acc: 0.4320 - recall_5: 0.0267 - precision_5: 0.7857\n",
            "Epoch 155: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0316 - acc: 0.4320 - recall_5: 0.0267 - precision_5: 0.7857 - val_loss: 1.2768 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0431 - acc: 0.4199 - recall_5: 0.0316 - precision_5: 0.6190\n",
            "Epoch 156: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0431 - acc: 0.4199 - recall_5: 0.0316 - precision_5: 0.6190 - val_loss: 1.2855 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 157/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0340 - acc: 0.4583 - recall_5: 0.0243 - precision_5: 0.4118\n",
            "Epoch 157: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0364 - acc: 0.4563 - recall_5: 0.0316 - precision_5: 0.5000 - val_loss: 1.3159 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0445 - acc: 0.4612 - recall_5: 0.0340 - precision_5: 0.6364\n",
            "Epoch 158: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0445 - acc: 0.4612 - recall_5: 0.0340 - precision_5: 0.6364 - val_loss: 1.4193 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 159/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0578 - acc: 0.4219 - recall_5: 0.0938 - precision_5: 0.5455\n",
            "Epoch 159: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0533 - acc: 0.4272 - recall_5: 0.0898 - precision_5: 0.5606 - val_loss: 1.3013 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 160/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0337 - acc: 0.4563 - recall_5: 0.0125 - precision_5: 0.5000\n",
            "Epoch 160: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0321 - acc: 0.4563 - recall_5: 0.0121 - precision_5: 0.5556 - val_loss: 1.2422 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0503 - acc: 0.4369 - recall_5: 0.0364 - precision_5: 0.5769\n",
            "Epoch 161: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0503 - acc: 0.4369 - recall_5: 0.0364 - precision_5: 0.5769 - val_loss: 1.3221 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 162/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0399 - acc: 0.4563 - recall_5: 0.0125 - precision_5: 0.4444        \n",
            "Epoch 162: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0310 - acc: 0.4709 - recall_5: 0.0267 - precision_5: 0.6471 - val_loss: 1.2893 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0396 - acc: 0.4417 - recall_5: 0.0510 - precision_5: 0.4565\n",
            "Epoch 163: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0396 - acc: 0.4417 - recall_5: 0.0510 - precision_5: 0.4565 - val_loss: 1.2775 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 164/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0361 - acc: 0.4514 - recall_5: 0.0347 - precision_5: 0.8333\n",
            "Epoch 164: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0409 - acc: 0.4612 - recall_5: 0.0340 - precision_5: 0.6667 - val_loss: 1.3297 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 165/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0404 - acc: 0.4406 - recall_5: 0.0437 - precision_5: 0.6364\n",
            "Epoch 165: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0437 - acc: 0.4515 - recall_5: 0.0485 - precision_5: 0.6897 - val_loss: 1.2794 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 166/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0186 - acc: 0.4719 - recall_5: 0.0531 - precision_5: 0.5862\n",
            "Epoch 166: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0254 - acc: 0.4587 - recall_5: 0.0485 - precision_5: 0.5882 - val_loss: 1.3827 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 167/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0391 - acc: 0.4574 - recall_5: 0.0256 - precision_5: 0.7500\n",
            "Epoch 167: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0358 - acc: 0.4612 - recall_5: 0.0291 - precision_5: 0.6316 - val_loss: 1.4011 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 168/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0461 - acc: 0.4236 - recall_5: 0.0521 - precision_5: 0.5556\n",
            "Epoch 168: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0316 - acc: 0.4563 - recall_5: 0.0534 - precision_5: 0.5641 - val_loss: 1.3170 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 169/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0240 - acc: 0.4826 - recall_5: 0.0556 - precision_5: 0.7619\n",
            "Epoch 169: val_loss did not improve from 1.22237\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0282 - acc: 0.4490 - recall_5: 0.0534 - precision_5: 0.6667 - val_loss: 1.3334 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 170/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0183 - acc: 0.4563 - recall_5: 0.0312 - precision_5: 0.5882\n",
            "Epoch 170: val_loss improved from 1.22237 to 1.20349, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 1.0265 - acc: 0.4442 - recall_5: 0.0340 - precision_5: 0.6087 - val_loss: 1.2035 - val_acc: 0.2250 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0379 - acc: 0.4248 - recall_5: 0.0558 - precision_5: 0.5897\n",
            "Epoch 171: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0379 - acc: 0.4248 - recall_5: 0.0558 - precision_5: 0.5897 - val_loss: 1.2957 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 172/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0446 - acc: 0.4306 - recall_5: 0.0556 - precision_5: 0.5000\n",
            "Epoch 172: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0447 - acc: 0.4296 - recall_5: 0.0485 - precision_5: 0.5405 - val_loss: 1.3131 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 173/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0338 - acc: 0.4469 - recall_5: 0.0437 - precision_5: 0.6667\n",
            "Epoch 173: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0432 - acc: 0.4345 - recall_5: 0.0413 - precision_5: 0.6538 - val_loss: 1.3785 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 174/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0313 - acc: 0.4656 - recall_5: 0.0406 - precision_5: 0.5652\n",
            "Epoch 174: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0291 - acc: 0.4587 - recall_5: 0.0461 - precision_5: 0.5588 - val_loss: 1.3112 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 175/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0245 - acc: 0.4844 - recall_5: 0.0500 - precision_5: 0.6957\n",
            "Epoch 175: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0297 - acc: 0.4806 - recall_5: 0.0558 - precision_5: 0.6389 - val_loss: 1.3906 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 176/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0261 - acc: 0.4618 - recall_5: 0.0590 - precision_5: 0.6800\n",
            "Epoch 176: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0389 - acc: 0.4393 - recall_5: 0.0485 - precision_5: 0.5128 - val_loss: 1.3605 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 177/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0337 - acc: 0.4602 - recall_5: 0.0341 - precision_5: 0.6316\n",
            "Epoch 177: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0350 - acc: 0.4515 - recall_5: 0.0291 - precision_5: 0.5217 - val_loss: 1.4229 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 178/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0325 - acc: 0.4517 - recall_5: 0.0483 - precision_5: 0.6296\n",
            "Epoch 178: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0356 - acc: 0.4709 - recall_5: 0.0461 - precision_5: 0.6333 - val_loss: 1.3168 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 179/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 1.0279 - acc: 0.4716 - recall_5: 0.0597 - precision_5: 0.6364\n",
            "Epoch 179: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0327 - acc: 0.4660 - recall_5: 0.0558 - precision_5: 0.6053 - val_loss: 1.3826 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0371 - acc: 0.4417 - recall_5: 0.0655 - precision_5: 0.6279\n",
            "Epoch 180: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0371 - acc: 0.4417 - recall_5: 0.0655 - precision_5: 0.6279 - val_loss: 1.3994 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 181/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0316 - acc: 0.4656 - recall_5: 0.0469 - precision_5: 0.7500\n",
            "Epoch 181: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0313 - acc: 0.4660 - recall_5: 0.0437 - precision_5: 0.6207 - val_loss: 1.3819 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 182/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0243 - acc: 0.4437 - recall_5: 0.0688 - precision_5: 0.7857\n",
            "Epoch 182: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0196 - acc: 0.4587 - recall_5: 0.0728 - precision_5: 0.7895 - val_loss: 1.5400 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 183/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0507 - acc: 0.4313 - recall_5: 0.0812 - precision_5: 0.6667\n",
            "Epoch 183: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0276 - acc: 0.4709 - recall_5: 0.0850 - precision_5: 0.7292 - val_loss: 1.4233 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0265 - acc: 0.4709 - recall_5: 0.0583 - precision_5: 0.6316\n",
            "Epoch 184: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0265 - acc: 0.4709 - recall_5: 0.0583 - precision_5: 0.6316 - val_loss: 1.4565 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0188 - acc: 0.4830 - recall_5: 0.0995 - precision_5: 0.7193\n",
            "Epoch 185: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0188 - acc: 0.4830 - recall_5: 0.0995 - precision_5: 0.7193 - val_loss: 1.3100 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 186/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0342 - acc: 0.4306 - recall_5: 0.0729 - precision_5: 0.6000\n",
            "Epoch 186: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0367 - acc: 0.4248 - recall_5: 0.0704 - precision_5: 0.5918 - val_loss: 1.3443 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0262 - acc: 0.4612 - recall_5: 0.0583 - precision_5: 0.6000\n",
            "Epoch 187: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0262 - acc: 0.4612 - recall_5: 0.0583 - precision_5: 0.6000 - val_loss: 1.4526 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 188/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0087 - acc: 0.4688 - recall_5: 0.0799 - precision_5: 0.6216\n",
            "Epoch 188: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0091 - acc: 0.4782 - recall_5: 0.0752 - precision_5: 0.5962 - val_loss: 1.3939 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0166 - acc: 0.4951 - recall_5: 0.0971 - precision_5: 0.6154\n",
            "Epoch 189: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0166 - acc: 0.4951 - recall_5: 0.0971 - precision_5: 0.6154 - val_loss: 1.2533 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0167 - acc: 0.4830 - recall_5: 0.0680 - precision_5: 0.5833\n",
            "Epoch 190: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0167 - acc: 0.4830 - recall_5: 0.0680 - precision_5: 0.5833 - val_loss: 1.3269 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 191/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0423 - acc: 0.4583 - recall_5: 0.0660 - precision_5: 0.6552\n",
            "Epoch 191: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0317 - acc: 0.4757 - recall_5: 0.0704 - precision_5: 0.6304 - val_loss: 1.4960 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0296 - acc: 0.4612 - recall_5: 0.0801 - precision_5: 0.5690\n",
            "Epoch 192: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0296 - acc: 0.4612 - recall_5: 0.0801 - precision_5: 0.5690 - val_loss: 1.3012 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0225 - acc: 0.4563 - recall_5: 0.0825 - precision_5: 0.5397\n",
            "Epoch 193: val_loss did not improve from 1.20349\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0225 - acc: 0.4563 - recall_5: 0.0825 - precision_5: 0.5397 - val_loss: 1.3299 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 194/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0213 - acc: 0.4938 - recall_5: 0.0969 - precision_5: 0.5167\n",
            "Epoch 194: val_loss improved from 1.20349 to 1.15665, saving model to weights.best.hdf5\n",
            "13/13 [==============================] - 0s 22ms/step - loss: 1.0304 - acc: 0.4684 - recall_5: 0.0971 - precision_5: 0.5405 - val_loss: 1.1566 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 195/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0379 - acc: 0.4219 - recall_5: 0.0562 - precision_5: 0.6207\n",
            "Epoch 195: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0309 - acc: 0.4466 - recall_5: 0.0607 - precision_5: 0.6250 - val_loss: 1.3875 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 196/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0447 - acc: 0.4500 - recall_5: 0.0719 - precision_5: 0.5610\n",
            "Epoch 196: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0281 - acc: 0.4515 - recall_5: 0.0777 - precision_5: 0.6154 - val_loss: 1.5333 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 197/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0221 - acc: 0.4750 - recall_5: 0.1031 - precision_5: 0.6600\n",
            "Epoch 197: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0191 - acc: 0.4709 - recall_5: 0.0947 - precision_5: 0.6724 - val_loss: 1.5159 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0168 - acc: 0.4757 - recall_5: 0.0850 - precision_5: 0.7955\n",
            "Epoch 198: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0168 - acc: 0.4757 - recall_5: 0.0850 - precision_5: 0.7955 - val_loss: 1.4889 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 199/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0126 - acc: 0.4781 - recall_5: 0.0719 - precision_5: 0.5111\n",
            "Epoch 199: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0190 - acc: 0.4733 - recall_5: 0.0655 - precision_5: 0.4909 - val_loss: 1.4596 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 200/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0366 - acc: 0.4875 - recall_5: 0.1125 - precision_5: 0.4932\n",
            "Epoch 200: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0278 - acc: 0.5000 - recall_5: 0.1092 - precision_5: 0.5357 - val_loss: 1.3092 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0223 - acc: 0.5000 - recall_5: 0.0704 - precision_5: 0.5918\n",
            "Epoch 201: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0223 - acc: 0.5000 - recall_5: 0.0704 - precision_5: 0.5918 - val_loss: 1.4746 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0158 - acc: 0.4951 - recall_5: 0.0947 - precision_5: 0.6000\n",
            "Epoch 202: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0158 - acc: 0.4951 - recall_5: 0.0947 - precision_5: 0.6000 - val_loss: 1.5038 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0204 - acc: 0.4539 - recall_5: 0.0825 - precision_5: 0.6538\n",
            "Epoch 203: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0204 - acc: 0.4539 - recall_5: 0.0825 - precision_5: 0.6538 - val_loss: 1.2757 - val_acc: 0.1250 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0132 - acc: 0.4709 - recall_5: 0.0728 - precision_5: 0.6122\n",
            "Epoch 204: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0132 - acc: 0.4709 - recall_5: 0.0728 - precision_5: 0.6122 - val_loss: 1.4284 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0311 - acc: 0.4709 - recall_5: 0.0752 - precision_5: 0.5741\n",
            "Epoch 205: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0311 - acc: 0.4709 - recall_5: 0.0752 - precision_5: 0.5741 - val_loss: 1.5040 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0262 - acc: 0.4757 - recall_5: 0.0631 - precision_5: 0.5778\n",
            "Epoch 206: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0262 - acc: 0.4757 - recall_5: 0.0631 - precision_5: 0.5778 - val_loss: 1.5141 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0143 - acc: 0.4782 - recall_5: 0.1214 - precision_5: 0.6098\n",
            "Epoch 207: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0143 - acc: 0.4782 - recall_5: 0.1214 - precision_5: 0.6098 - val_loss: 1.3719 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 208/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0451 - acc: 0.4500 - recall_5: 0.0875 - precision_5: 0.6364\n",
            "Epoch 208: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0250 - acc: 0.4782 - recall_5: 0.0922 - precision_5: 0.6552 - val_loss: 1.4346 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0150 - acc: 0.4757 - recall_5: 0.0898 - precision_5: 0.6271\n",
            "Epoch 209: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0150 - acc: 0.4757 - recall_5: 0.0898 - precision_5: 0.6271 - val_loss: 1.3372 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0261 - acc: 0.4709 - recall_5: 0.0801 - precision_5: 0.6346\n",
            "Epoch 210: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0261 - acc: 0.4709 - recall_5: 0.0801 - precision_5: 0.6346 - val_loss: 1.5586 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0090 - acc: 0.4927 - recall_5: 0.1092 - precision_5: 0.6081\n",
            "Epoch 211: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0090 - acc: 0.4927 - recall_5: 0.1092 - precision_5: 0.6081 - val_loss: 1.4013 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0199 - acc: 0.4660 - recall_5: 0.0947 - precision_5: 0.6842\n",
            "Epoch 212: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0199 - acc: 0.4660 - recall_5: 0.0947 - precision_5: 0.6842 - val_loss: 1.5144 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0090 - acc: 0.4709 - recall_5: 0.1092 - precision_5: 0.7031\n",
            "Epoch 213: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0090 - acc: 0.4709 - recall_5: 0.1092 - precision_5: 0.7031 - val_loss: 1.3508 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0133 - acc: 0.4587 - recall_5: 0.0971 - precision_5: 0.6349\n",
            "Epoch 214: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0133 - acc: 0.4587 - recall_5: 0.0971 - precision_5: 0.6349 - val_loss: 1.3401 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0098 - acc: 0.4539 - recall_5: 0.0898 - precision_5: 0.6491\n",
            "Epoch 215: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0098 - acc: 0.4539 - recall_5: 0.0898 - precision_5: 0.6491 - val_loss: 1.4050 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0065 - acc: 0.4782 - recall_5: 0.0995 - precision_5: 0.6212\n",
            "Epoch 216: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0065 - acc: 0.4782 - recall_5: 0.0995 - precision_5: 0.6212 - val_loss: 1.3787 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0153 - acc: 0.4782 - recall_5: 0.0947 - precision_5: 0.6964\n",
            "Epoch 217: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0153 - acc: 0.4782 - recall_5: 0.0947 - precision_5: 0.6964 - val_loss: 1.3666 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0088 - acc: 0.4539 - recall_5: 0.0971 - precision_5: 0.5970\n",
            "Epoch 218: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0088 - acc: 0.4539 - recall_5: 0.0971 - precision_5: 0.5970 - val_loss: 1.3702 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0124 - acc: 0.4709 - recall_5: 0.0995 - precision_5: 0.6119\n",
            "Epoch 219: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0124 - acc: 0.4709 - recall_5: 0.0995 - precision_5: 0.6119 - val_loss: 1.5498 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 220/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9994 - acc: 0.4875 - recall_5: 0.1125 - precision_5: 0.6207\n",
            "Epoch 220: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9994 - acc: 0.4927 - recall_5: 0.1141 - precision_5: 0.5875 - val_loss: 1.5948 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0120 - acc: 0.4806 - recall_5: 0.1553 - precision_5: 0.5981\n",
            "Epoch 221: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0120 - acc: 0.4806 - recall_5: 0.1553 - precision_5: 0.5981 - val_loss: 1.3964 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0223 - acc: 0.4393 - recall_5: 0.0777 - precision_5: 0.5714\n",
            "Epoch 222: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0223 - acc: 0.4393 - recall_5: 0.0777 - precision_5: 0.5714 - val_loss: 1.5469 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 223/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9891 - acc: 0.5000 - recall_5: 0.1181 - precision_5: 0.5667\n",
            "Epoch 223: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9994 - acc: 0.5049 - recall_5: 0.1286 - precision_5: 0.6023 - val_loss: 1.2935 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 224/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 1.0091 - acc: 0.4583 - recall_5: 0.0885 - precision_5: 0.5312\n",
            "Epoch 224: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0076 - acc: 0.4636 - recall_5: 0.0947 - precision_5: 0.5652 - val_loss: 1.2214 - val_acc: 0.2250 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0045 - acc: 0.4806 - recall_5: 0.1092 - precision_5: 0.6338\n",
            "Epoch 225: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0045 - acc: 0.4806 - recall_5: 0.1092 - precision_5: 0.6338 - val_loss: 1.3549 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 226/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 1.0140 - acc: 0.4618 - recall_5: 0.1146 - precision_5: 0.6346\n",
            "Epoch 226: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0026 - acc: 0.4709 - recall_5: 0.1141 - precision_5: 0.6351 - val_loss: 1.5674 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0040 - acc: 0.4927 - recall_5: 0.1141 - precision_5: 0.5949\n",
            "Epoch 227: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0040 - acc: 0.4927 - recall_5: 0.1141 - precision_5: 0.5949 - val_loss: 1.4967 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 228/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9967 - acc: 0.4781 - recall_5: 0.1219 - precision_5: 0.6842\n",
            "Epoch 228: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9962 - acc: 0.4806 - recall_5: 0.1214 - precision_5: 0.7143 - val_loss: 1.3721 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0050 - acc: 0.5291 - recall_5: 0.1165 - precision_5: 0.6000\n",
            "Epoch 229: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0050 - acc: 0.5291 - recall_5: 0.1165 - precision_5: 0.6000 - val_loss: 1.3713 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0014 - acc: 0.4709 - recall_5: 0.0922 - precision_5: 0.6032\n",
            "Epoch 230: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0014 - acc: 0.4709 - recall_5: 0.0922 - precision_5: 0.6032 - val_loss: 1.4873 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0194 - acc: 0.4757 - recall_5: 0.1311 - precision_5: 0.6000\n",
            "Epoch 231: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0194 - acc: 0.4757 - recall_5: 0.1311 - precision_5: 0.6000 - val_loss: 1.5281 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 232/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 1.0143 - acc: 0.4875 - recall_5: 0.1406 - precision_5: 0.5921\n",
            "Epoch 232: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 15ms/step - loss: 1.0112 - acc: 0.4879 - recall_5: 0.1262 - precision_5: 0.5909 - val_loss: 1.4573 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0030 - acc: 0.4976 - recall_5: 0.1141 - precision_5: 0.5949\n",
            "Epoch 233: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 1.0030 - acc: 0.4976 - recall_5: 0.1141 - precision_5: 0.5949 - val_loss: 1.3985 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9978 - acc: 0.4854 - recall_5: 0.1311 - precision_5: 0.5934\n",
            "Epoch 234: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9978 - acc: 0.4854 - recall_5: 0.1311 - precision_5: 0.5934 - val_loss: 1.3037 - val_acc: 0.0750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0081 - acc: 0.4684 - recall_5: 0.1311 - precision_5: 0.6067\n",
            "Epoch 235: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0081 - acc: 0.4684 - recall_5: 0.1311 - precision_5: 0.6067 - val_loss: 1.2414 - val_acc: 0.1000 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0005 - acc: 0.4927 - recall_5: 0.0947 - precision_5: 0.6724\n",
            "Epoch 236: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0005 - acc: 0.4927 - recall_5: 0.0947 - precision_5: 0.6724 - val_loss: 1.4931 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9994 - acc: 0.4879 - recall_5: 0.1796 - precision_5: 0.6016\n",
            "Epoch 237: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9994 - acc: 0.4879 - recall_5: 0.1796 - precision_5: 0.6016 - val_loss: 1.3808 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0012 - acc: 0.4612 - recall_5: 0.1068 - precision_5: 0.6471\n",
            "Epoch 238: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0012 - acc: 0.4612 - recall_5: 0.1068 - precision_5: 0.6471 - val_loss: 1.2256 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9918 - acc: 0.4951 - recall_5: 0.1481 - precision_5: 0.6224\n",
            "Epoch 239: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9918 - acc: 0.4951 - recall_5: 0.1481 - precision_5: 0.6224 - val_loss: 1.5047 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0093 - acc: 0.4879 - recall_5: 0.1117 - precision_5: 0.6301\n",
            "Epoch 240: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0093 - acc: 0.4879 - recall_5: 0.1117 - precision_5: 0.6301 - val_loss: 1.4806 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9964 - acc: 0.5000 - recall_5: 0.1092 - precision_5: 0.6164\n",
            "Epoch 241: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9964 - acc: 0.5000 - recall_5: 0.1092 - precision_5: 0.6164 - val_loss: 1.4354 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 242/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9819 - acc: 0.5104 - recall_5: 0.1493 - precision_5: 0.5972\n",
            "Epoch 242: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9951 - acc: 0.4951 - recall_5: 0.1408 - precision_5: 0.5979 - val_loss: 1.3092 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0000 - acc: 0.4976 - recall_5: 0.1044 - precision_5: 0.6515\n",
            "Epoch 243: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0000 - acc: 0.4976 - recall_5: 0.1044 - precision_5: 0.6515 - val_loss: 1.5969 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9830 - acc: 0.4757 - recall_5: 0.1650 - precision_5: 0.6071\n",
            "Epoch 244: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9830 - acc: 0.4757 - recall_5: 0.1650 - precision_5: 0.6071 - val_loss: 1.4055 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0143 - acc: 0.4587 - recall_5: 0.1311 - precision_5: 0.6207\n",
            "Epoch 245: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0143 - acc: 0.4587 - recall_5: 0.1311 - precision_5: 0.6207 - val_loss: 1.4770 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 246/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9943 - acc: 0.5182 - recall_5: 0.1276 - precision_5: 0.6533\n",
            "Epoch 246: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9926 - acc: 0.5121 - recall_5: 0.1214 - precision_5: 0.6410 - val_loss: 1.5031 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9911 - acc: 0.4976 - recall_5: 0.1286 - precision_5: 0.6092\n",
            "Epoch 247: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9911 - acc: 0.4976 - recall_5: 0.1286 - precision_5: 0.6092 - val_loss: 1.3619 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9982 - acc: 0.4903 - recall_5: 0.1189 - precision_5: 0.6533\n",
            "Epoch 248: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9982 - acc: 0.4903 - recall_5: 0.1189 - precision_5: 0.6533 - val_loss: 1.4790 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9875 - acc: 0.5049 - recall_5: 0.1456 - precision_5: 0.6452\n",
            "Epoch 249: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9875 - acc: 0.5049 - recall_5: 0.1456 - precision_5: 0.6452 - val_loss: 1.4910 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9952 - acc: 0.4879 - recall_5: 0.1359 - precision_5: 0.5957\n",
            "Epoch 250: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9952 - acc: 0.4879 - recall_5: 0.1359 - precision_5: 0.5957 - val_loss: 1.4289 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9950 - acc: 0.4903 - recall_5: 0.1262 - precision_5: 0.6341\n",
            "Epoch 251: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9950 - acc: 0.4903 - recall_5: 0.1262 - precision_5: 0.6341 - val_loss: 1.4102 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0106 - acc: 0.4830 - recall_5: 0.1456 - precision_5: 0.6122\n",
            "Epoch 252: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 1.0106 - acc: 0.4830 - recall_5: 0.1456 - precision_5: 0.6122 - val_loss: 1.4474 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9877 - acc: 0.4879 - recall_5: 0.1165 - precision_5: 0.6400\n",
            "Epoch 253: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9877 - acc: 0.4879 - recall_5: 0.1165 - precision_5: 0.6400 - val_loss: 1.4904 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 254/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9885 - acc: 0.4870 - recall_5: 0.1615 - precision_5: 0.6392\n",
            "Epoch 254: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9871 - acc: 0.4806 - recall_5: 0.1553 - precision_5: 0.6465 - val_loss: 1.5042 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9859 - acc: 0.5073 - recall_5: 0.1456 - precision_5: 0.5714\n",
            "Epoch 255: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9859 - acc: 0.5073 - recall_5: 0.1456 - precision_5: 0.5714 - val_loss: 1.4554 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 1.0021 - acc: 0.4612 - recall_5: 0.1311 - precision_5: 0.5745\n",
            "Epoch 256: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 1.0021 - acc: 0.4612 - recall_5: 0.1311 - precision_5: 0.5745 - val_loss: 1.1788 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9871 - acc: 0.4903 - recall_5: 0.1141 - precision_5: 0.5732\n",
            "Epoch 257: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9871 - acc: 0.4903 - recall_5: 0.1141 - precision_5: 0.5732 - val_loss: 1.5202 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9982 - acc: 0.5000 - recall_5: 0.1383 - precision_5: 0.5278\n",
            "Epoch 258: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9982 - acc: 0.5000 - recall_5: 0.1383 - precision_5: 0.5278 - val_loss: 1.2904 - val_acc: 0.0250 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9966 - acc: 0.4660 - recall_5: 0.1092 - precision_5: 0.5844\n",
            "Epoch 259: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9966 - acc: 0.4660 - recall_5: 0.1092 - precision_5: 0.5844 - val_loss: 1.4000 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 260/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9793 - acc: 0.5451 - recall_5: 0.1146 - precision_5: 0.5789\n",
            "Epoch 260: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9954 - acc: 0.5170 - recall_5: 0.1141 - precision_5: 0.5732 - val_loss: 1.4831 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9923 - acc: 0.4854 - recall_5: 0.1214 - precision_5: 0.6579\n",
            "Epoch 261: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9923 - acc: 0.4854 - recall_5: 0.1214 - precision_5: 0.6579 - val_loss: 1.4931 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9941 - acc: 0.5000 - recall_5: 0.1505 - precision_5: 0.6526\n",
            "Epoch 262: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9941 - acc: 0.5000 - recall_5: 0.1505 - precision_5: 0.6526 - val_loss: 1.5915 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 263/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9745 - acc: 0.5312 - recall_5: 0.1375 - precision_5: 0.6875\n",
            "Epoch 263: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9858 - acc: 0.5073 - recall_5: 0.1359 - precision_5: 0.6222 - val_loss: 1.5726 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 264/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9859 - acc: 0.5094 - recall_5: 0.1156 - precision_5: 0.6607\n",
            "Epoch 264: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9856 - acc: 0.5194 - recall_5: 0.1238 - precision_5: 0.6456 - val_loss: 1.5671 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9782 - acc: 0.4903 - recall_5: 0.1359 - precision_5: 0.6437\n",
            "Epoch 265: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9782 - acc: 0.4903 - recall_5: 0.1359 - precision_5: 0.6437 - val_loss: 1.4452 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 266/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9778 - acc: 0.5031 - recall_5: 0.1625 - precision_5: 0.7123\n",
            "Epoch 266: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9817 - acc: 0.5049 - recall_5: 0.1553 - precision_5: 0.6882 - val_loss: 1.4544 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 267/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9773 - acc: 0.5104 - recall_5: 0.1719 - precision_5: 0.6875\n",
            "Epoch 267: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9793 - acc: 0.5024 - recall_5: 0.1626 - precision_5: 0.6768 - val_loss: 1.4230 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9831 - acc: 0.5121 - recall_5: 0.1408 - precision_5: 0.6105\n",
            "Epoch 268: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9831 - acc: 0.5121 - recall_5: 0.1408 - precision_5: 0.6105 - val_loss: 1.5946 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 269/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9807 - acc: 0.4844 - recall_5: 0.1344 - precision_5: 0.5890\n",
            "Epoch 269: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9903 - acc: 0.4854 - recall_5: 0.1335 - precision_5: 0.5670 - val_loss: 1.5308 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9941 - acc: 0.5000 - recall_5: 0.1505 - precision_5: 0.6019\n",
            "Epoch 270: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9941 - acc: 0.5000 - recall_5: 0.1505 - precision_5: 0.6019 - val_loss: 1.5331 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9858 - acc: 0.4951 - recall_5: 0.1626 - precision_5: 0.6204\n",
            "Epoch 271: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9858 - acc: 0.4951 - recall_5: 0.1626 - precision_5: 0.6204 - val_loss: 1.4804 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 272/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9926 - acc: 0.4896 - recall_5: 0.1328 - precision_5: 0.6071\n",
            "Epoch 272: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9846 - acc: 0.4927 - recall_5: 0.1359 - precision_5: 0.6154 - val_loss: 1.5003 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9899 - acc: 0.5024 - recall_5: 0.1262 - precision_5: 0.6047\n",
            "Epoch 273: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9899 - acc: 0.5024 - recall_5: 0.1262 - precision_5: 0.6047 - val_loss: 1.6943 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9954 - acc: 0.4612 - recall_5: 0.1796 - precision_5: 0.5736\n",
            "Epoch 274: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9954 - acc: 0.4612 - recall_5: 0.1796 - precision_5: 0.5736 - val_loss: 1.6176 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9919 - acc: 0.5121 - recall_5: 0.1408 - precision_5: 0.5631\n",
            "Epoch 275: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9919 - acc: 0.5121 - recall_5: 0.1408 - precision_5: 0.5631 - val_loss: 1.4472 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9845 - acc: 0.5170 - recall_5: 0.1748 - precision_5: 0.6429\n",
            "Epoch 276: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9845 - acc: 0.5170 - recall_5: 0.1748 - precision_5: 0.6429 - val_loss: 1.3282 - val_acc: 0.0000e+00 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9736 - acc: 0.4976 - recall_5: 0.1432 - precision_5: 0.5900\n",
            "Epoch 277: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9736 - acc: 0.4976 - recall_5: 0.1432 - precision_5: 0.5900 - val_loss: 1.4672 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9709 - acc: 0.5121 - recall_5: 0.2039 - precision_5: 0.6512\n",
            "Epoch 278: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9709 - acc: 0.5121 - recall_5: 0.2039 - precision_5: 0.6512 - val_loss: 1.4294 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 279/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9927 - acc: 0.4896 - recall_5: 0.1389 - precision_5: 0.5634\n",
            "Epoch 279: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9803 - acc: 0.5073 - recall_5: 0.1456 - precision_5: 0.6061 - val_loss: 1.4968 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 280/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9713 - acc: 0.5026 - recall_5: 0.1719 - precision_5: 0.6667\n",
            "Epoch 280: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9806 - acc: 0.4806 - recall_5: 0.1650 - precision_5: 0.6602 - val_loss: 1.3876 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 281/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9873 - acc: 0.5156 - recall_5: 0.1500 - precision_5: 0.6076\n",
            "Epoch 281: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9868 - acc: 0.5024 - recall_5: 0.1529 - precision_5: 0.6117 - val_loss: 1.4878 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9770 - acc: 0.4854 - recall_5: 0.1626 - precision_5: 0.6768\n",
            "Epoch 282: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9770 - acc: 0.4854 - recall_5: 0.1626 - precision_5: 0.6768 - val_loss: 1.4601 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9837 - acc: 0.4733 - recall_5: 0.1408 - precision_5: 0.5577\n",
            "Epoch 283: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9837 - acc: 0.4733 - recall_5: 0.1408 - precision_5: 0.5577 - val_loss: 1.5246 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 284/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9632 - acc: 0.5174 - recall_5: 0.1979 - precision_5: 0.5588\n",
            "Epoch 284: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9725 - acc: 0.5121 - recall_5: 0.1772 - precision_5: 0.5840 - val_loss: 1.4028 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9796 - acc: 0.5000 - recall_5: 0.1335 - precision_5: 0.6322\n",
            "Epoch 285: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9796 - acc: 0.5000 - recall_5: 0.1335 - precision_5: 0.6322 - val_loss: 1.6598 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9655 - acc: 0.5316 - recall_5: 0.1845 - precision_5: 0.5984\n",
            "Epoch 286: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9655 - acc: 0.5316 - recall_5: 0.1845 - precision_5: 0.5984 - val_loss: 1.3911 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9926 - acc: 0.5073 - recall_5: 0.1626 - precision_5: 0.5929\n",
            "Epoch 287: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9926 - acc: 0.5073 - recall_5: 0.1626 - precision_5: 0.5929 - val_loss: 1.5221 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9884 - acc: 0.5000 - recall_5: 0.1602 - precision_5: 0.5789\n",
            "Epoch 288: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9884 - acc: 0.5000 - recall_5: 0.1602 - precision_5: 0.5789 - val_loss: 1.5013 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9883 - acc: 0.5049 - recall_5: 0.1165 - precision_5: 0.5393\n",
            "Epoch 289: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9883 - acc: 0.5049 - recall_5: 0.1165 - precision_5: 0.5393 - val_loss: 1.6232 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9759 - acc: 0.5291 - recall_5: 0.1626 - precision_5: 0.6204\n",
            "Epoch 290: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9759 - acc: 0.5291 - recall_5: 0.1626 - precision_5: 0.6204 - val_loss: 1.3889 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9642 - acc: 0.5291 - recall_5: 0.1602 - precision_5: 0.6667\n",
            "Epoch 291: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9642 - acc: 0.5291 - recall_5: 0.1602 - precision_5: 0.6667 - val_loss: 1.4965 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9796 - acc: 0.5194 - recall_5: 0.1917 - precision_5: 0.6220\n",
            "Epoch 292: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9796 - acc: 0.5194 - recall_5: 0.1917 - precision_5: 0.6220 - val_loss: 1.3339 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9740 - acc: 0.5097 - recall_5: 0.1699 - precision_5: 0.6195\n",
            "Epoch 293: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9740 - acc: 0.5097 - recall_5: 0.1699 - precision_5: 0.6195 - val_loss: 1.5227 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9766 - acc: 0.5024 - recall_5: 0.1845 - precision_5: 0.6080\n",
            "Epoch 294: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9766 - acc: 0.5024 - recall_5: 0.1845 - precision_5: 0.6080 - val_loss: 1.4912 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9653 - acc: 0.5437 - recall_5: 0.1893 - precision_5: 0.6190\n",
            "Epoch 295: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9653 - acc: 0.5437 - recall_5: 0.1893 - precision_5: 0.6190 - val_loss: 1.5017 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9681 - acc: 0.5000 - recall_5: 0.1650 - precision_5: 0.6733\n",
            "Epoch 296: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9681 - acc: 0.5000 - recall_5: 0.1650 - precision_5: 0.6733 - val_loss: 1.5403 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 297/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9675 - acc: 0.5000 - recall_5: 0.1953 - precision_5: 0.5906\n",
            "Epoch 297: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9688 - acc: 0.5000 - recall_5: 0.1966 - precision_5: 0.5956 - val_loss: 1.5012 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 298/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9705 - acc: 0.5000 - recall_5: 0.1953 - precision_5: 0.5814\n",
            "Epoch 298: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9738 - acc: 0.4927 - recall_5: 0.1869 - precision_5: 0.5878 - val_loss: 1.5363 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9649 - acc: 0.5558 - recall_5: 0.1796 - precision_5: 0.6116\n",
            "Epoch 299: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9649 - acc: 0.5558 - recall_5: 0.1796 - precision_5: 0.6116 - val_loss: 1.6250 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9683 - acc: 0.4879 - recall_5: 0.1626 - precision_5: 0.5877\n",
            "Epoch 300: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9683 - acc: 0.4879 - recall_5: 0.1626 - precision_5: 0.5877 - val_loss: 1.6364 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9825 - acc: 0.5049 - recall_5: 0.1650 - precision_5: 0.6182\n",
            "Epoch 301: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9825 - acc: 0.5049 - recall_5: 0.1650 - precision_5: 0.6182 - val_loss: 1.6707 - val_acc: 0.1750 - val_recall_5: 0.1500 - val_precision_5: 0.2308\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9716 - acc: 0.5243 - recall_5: 0.2015 - precision_5: 0.5533\n",
            "Epoch 302: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9716 - acc: 0.5243 - recall_5: 0.2015 - precision_5: 0.5533 - val_loss: 1.5289 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9640 - acc: 0.5121 - recall_5: 0.1748 - precision_5: 0.6154\n",
            "Epoch 303: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9640 - acc: 0.5121 - recall_5: 0.1748 - precision_5: 0.6154 - val_loss: 1.6451 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9579 - acc: 0.4927 - recall_5: 0.1893 - precision_5: 0.6240\n",
            "Epoch 304: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9579 - acc: 0.4927 - recall_5: 0.1893 - precision_5: 0.6240 - val_loss: 1.5650 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9645 - acc: 0.5097 - recall_5: 0.2015 - precision_5: 0.6058\n",
            "Epoch 305: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9645 - acc: 0.5097 - recall_5: 0.2015 - precision_5: 0.6058 - val_loss: 1.7134 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 306/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9619 - acc: 0.5000 - recall_5: 0.2431 - precision_5: 0.6667\n",
            "Epoch 306: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9804 - acc: 0.4879 - recall_5: 0.2306 - precision_5: 0.6090 - val_loss: 1.5347 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9640 - acc: 0.5340 - recall_5: 0.1772 - precision_5: 0.6404\n",
            "Epoch 307: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9640 - acc: 0.5340 - recall_5: 0.1772 - precision_5: 0.6404 - val_loss: 1.4769 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9692 - acc: 0.4806 - recall_5: 0.1942 - precision_5: 0.6504\n",
            "Epoch 308: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9692 - acc: 0.4806 - recall_5: 0.1942 - precision_5: 0.6504 - val_loss: 1.7517 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9721 - acc: 0.5267 - recall_5: 0.2379 - precision_5: 0.6087\n",
            "Epoch 309: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9721 - acc: 0.5267 - recall_5: 0.2379 - precision_5: 0.6087 - val_loss: 1.5115 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9742 - acc: 0.5024 - recall_5: 0.1893 - precision_5: 0.5865\n",
            "Epoch 310: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9742 - acc: 0.5024 - recall_5: 0.1893 - precision_5: 0.5865 - val_loss: 1.5280 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9699 - acc: 0.5000 - recall_5: 0.1796 - precision_5: 0.6066\n",
            "Epoch 311: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9699 - acc: 0.5000 - recall_5: 0.1796 - precision_5: 0.6066 - val_loss: 1.6838 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 312/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9674 - acc: 0.5234 - recall_5: 0.2266 - precision_5: 0.5878\n",
            "Epoch 312: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9724 - acc: 0.5146 - recall_5: 0.2184 - precision_5: 0.5806 - val_loss: 1.4512 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9828 - acc: 0.4976 - recall_5: 0.1408 - precision_5: 0.5088\n",
            "Epoch 313: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9828 - acc: 0.4976 - recall_5: 0.1408 - precision_5: 0.5088 - val_loss: 1.6197 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9658 - acc: 0.5097 - recall_5: 0.2015 - precision_5: 0.6058\n",
            "Epoch 314: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9658 - acc: 0.5097 - recall_5: 0.2015 - precision_5: 0.6058 - val_loss: 1.4533 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9726 - acc: 0.5194 - recall_5: 0.1869 - precision_5: 0.5704\n",
            "Epoch 315: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9726 - acc: 0.5194 - recall_5: 0.1869 - precision_5: 0.5704 - val_loss: 1.3460 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 316/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9614 - acc: 0.5286 - recall_5: 0.1719 - precision_5: 0.6947\n",
            "Epoch 316: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9567 - acc: 0.5243 - recall_5: 0.1699 - precision_5: 0.7000 - val_loss: 1.6997 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9639 - acc: 0.5194 - recall_5: 0.2330 - precision_5: 0.5854\n",
            "Epoch 317: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9639 - acc: 0.5194 - recall_5: 0.2330 - precision_5: 0.5854 - val_loss: 1.4384 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9421 - acc: 0.5437 - recall_5: 0.1966 - precision_5: 0.6328\n",
            "Epoch 318: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9421 - acc: 0.5437 - recall_5: 0.1966 - precision_5: 0.6328 - val_loss: 1.5717 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 319/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9593 - acc: 0.5052 - recall_5: 0.1875 - precision_5: 0.5950\n",
            "Epoch 319: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9554 - acc: 0.5049 - recall_5: 0.1869 - precision_5: 0.5878 - val_loss: 1.5911 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9608 - acc: 0.5049 - recall_5: 0.2039 - precision_5: 0.5753\n",
            "Epoch 320: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9608 - acc: 0.5049 - recall_5: 0.2039 - precision_5: 0.5753 - val_loss: 1.4992 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9526 - acc: 0.5340 - recall_5: 0.2039 - precision_5: 0.6131\n",
            "Epoch 321: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9526 - acc: 0.5340 - recall_5: 0.2039 - precision_5: 0.6131 - val_loss: 1.7301 - val_acc: 0.1750 - val_recall_5: 0.0500 - val_precision_5: 0.1818\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9559 - acc: 0.5340 - recall_5: 0.2524 - precision_5: 0.6341\n",
            "Epoch 322: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9559 - acc: 0.5340 - recall_5: 0.2524 - precision_5: 0.6341 - val_loss: 1.6959 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9624 - acc: 0.5388 - recall_5: 0.1942 - precision_5: 0.5882\n",
            "Epoch 323: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9624 - acc: 0.5388 - recall_5: 0.1942 - precision_5: 0.5882 - val_loss: 1.5170 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9568 - acc: 0.5194 - recall_5: 0.1917 - precision_5: 0.6172\n",
            "Epoch 324: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9568 - acc: 0.5194 - recall_5: 0.1917 - precision_5: 0.6172 - val_loss: 1.6449 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 325/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9722 - acc: 0.5000 - recall_5: 0.2281 - precision_5: 0.5794\n",
            "Epoch 325: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9667 - acc: 0.5073 - recall_5: 0.2160 - precision_5: 0.5894 - val_loss: 1.6386 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9549 - acc: 0.5146 - recall_5: 0.2257 - precision_5: 0.6242\n",
            "Epoch 326: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9549 - acc: 0.5146 - recall_5: 0.2257 - precision_5: 0.6242 - val_loss: 1.6912 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9507 - acc: 0.5291 - recall_5: 0.2306 - precision_5: 0.6169\n",
            "Epoch 327: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9507 - acc: 0.5291 - recall_5: 0.2306 - precision_5: 0.6169 - val_loss: 1.7739 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2000\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9484 - acc: 0.5267 - recall_5: 0.2549 - precision_5: 0.6176\n",
            "Epoch 328: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9484 - acc: 0.5267 - recall_5: 0.2549 - precision_5: 0.6176 - val_loss: 1.5924 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 329/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9550 - acc: 0.5495 - recall_5: 0.2734 - precision_5: 0.6481\n",
            "Epoch 329: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9520 - acc: 0.5534 - recall_5: 0.2718 - precision_5: 0.6588 - val_loss: 1.4816 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 330/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9561 - acc: 0.5286 - recall_5: 0.2318 - precision_5: 0.6449\n",
            "Epoch 330: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9572 - acc: 0.5364 - recall_5: 0.2330 - precision_5: 0.6531 - val_loss: 1.6539 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9501 - acc: 0.5218 - recall_5: 0.2597 - precision_5: 0.6331\n",
            "Epoch 331: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9501 - acc: 0.5218 - recall_5: 0.2597 - precision_5: 0.6331 - val_loss: 1.5590 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9460 - acc: 0.5218 - recall_5: 0.2233 - precision_5: 0.6174\n",
            "Epoch 332: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9460 - acc: 0.5218 - recall_5: 0.2233 - precision_5: 0.6174 - val_loss: 1.7381 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.3333\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9516 - acc: 0.5194 - recall_5: 0.2403 - precision_5: 0.5893\n",
            "Epoch 333: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9516 - acc: 0.5194 - recall_5: 0.2403 - precision_5: 0.5893 - val_loss: 1.6189 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9403 - acc: 0.5485 - recall_5: 0.2646 - precision_5: 0.6987\n",
            "Epoch 334: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9403 - acc: 0.5485 - recall_5: 0.2646 - precision_5: 0.6987 - val_loss: 1.6969 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9615 - acc: 0.5218 - recall_5: 0.2500 - precision_5: 0.6280\n",
            "Epoch 335: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9615 - acc: 0.5218 - recall_5: 0.2500 - precision_5: 0.6280 - val_loss: 1.6221 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9503 - acc: 0.5316 - recall_5: 0.2233 - precision_5: 0.6301\n",
            "Epoch 336: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9503 - acc: 0.5316 - recall_5: 0.2233 - precision_5: 0.6301 - val_loss: 1.6826 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9495 - acc: 0.4951 - recall_5: 0.2427 - precision_5: 0.6329\n",
            "Epoch 337: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9495 - acc: 0.4951 - recall_5: 0.2427 - precision_5: 0.6329 - val_loss: 1.7251 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9654 - acc: 0.5146 - recall_5: 0.2330 - precision_5: 0.6076\n",
            "Epoch 338: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9654 - acc: 0.5146 - recall_5: 0.2330 - precision_5: 0.6076 - val_loss: 1.6261 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9593 - acc: 0.5024 - recall_5: 0.2039 - precision_5: 0.5753\n",
            "Epoch 339: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9593 - acc: 0.5024 - recall_5: 0.2039 - precision_5: 0.5753 - val_loss: 1.7274 - val_acc: 0.1750 - val_recall_5: 0.0750 - val_precision_5: 0.2000\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9490 - acc: 0.5340 - recall_5: 0.2549 - precision_5: 0.6402\n",
            "Epoch 340: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9490 - acc: 0.5340 - recall_5: 0.2549 - precision_5: 0.6402 - val_loss: 1.7809 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 341/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9274 - acc: 0.5208 - recall_5: 0.2812 - precision_5: 0.6467\n",
            "Epoch 341: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9375 - acc: 0.5146 - recall_5: 0.2718 - precision_5: 0.6437 - val_loss: 1.5767 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 342/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9499 - acc: 0.5208 - recall_5: 0.2552 - precision_5: 0.6490\n",
            "Epoch 342: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9451 - acc: 0.5267 - recall_5: 0.2524 - precision_5: 0.6541 - val_loss: 1.8144 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9518 - acc: 0.5073 - recall_5: 0.2864 - precision_5: 0.6114\n",
            "Epoch 343: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9518 - acc: 0.5073 - recall_5: 0.2864 - precision_5: 0.6114 - val_loss: 1.6076 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9364 - acc: 0.5485 - recall_5: 0.2694 - precision_5: 0.6453\n",
            "Epoch 344: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9364 - acc: 0.5485 - recall_5: 0.2694 - precision_5: 0.6453 - val_loss: 1.4077 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9568 - acc: 0.5364 - recall_5: 0.2160 - precision_5: 0.5894\n",
            "Epoch 345: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9568 - acc: 0.5364 - recall_5: 0.2160 - precision_5: 0.5894 - val_loss: 1.6599 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9322 - acc: 0.5364 - recall_5: 0.2913 - precision_5: 0.6818\n",
            "Epoch 346: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9322 - acc: 0.5364 - recall_5: 0.2913 - precision_5: 0.6818 - val_loss: 1.4835 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9345 - acc: 0.5267 - recall_5: 0.2379 - precision_5: 0.6087\n",
            "Epoch 347: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9345 - acc: 0.5267 - recall_5: 0.2379 - precision_5: 0.6087 - val_loss: 1.6962 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9521 - acc: 0.5170 - recall_5: 0.2791 - precision_5: 0.6085\n",
            "Epoch 348: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9521 - acc: 0.5170 - recall_5: 0.2791 - precision_5: 0.6085 - val_loss: 1.5861 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 349/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9522 - acc: 0.5208 - recall_5: 0.2370 - precision_5: 0.6233\n",
            "Epoch 349: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9552 - acc: 0.5146 - recall_5: 0.2354 - precision_5: 0.6218 - val_loss: 1.6373 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9424 - acc: 0.5218 - recall_5: 0.2379 - precision_5: 0.6282\n",
            "Epoch 350: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9424 - acc: 0.5218 - recall_5: 0.2379 - precision_5: 0.6282 - val_loss: 1.6693 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9329 - acc: 0.5534 - recall_5: 0.2646 - precision_5: 0.5989\n",
            "Epoch 351: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9329 - acc: 0.5534 - recall_5: 0.2646 - precision_5: 0.5989 - val_loss: 1.5503 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9486 - acc: 0.5243 - recall_5: 0.2476 - precision_5: 0.5965\n",
            "Epoch 352: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9486 - acc: 0.5243 - recall_5: 0.2476 - precision_5: 0.5965 - val_loss: 1.6576 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9379 - acc: 0.5073 - recall_5: 0.2694 - precision_5: 0.6491\n",
            "Epoch 353: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9379 - acc: 0.5073 - recall_5: 0.2694 - precision_5: 0.6491 - val_loss: 1.5230 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9351 - acc: 0.5825 - recall_5: 0.2937 - precision_5: 0.6471\n",
            "Epoch 354: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9351 - acc: 0.5825 - recall_5: 0.2937 - precision_5: 0.6471 - val_loss: 1.4709 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9430 - acc: 0.5146 - recall_5: 0.2451 - precision_5: 0.5805\n",
            "Epoch 355: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9430 - acc: 0.5146 - recall_5: 0.2451 - precision_5: 0.5805 - val_loss: 1.6577 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9561 - acc: 0.5413 - recall_5: 0.2233 - precision_5: 0.6133\n",
            "Epoch 356: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9561 - acc: 0.5413 - recall_5: 0.2233 - precision_5: 0.6133 - val_loss: 1.8253 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9569 - acc: 0.5121 - recall_5: 0.2549 - precision_5: 0.5833\n",
            "Epoch 357: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9569 - acc: 0.5121 - recall_5: 0.2549 - precision_5: 0.5833 - val_loss: 1.8300 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9479 - acc: 0.5170 - recall_5: 0.2743 - precision_5: 0.6243\n",
            "Epoch 358: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9479 - acc: 0.5170 - recall_5: 0.2743 - precision_5: 0.6243 - val_loss: 1.5156 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9600 - acc: 0.5170 - recall_5: 0.2379 - precision_5: 0.6164\n",
            "Epoch 359: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9600 - acc: 0.5170 - recall_5: 0.2379 - precision_5: 0.6164 - val_loss: 1.6426 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 360/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9384 - acc: 0.5417 - recall_5: 0.2526 - precision_5: 0.6062\n",
            "Epoch 360: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9497 - acc: 0.5316 - recall_5: 0.2427 - precision_5: 0.5848 - val_loss: 1.5688 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 361/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9357 - acc: 0.5521 - recall_5: 0.2786 - precision_5: 0.6446\n",
            "Epoch 361: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9338 - acc: 0.5534 - recall_5: 0.2791 - precision_5: 0.6461 - val_loss: 1.7811 - val_acc: 0.1750 - val_recall_5: 0.1500 - val_precision_5: 0.2308\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9452 - acc: 0.5364 - recall_5: 0.2597 - precision_5: 0.6331\n",
            "Epoch 362: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9452 - acc: 0.5364 - recall_5: 0.2597 - precision_5: 0.6331 - val_loss: 1.7666 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9302 - acc: 0.5364 - recall_5: 0.2961 - precision_5: 0.6489\n",
            "Epoch 363: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9302 - acc: 0.5364 - recall_5: 0.2961 - precision_5: 0.6489 - val_loss: 1.6992 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9503 - acc: 0.5340 - recall_5: 0.2743 - precision_5: 0.6011\n",
            "Epoch 364: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9503 - acc: 0.5340 - recall_5: 0.2743 - precision_5: 0.6011 - val_loss: 1.6081 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9319 - acc: 0.5485 - recall_5: 0.2816 - precision_5: 0.6667\n",
            "Epoch 365: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9319 - acc: 0.5485 - recall_5: 0.2816 - precision_5: 0.6667 - val_loss: 1.6828 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9329 - acc: 0.5340 - recall_5: 0.3010 - precision_5: 0.5990\n",
            "Epoch 366: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9329 - acc: 0.5340 - recall_5: 0.3010 - precision_5: 0.5990 - val_loss: 1.7189 - val_acc: 0.1750 - val_recall_5: 0.0750 - val_precision_5: 0.2308\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9509 - acc: 0.4854 - recall_5: 0.2621 - precision_5: 0.5596\n",
            "Epoch 367: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9509 - acc: 0.4854 - recall_5: 0.2621 - precision_5: 0.5596 - val_loss: 1.6250 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9421 - acc: 0.5461 - recall_5: 0.2476 - precision_5: 0.5730\n",
            "Epoch 368: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9421 - acc: 0.5461 - recall_5: 0.2476 - precision_5: 0.5730 - val_loss: 1.6894 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9220 - acc: 0.5073 - recall_5: 0.2937 - precision_5: 0.6576\n",
            "Epoch 369: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9220 - acc: 0.5073 - recall_5: 0.2937 - precision_5: 0.6576 - val_loss: 1.7291 - val_acc: 0.1750 - val_recall_5: 0.1500 - val_precision_5: 0.2222\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9508 - acc: 0.5558 - recall_5: 0.3058 - precision_5: 0.6774\n",
            "Epoch 370: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9508 - acc: 0.5558 - recall_5: 0.3058 - precision_5: 0.6774 - val_loss: 1.9040 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9513 - acc: 0.5267 - recall_5: 0.2767 - precision_5: 0.6196\n",
            "Epoch 371: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9513 - acc: 0.5267 - recall_5: 0.2767 - precision_5: 0.6196 - val_loss: 1.7866 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 372/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9485 - acc: 0.5547 - recall_5: 0.2474 - precision_5: 0.5864\n",
            "Epoch 372: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.9422 - acc: 0.5510 - recall_5: 0.2549 - precision_5: 0.6000 - val_loss: 1.8883 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9482 - acc: 0.5121 - recall_5: 0.2961 - precision_5: 0.5810\n",
            "Epoch 373: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9482 - acc: 0.5121 - recall_5: 0.2961 - precision_5: 0.5810 - val_loss: 1.7170 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.2000\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9454 - acc: 0.5170 - recall_5: 0.2840 - precision_5: 0.5764\n",
            "Epoch 374: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9454 - acc: 0.5170 - recall_5: 0.2840 - precision_5: 0.5764 - val_loss: 1.7663 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 375/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9298 - acc: 0.5573 - recall_5: 0.2760 - precision_5: 0.6023\n",
            "Epoch 375: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9328 - acc: 0.5583 - recall_5: 0.2816 - precision_5: 0.5979 - val_loss: 1.7348 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 376/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9260 - acc: 0.5234 - recall_5: 0.3099 - precision_5: 0.6134\n",
            "Epoch 376: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9281 - acc: 0.5364 - recall_5: 0.3107 - precision_5: 0.6184 - val_loss: 1.7308 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9422 - acc: 0.5170 - recall_5: 0.2888 - precision_5: 0.5891\n",
            "Epoch 377: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9422 - acc: 0.5170 - recall_5: 0.2888 - precision_5: 0.5891 - val_loss: 1.7398 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9257 - acc: 0.5388 - recall_5: 0.2937 - precision_5: 0.6402\n",
            "Epoch 378: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9257 - acc: 0.5388 - recall_5: 0.2937 - precision_5: 0.6402 - val_loss: 1.6725 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9408 - acc: 0.5485 - recall_5: 0.3034 - precision_5: 0.6443\n",
            "Epoch 379: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9408 - acc: 0.5485 - recall_5: 0.3034 - precision_5: 0.6443 - val_loss: 1.7418 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.1429\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9276 - acc: 0.5607 - recall_5: 0.3034 - precision_5: 0.6345\n",
            "Epoch 380: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9276 - acc: 0.5607 - recall_5: 0.3034 - precision_5: 0.6345 - val_loss: 1.8285 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.1111\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9328 - acc: 0.5194 - recall_5: 0.3155 - precision_5: 0.6533\n",
            "Epoch 381: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9328 - acc: 0.5194 - recall_5: 0.3155 - precision_5: 0.6533 - val_loss: 1.9239 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 382/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9361 - acc: 0.5365 - recall_5: 0.3021 - precision_5: 0.6138\n",
            "Epoch 382: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9354 - acc: 0.5291 - recall_5: 0.3034 - precision_5: 0.6039 - val_loss: 1.6965 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9405 - acc: 0.5316 - recall_5: 0.3010 - precision_5: 0.6392\n",
            "Epoch 383: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9405 - acc: 0.5316 - recall_5: 0.3010 - precision_5: 0.6392 - val_loss: 1.6528 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 384/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9272 - acc: 0.5339 - recall_5: 0.3229 - precision_5: 0.6359\n",
            "Epoch 384: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9363 - acc: 0.5291 - recall_5: 0.3180 - precision_5: 0.6209 - val_loss: 1.7692 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 385/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9350 - acc: 0.5729 - recall_5: 0.3177 - precision_5: 0.6131\n",
            "Epoch 385: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9330 - acc: 0.5680 - recall_5: 0.3204 - precision_5: 0.6140 - val_loss: 1.7487 - val_acc: 0.1750 - val_recall_5: 0.1500 - val_precision_5: 0.2500\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9397 - acc: 0.5534 - recall_5: 0.3325 - precision_5: 0.6199\n",
            "Epoch 386: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9397 - acc: 0.5534 - recall_5: 0.3325 - precision_5: 0.6199 - val_loss: 1.5422 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9305 - acc: 0.5291 - recall_5: 0.2718 - precision_5: 0.6054\n",
            "Epoch 387: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9305 - acc: 0.5291 - recall_5: 0.2718 - precision_5: 0.6054 - val_loss: 1.8074 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 388/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9217 - acc: 0.5531 - recall_5: 0.3781 - precision_5: 0.6368\n",
            "Epoch 388: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9429 - acc: 0.5340 - recall_5: 0.3519 - precision_5: 0.6144 - val_loss: 1.8811 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 389/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9340 - acc: 0.5651 - recall_5: 0.3151 - precision_5: 0.6080\n",
            "Epoch 389: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9288 - acc: 0.5704 - recall_5: 0.3252 - precision_5: 0.6233 - val_loss: 1.7933 - val_acc: 0.1750 - val_recall_5: 0.1250 - val_precision_5: 0.2273\n",
            "Epoch 390/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9574 - acc: 0.5250 - recall_5: 0.2812 - precision_5: 0.5960\n",
            "Epoch 390: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 16ms/step - loss: 0.9342 - acc: 0.5388 - recall_5: 0.3083 - precision_5: 0.6225 - val_loss: 1.8382 - val_acc: 0.1750 - val_recall_5: 0.1500 - val_precision_5: 0.2000\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9232 - acc: 0.5413 - recall_5: 0.3252 - precision_5: 0.6381\n",
            "Epoch 391: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9232 - acc: 0.5413 - recall_5: 0.3252 - precision_5: 0.6381 - val_loss: 1.6546 - val_acc: 0.1750 - val_recall_5: 0.1250 - val_precision_5: 0.2273\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9278 - acc: 0.5364 - recall_5: 0.3034 - precision_5: 0.6410\n",
            "Epoch 392: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9278 - acc: 0.5364 - recall_5: 0.3034 - precision_5: 0.6410 - val_loss: 1.8125 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 393/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9146 - acc: 0.5562 - recall_5: 0.3156 - precision_5: 0.6273\n",
            "Epoch 393: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.9208 - acc: 0.5413 - recall_5: 0.3131 - precision_5: 0.6262 - val_loss: 1.7582 - val_acc: 0.1750 - val_recall_5: 0.1000 - val_precision_5: 0.2000\n",
            "Epoch 394/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9161 - acc: 0.5807 - recall_5: 0.3411 - precision_5: 0.6422\n",
            "Epoch 394: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9138 - acc: 0.5777 - recall_5: 0.3398 - precision_5: 0.6393 - val_loss: 1.8328 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9178 - acc: 0.5534 - recall_5: 0.2985 - precision_5: 0.5829\n",
            "Epoch 395: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9178 - acc: 0.5534 - recall_5: 0.2985 - precision_5: 0.5829 - val_loss: 1.9935 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9238 - acc: 0.5340 - recall_5: 0.3447 - precision_5: 0.6256\n",
            "Epoch 396: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9238 - acc: 0.5340 - recall_5: 0.3447 - precision_5: 0.6256 - val_loss: 1.7697 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 397/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9294 - acc: 0.5398 - recall_5: 0.3068 - precision_5: 0.5870\n",
            "Epoch 397: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9199 - acc: 0.5461 - recall_5: 0.3204 - precision_5: 0.6027 - val_loss: 1.8080 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9340 - acc: 0.5024 - recall_5: 0.2864 - precision_5: 0.5514\n",
            "Epoch 398: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9340 - acc: 0.5024 - recall_5: 0.2864 - precision_5: 0.5514 - val_loss: 1.5969 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2800\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9222 - acc: 0.5607 - recall_5: 0.3301 - precision_5: 0.6385\n",
            "Epoch 399: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9222 - acc: 0.5607 - recall_5: 0.3301 - precision_5: 0.6385 - val_loss: 1.7648 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.2000\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9129 - acc: 0.5583 - recall_5: 0.3422 - precision_5: 0.6130\n",
            "Epoch 400: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9129 - acc: 0.5583 - recall_5: 0.3422 - precision_5: 0.6130 - val_loss: 1.7701 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9352 - acc: 0.5243 - recall_5: 0.2791 - precision_5: 0.5990\n",
            "Epoch 401: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9352 - acc: 0.5243 - recall_5: 0.2791 - precision_5: 0.5990 - val_loss: 1.8621 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 402/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9363 - acc: 0.5443 - recall_5: 0.3099 - precision_5: 0.5920\n",
            "Epoch 402: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9304 - acc: 0.5534 - recall_5: 0.3204 - precision_5: 0.6055 - val_loss: 1.9159 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9193 - acc: 0.5583 - recall_5: 0.3519 - precision_5: 0.6042\n",
            "Epoch 403: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9193 - acc: 0.5583 - recall_5: 0.3519 - precision_5: 0.6042 - val_loss: 1.8112 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9263 - acc: 0.5316 - recall_5: 0.3495 - precision_5: 0.6344\n",
            "Epoch 404: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9263 - acc: 0.5316 - recall_5: 0.3495 - precision_5: 0.6344 - val_loss: 1.7785 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9341 - acc: 0.5364 - recall_5: 0.3204 - precision_5: 0.5789\n",
            "Epoch 405: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9341 - acc: 0.5364 - recall_5: 0.3204 - precision_5: 0.5789 - val_loss: 1.8418 - val_acc: 0.1500 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 406/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9260 - acc: 0.5365 - recall_5: 0.3333 - precision_5: 0.6214\n",
            "Epoch 406: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9228 - acc: 0.5316 - recall_5: 0.3301 - precision_5: 0.6182 - val_loss: 1.7414 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 407/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9355 - acc: 0.5511 - recall_5: 0.2955 - precision_5: 0.6190\n",
            "Epoch 407: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9383 - acc: 0.5388 - recall_5: 0.2937 - precision_5: 0.5990 - val_loss: 1.8980 - val_acc: 0.1750 - val_recall_5: 0.0250 - val_precision_5: 0.1429\n",
            "Epoch 408/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9214 - acc: 0.5341 - recall_5: 0.3551 - precision_5: 0.6158\n",
            "Epoch 408: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.9229 - acc: 0.5267 - recall_5: 0.3592 - precision_5: 0.6218 - val_loss: 1.9077 - val_acc: 0.1750 - val_recall_5: 0.1000 - val_precision_5: 0.2000\n",
            "Epoch 409/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9297 - acc: 0.5483 - recall_5: 0.3182 - precision_5: 0.6364\n",
            "Epoch 409: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.9225 - acc: 0.5437 - recall_5: 0.3107 - precision_5: 0.6368 - val_loss: 1.8598 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9289 - acc: 0.5340 - recall_5: 0.3374 - precision_5: 0.6178\n",
            "Epoch 410: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9289 - acc: 0.5340 - recall_5: 0.3374 - precision_5: 0.6178 - val_loss: 1.7739 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2414\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9113 - acc: 0.5704 - recall_5: 0.3228 - precision_5: 0.6186\n",
            "Epoch 411: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.9113 - acc: 0.5704 - recall_5: 0.3228 - precision_5: 0.6186 - val_loss: 2.0645 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2000\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9243 - acc: 0.5340 - recall_5: 0.3495 - precision_5: 0.5783\n",
            "Epoch 412: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 24ms/step - loss: 0.9243 - acc: 0.5340 - recall_5: 0.3495 - precision_5: 0.5783 - val_loss: 1.8347 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9226 - acc: 0.5583 - recall_5: 0.3592 - precision_5: 0.6520\n",
            "Epoch 413: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.9226 - acc: 0.5583 - recall_5: 0.3592 - precision_5: 0.6520 - val_loss: 1.9036 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 414/500\n",
            "10/13 [======================>.......] - ETA: 0s - loss: 0.9471 - acc: 0.5344 - recall_5: 0.3594 - precision_5: 0.6021\n",
            "Epoch 414: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.9323 - acc: 0.5485 - recall_5: 0.3519 - precision_5: 0.6118 - val_loss: 1.8594 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9176 - acc: 0.5485 - recall_5: 0.3350 - precision_5: 0.6079\n",
            "Epoch 415: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.9176 - acc: 0.5485 - recall_5: 0.3350 - precision_5: 0.6079 - val_loss: 1.9447 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9260 - acc: 0.5267 - recall_5: 0.3277 - precision_5: 0.6164\n",
            "Epoch 416: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 28ms/step - loss: 0.9260 - acc: 0.5267 - recall_5: 0.3277 - precision_5: 0.6164 - val_loss: 1.8912 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 417/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9354 - acc: 0.5142 - recall_5: 0.3040 - precision_5: 0.6185\n",
            "Epoch 417: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 21ms/step - loss: 0.9224 - acc: 0.5218 - recall_5: 0.3155 - precision_5: 0.6404 - val_loss: 1.8374 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 418/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9317 - acc: 0.5781 - recall_5: 0.3307 - precision_5: 0.6019\n",
            "Epoch 418: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.9345 - acc: 0.5752 - recall_5: 0.3252 - precision_5: 0.6063 - val_loss: 1.9004 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 419/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9259 - acc: 0.5483 - recall_5: 0.3523 - precision_5: 0.6327\n",
            "Epoch 419: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9264 - acc: 0.5485 - recall_5: 0.3544 - precision_5: 0.6348 - val_loss: 1.8932 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 420/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9079 - acc: 0.5483 - recall_5: 0.3381 - precision_5: 0.6398\n",
            "Epoch 420: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9155 - acc: 0.5388 - recall_5: 0.3277 - precision_5: 0.6368 - val_loss: 1.9219 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 421/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9021 - acc: 0.5568 - recall_5: 0.3295 - precision_5: 0.6339\n",
            "Epoch 421: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 25ms/step - loss: 0.9050 - acc: 0.5510 - recall_5: 0.3252 - precision_5: 0.6291 - val_loss: 1.8653 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9124 - acc: 0.5534 - recall_5: 0.3544 - precision_5: 0.6186\n",
            "Epoch 422: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.9124 - acc: 0.5534 - recall_5: 0.3544 - precision_5: 0.6186 - val_loss: 2.1630 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 423/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9131 - acc: 0.5469 - recall_5: 0.3516 - precision_5: 0.6000\n",
            "Epoch 423: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9163 - acc: 0.5437 - recall_5: 0.3544 - precision_5: 0.6033 - val_loss: 1.8723 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9178 - acc: 0.5922 - recall_5: 0.3665 - precision_5: 0.6189\n",
            "Epoch 424: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9178 - acc: 0.5922 - recall_5: 0.3665 - precision_5: 0.6189 - val_loss: 2.1667 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 425/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.9105 - acc: 0.5682 - recall_5: 0.4119 - precision_5: 0.6591\n",
            "Epoch 425: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 23ms/step - loss: 0.9147 - acc: 0.5704 - recall_5: 0.4005 - precision_5: 0.6574 - val_loss: 1.9291 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9174 - acc: 0.5510 - recall_5: 0.3665 - precision_5: 0.6138\n",
            "Epoch 426: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 27ms/step - loss: 0.9174 - acc: 0.5510 - recall_5: 0.3665 - precision_5: 0.6138 - val_loss: 1.7300 - val_acc: 0.1750 - val_recall_5: 0.1250 - val_precision_5: 0.2174\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9207 - acc: 0.5388 - recall_5: 0.3592 - precision_5: 0.6192\n",
            "Epoch 427: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 30ms/step - loss: 0.9207 - acc: 0.5388 - recall_5: 0.3592 - precision_5: 0.6192 - val_loss: 1.8180 - val_acc: 0.1750 - val_recall_5: 0.0000e+00 - val_precision_5: 0.0000e+00\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9111 - acc: 0.5485 - recall_5: 0.3422 - precision_5: 0.6468\n",
            "Epoch 428: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 26ms/step - loss: 0.9111 - acc: 0.5485 - recall_5: 0.3422 - precision_5: 0.6468 - val_loss: 1.9754 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 429/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9055 - acc: 0.5443 - recall_5: 0.3698 - precision_5: 0.6256\n",
            "Epoch 429: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9066 - acc: 0.5437 - recall_5: 0.3714 - precision_5: 0.6220 - val_loss: 1.8537 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9096 - acc: 0.5704 - recall_5: 0.3544 - precision_5: 0.6404\n",
            "Epoch 430: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9096 - acc: 0.5704 - recall_5: 0.3544 - precision_5: 0.6404 - val_loss: 2.0177 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9322 - acc: 0.5218 - recall_5: 0.3204 - precision_5: 0.5570\n",
            "Epoch 431: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.9322 - acc: 0.5218 - recall_5: 0.3204 - precision_5: 0.5570 - val_loss: 1.8927 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9148 - acc: 0.5728 - recall_5: 0.3956 - precision_5: 0.6546\n",
            "Epoch 432: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9148 - acc: 0.5728 - recall_5: 0.3956 - precision_5: 0.6546 - val_loss: 1.8668 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 433/500\n",
            " 9/13 [===================>..........] - ETA: 0s - loss: 0.9023 - acc: 0.5729 - recall_5: 0.3368 - precision_5: 0.6258\n",
            "Epoch 433: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9195 - acc: 0.5631 - recall_5: 0.3325 - precision_5: 0.6256 - val_loss: 1.9701 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9070 - acc: 0.5583 - recall_5: 0.3592 - precision_5: 0.6192\n",
            "Epoch 434: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9070 - acc: 0.5583 - recall_5: 0.3592 - precision_5: 0.6192 - val_loss: 1.9755 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9185 - acc: 0.5510 - recall_5: 0.3398 - precision_5: 0.6061\n",
            "Epoch 435: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9185 - acc: 0.5510 - recall_5: 0.3398 - precision_5: 0.6061 - val_loss: 2.1332 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9062 - acc: 0.5680 - recall_5: 0.3471 - precision_5: 0.6217\n",
            "Epoch 436: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9062 - acc: 0.5680 - recall_5: 0.3471 - precision_5: 0.6217 - val_loss: 1.9801 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9151 - acc: 0.5413 - recall_5: 0.3665 - precision_5: 0.5922\n",
            "Epoch 437: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9151 - acc: 0.5413 - recall_5: 0.3665 - precision_5: 0.5922 - val_loss: 2.0174 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9075 - acc: 0.5558 - recall_5: 0.3301 - precision_5: 0.5991\n",
            "Epoch 438: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9075 - acc: 0.5558 - recall_5: 0.3301 - precision_5: 0.5991 - val_loss: 2.0307 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2000\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9249 - acc: 0.5291 - recall_5: 0.3568 - precision_5: 0.6336\n",
            "Epoch 439: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9249 - acc: 0.5291 - recall_5: 0.3568 - precision_5: 0.6336 - val_loss: 1.8405 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9004 - acc: 0.5631 - recall_5: 0.3883 - precision_5: 0.6275\n",
            "Epoch 440: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9004 - acc: 0.5631 - recall_5: 0.3883 - precision_5: 0.6275 - val_loss: 2.0248 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 441/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9135 - acc: 0.5651 - recall_5: 0.3542 - precision_5: 0.6445\n",
            "Epoch 441: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9090 - acc: 0.5655 - recall_5: 0.3544 - precision_5: 0.6404 - val_loss: 2.1144 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2000\n",
            "Epoch 442/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.8971 - acc: 0.5767 - recall_5: 0.3892 - precision_5: 0.6716\n",
            "Epoch 442: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9040 - acc: 0.5558 - recall_5: 0.3762 - precision_5: 0.6275 - val_loss: 2.1249 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 443/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9165 - acc: 0.5651 - recall_5: 0.3802 - precision_5: 0.6134\n",
            "Epoch 443: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9113 - acc: 0.5704 - recall_5: 0.3835 - precision_5: 0.6196 - val_loss: 1.9184 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8851 - acc: 0.5752 - recall_5: 0.4005 - precision_5: 0.6548\n",
            "Epoch 444: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8851 - acc: 0.5752 - recall_5: 0.4005 - precision_5: 0.6548 - val_loss: 2.0781 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8966 - acc: 0.5825 - recall_5: 0.3932 - precision_5: 0.6532\n",
            "Epoch 445: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8966 - acc: 0.5825 - recall_5: 0.3932 - precision_5: 0.6532 - val_loss: 1.9159 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 446/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8936 - acc: 0.5729 - recall_5: 0.3854 - precision_5: 0.6218\n",
            "Epoch 446: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9021 - acc: 0.5631 - recall_5: 0.3762 - precision_5: 0.6151 - val_loss: 1.9451 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8990 - acc: 0.5631 - recall_5: 0.3932 - precision_5: 0.6328\n",
            "Epoch 447: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8990 - acc: 0.5631 - recall_5: 0.3932 - precision_5: 0.6328 - val_loss: 1.9694 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9247 - acc: 0.5364 - recall_5: 0.3568 - precision_5: 0.6176\n",
            "Epoch 448: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9247 - acc: 0.5364 - recall_5: 0.3568 - precision_5: 0.6176 - val_loss: 1.8489 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8999 - acc: 0.5607 - recall_5: 0.3811 - precision_5: 0.6356\n",
            "Epoch 449: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8999 - acc: 0.5607 - recall_5: 0.3811 - precision_5: 0.6356 - val_loss: 1.9461 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8982 - acc: 0.5704 - recall_5: 0.3956 - precision_5: 0.6342\n",
            "Epoch 450: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8982 - acc: 0.5704 - recall_5: 0.3956 - precision_5: 0.6342 - val_loss: 1.9352 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9125 - acc: 0.5558 - recall_5: 0.3544 - precision_5: 0.5863\n",
            "Epoch 451: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9125 - acc: 0.5558 - recall_5: 0.3544 - precision_5: 0.5863 - val_loss: 2.0407 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8998 - acc: 0.5728 - recall_5: 0.3544 - precision_5: 0.6376\n",
            "Epoch 452: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8998 - acc: 0.5728 - recall_5: 0.3544 - precision_5: 0.6376 - val_loss: 2.1740 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8992 - acc: 0.5607 - recall_5: 0.3956 - precision_5: 0.6367\n",
            "Epoch 453: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8992 - acc: 0.5607 - recall_5: 0.3956 - precision_5: 0.6367 - val_loss: 2.0245 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 454/500\n",
            "11/13 [========================>.....] - ETA: 0s - loss: 0.8927 - acc: 0.5511 - recall_5: 0.4119 - precision_5: 0.6304\n",
            "Epoch 454: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9073 - acc: 0.5461 - recall_5: 0.4078 - precision_5: 0.6222 - val_loss: 2.1343 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8944 - acc: 0.5631 - recall_5: 0.4005 - precision_5: 0.6395\n",
            "Epoch 455: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8944 - acc: 0.5631 - recall_5: 0.4005 - precision_5: 0.6395 - val_loss: 2.0987 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8963 - acc: 0.5558 - recall_5: 0.3932 - precision_5: 0.6353\n",
            "Epoch 456: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8963 - acc: 0.5558 - recall_5: 0.3932 - precision_5: 0.6353 - val_loss: 1.8901 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9176 - acc: 0.5680 - recall_5: 0.3883 - precision_5: 0.6202\n",
            "Epoch 457: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9176 - acc: 0.5680 - recall_5: 0.3883 - precision_5: 0.6202 - val_loss: 1.9138 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9015 - acc: 0.5607 - recall_5: 0.3786 - precision_5: 0.6118\n",
            "Epoch 458: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9015 - acc: 0.5607 - recall_5: 0.3786 - precision_5: 0.6118 - val_loss: 2.1050 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8971 - acc: 0.5461 - recall_5: 0.3592 - precision_5: 0.5992\n",
            "Epoch 459: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8971 - acc: 0.5461 - recall_5: 0.3592 - precision_5: 0.5992 - val_loss: 2.0068 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9134 - acc: 0.5583 - recall_5: 0.3835 - precision_5: 0.6295\n",
            "Epoch 460: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9134 - acc: 0.5583 - recall_5: 0.3835 - precision_5: 0.6295 - val_loss: 1.9801 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 461/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.9075 - acc: 0.5443 - recall_5: 0.3854 - precision_5: 0.5920\n",
            "Epoch 461: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8995 - acc: 0.5461 - recall_5: 0.3908 - precision_5: 0.6053 - val_loss: 2.0715 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9014 - acc: 0.5704 - recall_5: 0.3981 - precision_5: 0.6332\n",
            "Epoch 462: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9014 - acc: 0.5704 - recall_5: 0.3981 - precision_5: 0.6332 - val_loss: 2.1656 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8864 - acc: 0.5752 - recall_5: 0.4102 - precision_5: 0.6426\n",
            "Epoch 463: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8864 - acc: 0.5752 - recall_5: 0.4102 - precision_5: 0.6426 - val_loss: 1.9632 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8954 - acc: 0.5752 - recall_5: 0.4223 - precision_5: 0.6170\n",
            "Epoch 464: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8954 - acc: 0.5752 - recall_5: 0.4223 - precision_5: 0.6170 - val_loss: 1.8886 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8969 - acc: 0.5510 - recall_5: 0.4053 - precision_5: 0.6140\n",
            "Epoch 465: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8969 - acc: 0.5510 - recall_5: 0.4053 - precision_5: 0.6140 - val_loss: 1.7896 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9055 - acc: 0.5583 - recall_5: 0.3786 - precision_5: 0.6290\n",
            "Epoch 466: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9055 - acc: 0.5583 - recall_5: 0.3786 - precision_5: 0.6290 - val_loss: 2.0192 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 467/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8845 - acc: 0.5807 - recall_5: 0.4062 - precision_5: 0.6638\n",
            "Epoch 467: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8888 - acc: 0.5777 - recall_5: 0.4029 - precision_5: 0.6614 - val_loss: 2.1575 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8812 - acc: 0.5752 - recall_5: 0.3932 - precision_5: 0.6532\n",
            "Epoch 468: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8812 - acc: 0.5752 - recall_5: 0.3932 - precision_5: 0.6532 - val_loss: 2.1941 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1842\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8853 - acc: 0.5752 - recall_5: 0.4029 - precision_5: 0.6264\n",
            "Epoch 469: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8853 - acc: 0.5752 - recall_5: 0.4029 - precision_5: 0.6264 - val_loss: 2.1687 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8997 - acc: 0.5777 - recall_5: 0.4320 - precision_5: 0.6473\n",
            "Epoch 470: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8997 - acc: 0.5777 - recall_5: 0.4320 - precision_5: 0.6473 - val_loss: 2.0029 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8982 - acc: 0.5850 - recall_5: 0.3956 - precision_5: 0.6468\n",
            "Epoch 471: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8982 - acc: 0.5850 - recall_5: 0.3956 - precision_5: 0.6468 - val_loss: 2.0454 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8877 - acc: 0.5777 - recall_5: 0.4150 - precision_5: 0.6453\n",
            "Epoch 472: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8877 - acc: 0.5777 - recall_5: 0.4150 - precision_5: 0.6453 - val_loss: 2.2560 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8791 - acc: 0.5704 - recall_5: 0.4272 - precision_5: 0.6494\n",
            "Epoch 473: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8791 - acc: 0.5704 - recall_5: 0.4272 - precision_5: 0.6494 - val_loss: 2.0538 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2333\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9069 - acc: 0.5728 - recall_5: 0.3835 - precision_5: 0.6054\n",
            "Epoch 474: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9069 - acc: 0.5728 - recall_5: 0.3835 - precision_5: 0.6054 - val_loss: 2.1277 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8996 - acc: 0.5680 - recall_5: 0.4005 - precision_5: 0.6274\n",
            "Epoch 475: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8996 - acc: 0.5680 - recall_5: 0.4005 - precision_5: 0.6274 - val_loss: 2.0634 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8966 - acc: 0.5558 - recall_5: 0.3859 - precision_5: 0.6335\n",
            "Epoch 476: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8966 - acc: 0.5558 - recall_5: 0.3859 - precision_5: 0.6335 - val_loss: 2.1042 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1750\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8797 - acc: 0.5752 - recall_5: 0.4223 - precision_5: 0.6374\n",
            "Epoch 477: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8797 - acc: 0.5752 - recall_5: 0.4223 - precision_5: 0.6374 - val_loss: 2.1650 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8981 - acc: 0.5655 - recall_5: 0.4005 - precision_5: 0.6346\n",
            "Epoch 478: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8981 - acc: 0.5655 - recall_5: 0.4005 - precision_5: 0.6346 - val_loss: 2.1978 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8890 - acc: 0.5874 - recall_5: 0.4102 - precision_5: 0.6259\n",
            "Epoch 479: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8890 - acc: 0.5874 - recall_5: 0.4102 - precision_5: 0.6259 - val_loss: 2.1496 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8900 - acc: 0.5631 - recall_5: 0.4369 - precision_5: 0.6102\n",
            "Epoch 480: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8900 - acc: 0.5631 - recall_5: 0.4369 - precision_5: 0.6102 - val_loss: 1.9178 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9105 - acc: 0.5437 - recall_5: 0.3811 - precision_5: 0.6157\n",
            "Epoch 481: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.9105 - acc: 0.5437 - recall_5: 0.3811 - precision_5: 0.6157 - val_loss: 2.0595 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1944\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8747 - acc: 0.5947 - recall_5: 0.4102 - precision_5: 0.6815\n",
            "Epoch 482: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8747 - acc: 0.5947 - recall_5: 0.4102 - precision_5: 0.6815 - val_loss: 2.2543 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1842\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8870 - acc: 0.5583 - recall_5: 0.4175 - precision_5: 0.6078\n",
            "Epoch 483: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8870 - acc: 0.5583 - recall_5: 0.4175 - precision_5: 0.6078 - val_loss: 1.9623 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2188\n",
            "Epoch 484/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8865 - acc: 0.5703 - recall_5: 0.3854 - precision_5: 0.6141\n",
            "Epoch 484: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8878 - acc: 0.5752 - recall_5: 0.3932 - precision_5: 0.6160 - val_loss: 1.9394 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8915 - acc: 0.5874 - recall_5: 0.4369 - precision_5: 0.6593\n",
            "Epoch 485: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8915 - acc: 0.5874 - recall_5: 0.4369 - precision_5: 0.6593 - val_loss: 2.2644 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8914 - acc: 0.5728 - recall_5: 0.4248 - precision_5: 0.6295\n",
            "Epoch 486: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8914 - acc: 0.5728 - recall_5: 0.4248 - precision_5: 0.6295 - val_loss: 2.3058 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8818 - acc: 0.5850 - recall_5: 0.4126 - precision_5: 0.6204\n",
            "Epoch 487: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8818 - acc: 0.5850 - recall_5: 0.4126 - precision_5: 0.6204 - val_loss: 2.0335 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2258\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9076 - acc: 0.5583 - recall_5: 0.3932 - precision_5: 0.6136\n",
            "Epoch 488: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9076 - acc: 0.5583 - recall_5: 0.3932 - precision_5: 0.6136 - val_loss: 2.1248 - val_acc: 0.1750 - val_recall_5: 0.1000 - val_precision_5: 0.1481\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9061 - acc: 0.5631 - recall_5: 0.3859 - precision_5: 0.6285\n",
            "Epoch 489: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.9061 - acc: 0.5631 - recall_5: 0.3859 - precision_5: 0.6285 - val_loss: 2.1616 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.9057 - acc: 0.5680 - recall_5: 0.3786 - precision_5: 0.5977\n",
            "Epoch 490: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.9057 - acc: 0.5680 - recall_5: 0.3786 - precision_5: 0.5977 - val_loss: 2.1307 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2059\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8799 - acc: 0.5971 - recall_5: 0.4029 - precision_5: 0.6510\n",
            "Epoch 491: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8799 - acc: 0.5971 - recall_5: 0.4029 - precision_5: 0.6510 - val_loss: 2.2905 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8966 - acc: 0.5704 - recall_5: 0.4175 - precision_5: 0.6277\n",
            "Epoch 492: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8966 - acc: 0.5704 - recall_5: 0.4175 - precision_5: 0.6277 - val_loss: 2.0160 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8889 - acc: 0.5680 - recall_5: 0.4150 - precision_5: 0.6453\n",
            "Epoch 493: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8889 - acc: 0.5680 - recall_5: 0.4150 - precision_5: 0.6453 - val_loss: 2.1944 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1842\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8864 - acc: 0.5704 - recall_5: 0.4248 - precision_5: 0.6364\n",
            "Epoch 494: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8864 - acc: 0.5704 - recall_5: 0.4248 - precision_5: 0.6364 - val_loss: 2.3627 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8831 - acc: 0.5898 - recall_5: 0.4126 - precision_5: 0.6367\n",
            "Epoch 495: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8831 - acc: 0.5898 - recall_5: 0.4126 - precision_5: 0.6367 - val_loss: 2.0960 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1892\n",
            "Epoch 496/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8783 - acc: 0.6042 - recall_5: 0.4401 - precision_5: 0.6627\n",
            "Epoch 496: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8770 - acc: 0.6019 - recall_5: 0.4345 - precision_5: 0.6654 - val_loss: 2.2262 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.8859 - acc: 0.5631 - recall_5: 0.4272 - precision_5: 0.6308\n",
            "Epoch 497: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 17ms/step - loss: 0.8859 - acc: 0.5631 - recall_5: 0.4272 - precision_5: 0.6308 - val_loss: 2.1729 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2121\n",
            "Epoch 498/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8935 - acc: 0.5859 - recall_5: 0.4297 - precision_5: 0.6522\n",
            "Epoch 498: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 18ms/step - loss: 0.8944 - acc: 0.5777 - recall_5: 0.4223 - precision_5: 0.6444 - val_loss: 2.3254 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1842\n",
            "Epoch 499/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8750 - acc: 0.5807 - recall_5: 0.4531 - precision_5: 0.6421\n",
            "Epoch 499: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 19ms/step - loss: 0.8733 - acc: 0.5777 - recall_5: 0.4539 - precision_5: 0.6404 - val_loss: 2.0840 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.2000\n",
            "Epoch 500/500\n",
            "12/13 [==========================>...] - ETA: 0s - loss: 0.8889 - acc: 0.5625 - recall_5: 0.3906 - precision_5: 0.6122\n",
            "Epoch 500: val_loss did not improve from 1.15665\n",
            "13/13 [==============================] - 0s 20ms/step - loss: 0.8857 - acc: 0.5631 - recall_5: 0.3908 - precision_5: 0.6145 - val_loss: 2.3858 - val_acc: 0.1750 - val_recall_5: 0.1750 - val_precision_5: 0.1795\n"
          ]
        }
      ],
      "source": [
        "best_weights_file = 'weights.best.hdf5'\n",
        "checkpoint = ModelCheckpoint(best_weights_file,monitor='val_loss',verbose=1,save_best_only=True,mode='min')\n",
        "\n",
        "callbacks = [checkpoint]\n",
        "\n",
        "\n",
        "train_history = model.fit([x_delta_aug[40:],x_theta_aug[40:],x_alpha_aug[40:],x_beta_aug[40:],x_gamma_aug[40:]],y_train_aug[40:],\n",
        "          batch_size=32,epochs=500,callbacks=callbacks,\n",
        "          validation_data=validation_data,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = train_history.epoch[-1]+1\n",
        "history = train_history.history"
      ],
      "metadata": {
        "id": "UeDq8adZ2KBg"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "axes[0].plot(range(1, num_epochs+1), history['loss'])\n",
        "axes[0].plot(range(1, num_epochs+1), history['val_loss'])\n",
        "axes[0].legend(['Train loss curve', 'Validation loss curve'])\n",
        "axes[0].set_xlabel('epoch')\n",
        "axes[0].set_ylabel('loss')\n",
        "\n",
        "\n",
        "axes[1].plot(range(1, num_epochs+1), history['acc'])\n",
        "axes[1].plot(range(1, num_epochs+1), history['val_acc'])\n",
        "axes[1].legend(['Train accuracy curve', 'Validation accuracy curve'])\n",
        "axes[1].set_xlabel('epoch')\n",
        "axes[1].set_ylabel('accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "leqtoAtf28yj",
        "outputId": "cfc63df6-b715-441a-9cc9-7cae5a73a82c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# early stopping\n",
        "early_stop_epoch = np.argmax(history['val_acc'])\n",
        "print('The early stop epoch is: ', early_stop_epoch)\n",
        "print('Train acc (Early stopping): %.2f' % history['acc'][early_stop_epoch])\n",
        "print('Validation acc (Early stopping): %.2f' % history['val_acc'][early_stop_epoch])"
      ],
      "metadata": {
        "id": "d3W6JmXP3P-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063d6cb9-e232-4a14-acb6-0e645cc21230"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The early stop epoch is:  169\n",
            "Train acc (Early stopping): 0.44\n",
            "Validation acc (Early stopping): 0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SexDioE2XZZH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}